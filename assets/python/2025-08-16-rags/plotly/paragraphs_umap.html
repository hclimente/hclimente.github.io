<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>                        <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.1.0.min.js" integrity="sha256-Ei4740bWZhaUTQuD6q9yQlgVCMPBz6CZWhevDYPv93A=" crossorigin="anonymous"></script>                <div id="umap_plot" class="plotly-graph-div" style="height:100%; width:100%;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("umap_plot")) {                    Plotly.newPlot(                        "umap_plot",                        [{"hoverinfo":"text","marker":{"color":["hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(86,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(136,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(99,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(211,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(74,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(285,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(335,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(248,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(273,70%,50%)","hsl(260,70%,50%)","hsl(260,70%,50%)","hsl(260,70%,50%)","hsl(260,70%,50%)","hsl(260,70%,50%)","hsl(260,70%,50%)","hsl(260,70%,50%)","hsl(260,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(347,70%,50%)","hsl(148,70%,50%)","hsl(148,70%,50%)","hsl(148,70%,50%)","hsl(148,70%,50%)","hsl(148,70%,50%)","hsl(148,70%,50%)","hsl(148,70%,50%)","hsl(148,70%,50%)","hsl(148,70%,50%)","hsl(148,70%,50%)","hsl(148,70%,50%)","hsl(148,70%,50%)","hsl(148,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(297,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(12,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(173,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(24,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(223,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(186,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(111,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(124,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(310,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(235,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(198,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(0,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(322,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(62,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(37,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(49,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)","hsl(161,70%,50%)"],"opacity":0.7,"size":8},"mode":"markers","text":["\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eCancer is the name of a collection of related diseases. Specifically, all cancers undergo an uncontrolled proliferation of the patient cells, which spread into surrounding tissues. In a normal organis...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eThis abnormal behavior occurs as consequence of the alteration of crucial genes. These alterations can be inherited from our parents, or acquired during our lifetime due to replication errors or expos...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eBreast cancer occurs when breast cells undergo this uncontrolled proliferation. In most of the cases they begin in the ducts that carry the milk to the nipple. However the tumor can originate in other...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eBreast cancer is the second most commonly diagnosed cancer among women, after non-melanoma skin cancer. We find the highest incidence in Western countries, and it has increased in the last decades. Tw...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eBreast cancer is a very heterogeneous disease: while all the tumors appear in the same organ, the tissue where they originate, the molecular mechanism involved, the response to therapy, etc. vastly di...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eHormone receptor positive tumors include the tumors expressing ER and\u002for PR, which respectively depend on estrogen and\u002for progesterone to grow. They happen mostly in postmenopausal women. HR+\u002fHER2- al...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eHER2+ tumors depend on the protein HER2\u002fneu (human epidermal growth factor receptor 2) to proliferate, which they over-express. HR+\u002fHER2+ (also known as LuminalB) constitutes 10% of the cases, while H...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eTriple-negative tumors (also known as basal-like) lack the expression of all three of ER, PgR and HER2. These patients present a worse prognosis than the rest, due to the aggressiveness of the tumor a...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eRoutine screening for breast cancer has been set up in the last decades in many countries. After it was introduced we observed a mortality reduction of 30%, justifying its wide implementation. It cons...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eDespite the aforementioned success, there is a big controversy regarding mammography programs usefulness. That is because, in practical terms, the 30% decrease in mortality means that for every 1000 w...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eIn the mid-19th century a French medical doctor, Pierre Paul Broca, reported for the first time a case of familial breast cancer. Indeed, his wife acquired breast cancer, as many women in her family h...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eIt wasn\u2019t until the late 20th century that two genes involved in DNA repair, BRCA1 and BRCA2, were associated with hereditary breast and ovarian cancer (HBOC). Some mutations in these genes increase t...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eHBOC follows an autosomal dominant inheritance pattern. While approximately 5\u201310% of all patients with breast cancer exhibit a monogenic predisposition to breast and ovarian cancer, only about 25% of ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eTable 1. Overview of HBOC genes: estimated lifetime risk of breast cancer (age in years) and tumorogenic molecular mechanisms that involves them: homologous recombination repair (HRR), replication for...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e| **Gene** | **Breast cancer estimated lifetime risk (age in years)** | **HRR** | **Replication fork stability** | **Transcription\u2013replication collisions** | **MMR** | **DNA damage signaling, checkpoi...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e| :------: | :------------------------------------------------------: | :-----: | :----------------------------: | :--------------------------------------: | :-----: | :-------------------------------...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|   ATM    |                      60% by age 80                       |    \u2713    |                                |                                          |         |                          \u2713      ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  BARD1   |                         Unknown                          |    \u2713    |                                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|   BLM    |                         Unknown                          |         |               \u2713                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  BRCA1   |                     57\u201365% by age 70                     |    \u2713    |               \u2713                |                    \u2713                     |         |                          \u2713      ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  BRCA2   |                     45\u201355% by age 70                     |    \u2713    |               \u2713                |                    \u2713                     |         |                          \u2713      ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  BRIP1   |                         OR: \u003c2.0                         |         |                                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|   CDH1   |                      42% by age 80                       |         |                                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  CHEK2   |                      37% by age 70                       |         |                                |                                          |         |                          \u2713      ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e| FAM175A  |                         Unknown                          |    \u2713    |                                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  FANCC   |                         Unknown                          |         |               \u2713                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  FANCM   |                         Unknown                          |         |               \u2713                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|   MLH1   |                      ~19% by age 70                      |         |               \u2713                |                                          |    \u2713    |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  MRE11   |                         Unknown                          |         |                                |                                          |    \u2713    |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|   MSH2   |                      ~11% by age 70                      |         |                                |                                          |    \u2713    |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|   NBN    |                         OR: 3.0                          |    \u2713    |                                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|   NF1    |          6.5-fold increase in women aged 30\u201339           |         |                                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  PALB2   |                      35% by age 70                       |    \u2713    |               \u2713                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|   PMS2   |                         SIR: 3.8                         |         |                                |                                          |    \u2713    |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|   PTEN   |                      85% by age 70                       |         |                                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  RAD51B  |                         Unknown                          |    \u2713    |                                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  RAD51C  |                         Unknown                          |    \u2713    |                                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  RAD51D  |                         Unknown                          |    \u2713    |                                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  RECQL   |                         Unknown                          |         |               \u2713                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  RINT1   |                         Unknown                          |    \u2713    |                                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|  STK11   |                      32% by age 60                       |         |                                |                                          |         |                                 ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e|   TP53   |                      25% by age 70                       |         |                                |                                          |         |                          \u2713      ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eNearly all known HBOC susceptibility genes encode tumor suppressors that participate in genome stability pathways (homologous recombination repair, replication fork stability, transcription\u2013replicatio...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eThe homologous recombination repair pathway (HRR) deals with double strand DNA breaks by using the undamaged chromosome as template for error-free repair. After a DSB occurs, the MRN complex (MRE11, R...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eHRR involves BRCA1, BRCA2 and, actually, most of the HBOC genes. Because of its ability to interact with a wide range of proteins, BRCA1 is hypothetized to act as a recruitment scaffold. A deficiency ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eBRCA1 and BRCA2 protect newly synthesized DNA and promote the restart of stalled forks in an HRR-independent manner. In the absence of these proteins, newly synthesized DNA in a stalled fork would get...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eCollisions between transcription and replication are emerging as a source of genome instability. In particular, RNA-DNA hybrids called R-loops can form between the nascent transcript and the DNA templ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eDNA mismatch repair (MMR) corrects base-base mispairs. When MMR is faulty, accumulations point mutations and genetic changes in repeated nucleotide sequences (microsatellite instability) occur. MMR al...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003ePathways involved in genome maintenance, cell cycle checkpoints and cell death usually eliminate cells with damaged DNA. When proteins involved in them are not active, some processes such as cell cycl...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eDespite the identification of HBOC genes, 52% of the heritability or familial breast cancer remains unexplained: 20% is explained by high penetrance loci and an extra 28% by common variants. We can il...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e\u003e **iCOGS** is a custom Illumina array designed by four consortia that study genetic susceptibility of three hormone-related cancers: breast ([BCAC](http:\u002f\u002fccge.medschl.cam.ac.uk\u002fconsortia\u002fbcac\u002f) and ...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003eGENESIS (GENE SISter) is a French project that aims to shed some light on familial breast cancer. The index cases are patients with a breast cancer affected sister and no BRCA1\u002f2 mutations. The contro...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e- PDQ\u00ae Cancer Genetics Editorial Board. PDQ Genetics of Breast and Gynecologic Cancers. Bethesda, MD: National Cancer Institute. Updated 30\u002f03\u002f2017. Available at: https:\u002f\u002fwww.cancer.gov\u002ftypes\u002fbreast\u002fh...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e- Foulkes, W. D. (2008). Inherited Susceptibility to Common Cancers. The New England Journal of Medicine, 359(20), 2143\u20132153. https:\u002f\u002fdoi.org\u002f10.1056\u002fNEJMra0802968...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e- Nielsen, F. C., van Overeem Hansen, T., & S\u00f8rensen, C. S. (2016). Hereditary breast and ovarian cancer: new genes in confined pathways. Nature Reviews Cancer, 16(9), 599\u2013612. https:\u002f\u002fdoi.org\u002f10.1038...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e- Michailidou, K., Hall, P., Gonzalez-Neira, A., Ghoussaini, M., Dennis, J., Milne, R. L., \u2026 Easton, D. F. (2013). Large-scale genotyping identifies 41 new loci associated with breast cancer risk. Nat...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e- Rudolph, A., Chang-claude, J., & Schmidt, M. K. (2016). Gene \u2013 environment interaction and risk of breast cancer. British Journal of Cancer, 114(2), 125\u2013133. https:\u002f\u002fdoi.org\u002f10.1038\u002fbjc.2015.439...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e- Sakoda, L. C., Jorgenson, E., & Witte, J. S. (2013). Turning of COGS moves forward findings for hormonally mediated cancers. Nature Genetics, 45(4), 345\u20138. https:\u002f\u002fdoi.org\u002f10.1038\u002fng.2587...","\u003cb\u003eFamilial breast cancer\u003c\u002fb\u003e\u003cbr\u003e- Sinilnikova, O. M., Dondon, M.-G., Eon-Marchais, S., Damiola, F., Barjhoux, L., Marcou, M., \u2026 Andrieu, N. (2016). GENESIS: a French national resource to study the missing heritability of breast canc...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003eI will try to explain what I know about heritability by using human height as example phenotype. This will be helpful not only because it is very tangible, but also because it is considered a \"model\" ...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003e$$\\sigma^2_P$$ includes the total observed variation, usually excluding variation due to known fixed factors and covariates (age, sex, cohort...)....","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003eHeritability is a term that aims to describe the proportion of the phenotypic variance that is explained by the genotype. The heritability of height was assessed more than a century ago, when Galton a...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003e* Narrow-sense heritability $$h^2$$: heritability is the proportion of the phenotypic variance that is explained by additive genetic effects:...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003e  which accounts for the genetic variability of additive genetic effects (A, also referred to as the breeding value); of dominance genetic effects (D, interactions between alleles at the same locus); ...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003eNarrow-sense heritability is the estimate that applies in most of situations, and hence, the most widely used. This is because non-additive effects such as dominance do not contribute to genotypic res...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003eHeritability is calculated from empirical data of related individuals, where we compare the expected and the observed resemblance. To estimate it, we need to calculate both the variance in additive ge...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003eWhen it is possible, it is estimated in simple and balanced experiments. For example, by regressing the offspring on parental phenotypes, the correlation of full or half siblings, and the difference i...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003eIn the case of height, 80% of the intra-population variability in height is due to genetic factors ($$h^2$$ = 0.8) (Visscher, 2008). Three studies with a total sample size of 63k individuals (14k + 16...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003eOf the main suspects of missing heritability, variants not covered by standard experiment designs are regarded as the most likely cause. Although candidates like structural variants have been proposed...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003e- Bahcall, O. Common variation and heritability estimates for breast, ovarian and prostate cancers. Nature iCOGS. Retrieved from https:\u002f\u002fdoi:10.1038\u002fngicogs.1...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003e- Manolio, T. A., Collins, F. S., Cox, N. J., Goldstein, D. B., Hindorff, L. A., Hunter, D. J., \u2026 Visscher, P. M. (2009). Finding the missing heritability of complex diseases. Nature, 461(7265), 747\u20137...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003e- Visscher, P. M. (2008). Sizing up human height variation. Nature Genetics, 40(5), 489\u201390. https:\u002f\u002fdoi.org\u002f10.1038\u002fng0508-489...","\u003cb\u003eHeritability\u003c\u002fb\u003e\u003cbr\u003e- Visscher, P. M., Hill, W. G., & Wray, N. R. (2008). Heritability in the genomics era--concepts and misconceptions. Nature Reviews. Genetics, 9(4), 255\u201366. https:\u002f\u002fdoi.org\u002f10.1038\u002fnrg2322...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eHere we a...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eHere we address the problem of looking for similar, but not necessarily equal items. This is frequently the case of looking for related documents. For example, all the versions of the same news articl...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eIf we wanted to find equal documents, finding an efficient solution would be relatively straightforward: hash them and see which ones fall in the same bucket. In this case, we have to define a similar...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eThe Jaccard similarity between two sets $$A$$ and $$B$$ is defined by looking at the relative size of their intersection:...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eCosine distance is used in spaces that have dimensions, and hence we can think of points as non-zero vectors. In this case, the distance between two vectors $$x$$ and $$y$$ would be the angle between ...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eEdit distance can be used when points are strings. The distance between two strings $$x$$ and $$y$$ will be the smallest number of single-character insertions and deletions that would convert $$x$$ in...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eIn this problem, we will start from $$N$$ items (documents, images, etc.) which we represent in a $$D$$-dimensional space. An exhaustive approach is calculating all pairwise distances, but that would ...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003e1. Shingling: convert documents into vectors\u002fsets....","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eThe first step is representing the documents as sets. A $$k$$-shingle of a document is the set of any substring of length $$k$$ that appears in the document. Or, instead of directly using substrings a...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eThe choice of $$k$$ is not trivial, and mostly depends on how long are usually the documents we are dealing with. Hence, $$k$$ must be chosen so that the probability of any given shingle appearing in ...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eThere are two kind of special elements in the text that must be dealt with: white spaces - tabs, spaces... - and _stop words_ - the most common words. Stop words are specially interesting because, whi...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003e(Sets contain unique, unordered elements; multisets or bags are generalisations of sets which may contain several instances of the same element.)...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eIn the exhaustive approach, we could already take the shingle-sets and calculate the Jaccard index between all pairs, still a problem with $$O(N^2)$$ complexity. Additionally, shingle-sets are large. ...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eWe will do so through a process called minhashing. To understand it, we can imagine all our shingle-sets represented it as a characteristic matrix $$C$$, although our data most probably won't be repre...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003e1. Generate a random permutation of the rows of $$C$$....","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eWe build a new representation of our set $$S$$ as a vector $$[h_1(S), h_2(S), ..., h_n(S)]$$. This is the only representation we will use to study similarity. Minhashing exploits an interesting proper...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eIn practice, permuting a huge matrix is very time consuming, and it is not feasible in real-world applications. Instead, $$n$$ hash functions $$h_i$$ are selected, which are applied on the row number....","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eWe calculate $$M$$, which has a complexity of $$N$$. We will pick the documents that are similar enough on the M matrix as candidates to similar documents. Then, we will compute exactly the Jaccard si...","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eWe do that by binning the rows into bands, and the compare the documents inside each band. We will get how many bands are exactly the same between two documents....","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003eDepending on the choice of $$r$$ and $$t$$, we modulate the curve. Hence we get to the sensitivity of our curve....","\u003cb\u003eFinding similar documents\u003c\u002fb\u003e\u003cbr\u003e- Leskovec, J., Rajaraman, A., & Ullman, J. D. (2014). Mining of Massive Datasets (3rd ed.). Cambridge University Press. Retrieved from http:\u002f\u002fi.stanford.edu\u002f~ullman\u002fmmdsn.html...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003eUnderstanding how exposures, such as gene expression, cause complex phenotypes is a key question in biology. While randomized controlled trials are the gold standard for establishing causality, their ...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e\u003e \ud83d\udca1 **Randomized controlled trials** (RCTs) can establish causality even in the presence of variables that are not under experimental control. The key procedure involves randomly assigning the treatme...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003eMendelian Randomization (MR) studies the causal effect of an exposure on an outcome using genetic variants (SNPs). When certain assumptions are met ([Key assumptions and how to verify them](#key-assum...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003eOur goal is to precisely estimate the effect of an exposure on a trait. However, the presence of confounders that are either unobserved or difficult to measure makes this impossible. An instrument, su...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003eIn mathematical terms, we aim to estimate the effect of an exposure $$X$$ on an outcome $$Y$$using an instrument $$Z$$. Since $$Z$$ is a SNP, it will usually take values in 0, 1 and 2 (the number of m...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e1. Estimate the relation between the instrument and the exposure: $$X=\\beta_{ZX}Z+\\varepsilon$$...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003eThe estimated causal effect $$\\beta_{\\hat{X}Y}$$ is unconfounded! This is usually performed via [**two-stage least squares**](https:\u002f\u002fmr-dictionary.mrcieu.ac.uk\u002fterm\u002ftsls\u002f). Alternatively, we can obta...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e1. _Relevance_: the SNP is associated with the exposure....","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003eOther common, but optional, assumptions are _linearity_ and _homogeneity_ (the effect does not vary across strata in the population, like SNP levels or sex)....","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003eAlthough these assumptions are sometimes violated, we have ways to detect such cases:...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e1. It can be violated when the SNP is a weak instrument. It can be measured using (Cragg-Donald) F-statistic $$\\left( \\frac {n-m-1} {m} \\right) \\left( \\frac {R^2} {1-R^2}\\right)$$ where $$n$$ is the n...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e2. Common violations include [assortative mating](https:\u002f\u002fmr-dictionary.mrcieu.ac.uk\u002fterm\u002fassortative-mating\u002f), [population structure](https:\u002f\u002fmr-dictionary.mrcieu.ac.uk\u002fterm\u002fpop-strat\u002f) and [dynastic...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e3. [(Horizontal) pleiotropy](https:\u002f\u002fmr-dictionary.mrcieu.ac.uk\u002fterm\u002fhorizontal-pleiotropy\u002f) and linkage with other causal genes are common violations. When using multiple instruments, it can be assum...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e  - Two-sample: the SNP-exposure relationship is measured on a set of samples, and the exposure-outcome on another one....","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e  - Summary-level: as an attention note, all summary statistics must come from ancestry-matched samples....","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e  - Multiple SNPs: this can address the weak association that individual SNPs might have with the trait. Notably, the dependencies between the SNPs (linkage disequilibrium) can produce trouble. The SN...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e**Exposure:** it can be simple (e.g., gene expression), or complex (e.g., body mas index)....","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e**Instruments:** we will use as many SNPs associated to the exposure of interest as possible (e.g., polygenic score). This will capture the full genetic architecture of the trait as well as violations...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003eIn the clinical setting, our interest is learning about \\*modifiable **\\***causes of disease, i.e., those that can be treated....","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e**Exposure:** typically, a protein, since it needs to be targetable by a small molecule, a monoclonal antibody, etc. The expectation is that it will affect a complex biomarker through _vertical_ pleio...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e**Instruments:** SNPs affecting the gene\u002fprotein of interest, often _cis_-pQTL. _Trans_-pQTL can also be used, but they are more likely to partake in horizontal pleiotropy....","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003eWe can use multivariable MR to get tissue-specific exposures, and partition the effect on the phenotype. Two disclaimers are in order: GWAS hits often colocalize with eQTLs in multiple tissues; and ex...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003eMultivariable MR studies the causal impact of multiple exposures. This allows to consider complex causal pathways, even those involving mediators....","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e- Hartley, A. E., Power, G. M., Sanderson, E., & Smith, G. D. (2022). A Guide for Understanding and Designing Mendelian Randomization Studies in the Musculoskeletal Field. In JBMR Plus (Vol. 6, Issue ...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e- Burgess, S., Mason, A. M., Grant, A. J., Slob, E. A. W., Gkatzionis, A., Zuber, V., Patel, A., Tian, H., Liu, C., Haynes, W. G., Hovingh, G. K., Knudsen, L. B., Whittaker, J. C., & Gill, D. (2023). ...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e- Teumer, A. (2018). Common Methods for Performing Mendelian Randomization. In Frontiers in Cardiovascular Medicine (Vol. 5). Frontiers Media SA. https:\u002f\u002fdoi.org\u002f10.3389\u002ffcvm.2018.00051...","\u003cb\u003eMendelian randomization\u003c\u002fb\u003e\u003cbr\u003e- Holmes, M. V., Richardson, T. G., Ference, B. A., Davies, N. M., & Davey Smith, G. (2021). Integrating genomics with biomarkers and therapeutic targets to invigorate cardiovascular drug development....","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eThe commonly taught approach to AI is **model-centric**: the data is assumed to be fixed and perfect, and the challenge is producing the best model. However this contrast with the real world applicati...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e- Algorithms that understand the data and leverage that to improve the models. E.g., train on easy data first (curriculum learning)....","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e- Given a dataset, produce the best model...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e- Given a model, improve the training set...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eA motivating example is the kNN algorithm. It has no loss function, the prediction is simply a majority vote, and the quality of the prediction depends on the quality of the data. Another one is DALL-...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eNote that data-centric AI is not about hand-picking good datapoints or getting more data. Some examples are:...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e- Outlier detection and removal: handling abnormal examples...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eEach training example in our dataset consists on a feature vector $$\\mathbf x$$, and an observed (noisy) label $$\\tilde y$$. Note that this label might not equal the latent true label $$y^\\ast$$. This...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e1. Correctable mis-classification: $$\\tilde y$$ is wrong, but there is only one $$y^\\ast$$....","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eWe will tackle the first case using the **confident learning** framework. This label noise can occur in three ways:...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e- Uniform: $$p\\left(\\tilde{y}=i \\mid y^*=j\\right)=\\epsilon, \\forall i \\neq j$$...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eThe first case can be by-passed by good modeling, given enough data. However, it is hardly realistic. On the other hand, second form is a compromise between what is realistic and what is tractable, an...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e\u003caside\u003e...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e\ud83d\udca1 **Confident learning** is a data-centric and model-agnostic framework. In other words, it allows to use **any** model\u2019s predicted probability to find label errors. It is implemented in the Python li...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eConfident learning aims to estimate $$p\\left(\\tilde{y} \\mid y^\\ast \\right)$$ and $$p\\left(y^\\ast\\right)$$. It does so in one step by estimating the joint distribution $$p\\left(\\tilde{y} , y^\\ast \\righ...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e\u003caside\u003e...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e\ud83d\udca1 A naive way to find label errors is to sort by the loss function (assuming no overfitting), i.e., the examples with the highest loss are likely to be label errors. However, how do we pick an appropr...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eIn order to estimate $$p\\left(\\tilde{y}, y^*\\right)$$, confident learning requires two inputs: the noisy labels $$\\tilde y$$ and the (out-of-sample) predicted probabilities $$\\hat p\\left(\\tilde{y} = i...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eThe difficulty lies in assigning latent labels to the examples. How to know which examples are mislabeled? The key insight is finding a threshold for the algorithm\u2019s confidence on the prediction. That...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eFor each example in the **out-of-sample** data, we will take the highest probability class, and compare it to its respective threshold $$t_j$$. If the model is not that confident in the class, we will...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e\u003caside\u003e...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e\ud83d\udca1 This computation is robust to outliers: examples that are not confidently predicted for any of the classes will be dropped from the contingency table....","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e1. Estimate noise via counting...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eOur ultimate goal is to estimate the joint distribution of true and noisy labels, $$\\boldsymbol{ Q_{\\tilde y, y^\\ast}}$$....","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eThe first step is computing a **confident joint** table $$\\boldsymbol{ C_{\\tilde y, y^\\ast} } \\in \\mathbf N^{m \\times m}$$. Diagonal elements count likely correct labels, and non-diagonals count likel...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e\\boldsymbol{C}_{\\tilde{y}, y^*}[i][j]:=\\left|\\hat{\\boldsymbol{X}}_{\\tilde{y}=i, y^*=j}\\right|...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eThe next step is using $$\\boldsymbol{ C_{\\tilde y, y^\\ast} }$$ to estimate $$\\boldsymbol{ Q_{\\tilde y, y^\\ast} }$$:...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eGiven $$\\boldsymbol{ C_{\\tilde y, y^\\ast} }$$ and $$\\boldsymbol{ Q_{\\tilde y, y^\\ast} }$$, any rank and prune approach can be used to clean the data....","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eA data-related issue in machine learning is **selection bias**. This happens when the training and the real-world distributions do not match. This can happen for several reasons....","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e| **Reason**                                          | **Validation set**         |...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eSelection bias can lead to **spurious correlations**, in which our models pick up \u201cshortcuts\u201d, rather than important features. To avoid this, we will pick the **validation data** which most closely re...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eSay we want to achieve 95% classification accuracy. What is the required sample size? To find out, we can train our model on increasingly lager subsamples to study how performance improves, then extra...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eOur labels will often come from a team of annotators. Hence, each training example might have multiple, sometimes contradicting annotations. Moreover, not every annotator sees every sample. We can dec...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e- Consensus label: pick the single, best label...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eConfidence score: fraction of annotators agreeing on the majority label. Out of those who emitted a label for that training example....","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eQuality of the annotator: fraction of the annotations that match the majority label....","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eProblems: it won\u2019t handle well examples with a single annotation examples (low confidence); it does not account for ties, or for the quality of the annotators....","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eSolution: train a classifier, which predicts each class, and treat it as a separate annotator. We learn on the majority vote annotator. This solves:...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e- Ties: are broken by the classifier...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eSolution: learn the probability distribution of what the true label should be given the example and all the annotations. This will be a weighted average of all the annotations from both the annotators...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eThe focus or data-centric ML is to improve models by improving the data. Crucially, this requires identifying the relevant evaluation metric(s) to improve. Such evaluation metrics (or, simply, metrics...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eIn practice, we will compute this metric for multiple unseen examples, then aggregate them by:...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e- Averaging the metrics obtained over all the examples...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e\u003e \ud83d\udca1 Invest as much time thinking about model evaluation as about the models themselves. It has **huge** impact in real world applications. I list some common pitfalls below....","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e- Data leakage: we fail to use truly held-out data. This happens, for instance when we use data from multiple data sources which contain the same training examples....","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eA **data slice** is a subset of the data that shares a common characteristic (a.k.a., cohort, subpopulation or subgroup), like race, gender, age or socioeconomics. Although it might be tempting to exc...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eIdeally, model predictions should not change across slices. When that does not happen, we can tackle that in different ways:...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003e1. Use a more flexible model, that can capture more complex relationships...","\u003cb\u003eData-centric machine learning\u003c\u002fb\u003e\u003cbr\u003eIn any way, the first step is to find out the subpopulations on which we are underperforming....","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e\u003e Note: not _everything_ in...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eEvery Python object has three builtin properties (a reference, a class, and a refcount) as well as additional, class-specific properties....","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eA **reference** is a pointer, a way to access the memory address that stores the object. It can be associated to a name, or an element in a collection:...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003ea = 1...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e4342270592...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eA **class** is the type of the object (e.g., a float, or a string). Each object contains a pointer to its class, [as we will see below](#the-two-dictionaries-underlying-an-object). We can retrieve an ...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eThe **refcount** is a counter that keeps track of how many references point to an object. Its value gets increased by 1 when, for instance, an object gets assigned to a new name. It gets decreased by ...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e2...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e4294967295...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eObjects have additional properties and methods that encode their state and behaviors. For instance, the `float` class has an additional property that stores the numerical value, as well as multiple me...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eObjects are first-class citizens in Python, meaning they can be treated like any other value. In other words, they can:...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eAs mentioned above, the assignment operator `=` does not copy objects, only references. If we need to copy an object, we need to use the `copy` module. There are two types of copies: shallow and deep....","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eShallow copies, made with `copy.copy`, duplicate the object. However any reference it stores will just get copied as a reference, i.e., the referenced object will not be duplicated....","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003ex = [1, 2, [3, 4]]...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003ex = [1, 2, [3, 4]]...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003ePython allows us to define our own classes using the `class` keyword. New objects are instantiated using the class name. Let's see an example:...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e    def __init__(self, species, weight):...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e    def set_favorite(self, flag):...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eIn other languages, a class' attributes can be set as public (accessible to everyone), protected (only accessible within the class and subclasses) or as private (only accessible within the class). Thi...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003ePython emulates protected and private attributes by prepending one or two underscores respectively. In our `Animal` example, `Animal.__favorite` is a private attribute:...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eFalse...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eTrue...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eUnderlying every object there are two dictionaries. They are accessible, respectively, using `{instance}.__dict__` and `{Class}.__dict__`. The first one is an instance-specific dictionary containing i...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eSimilarly, each class has its own dictionary, containing the data and functions used by all instances (class' methods, attributes defined at the class level, etc.):...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eFor instance, this is where the `Animal.eat()` method lives. This dictionary is shared by all the instances, which is why every non-static method requires the instance to be passed as the first argume...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eThe instance's dictionary keeps the class flexible, allowing to add new attributes at any time:...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e    def __init__(self, species, weight):...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e**Serialization** is the process of converting a Python object into a file format that can be used to reconstruct the object later. This allows us to store objects, make them persistent across executi...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003eimport json...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e    def __eq__(self, other):...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e        name    = dct[\"name\"]...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e# serialize...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e# deserialize...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e# serialize or \"pickle\"...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e# deserialize or \"unpickle\"...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython objects\u003c\u002fb\u003e\u003cbr\u003e- D. Beazley, [Advanced Python Mastery](https:\u002f\u002fgithub.com\u002fdabeaz-course\u002fpython-mastery)...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003eA language is **statically typed** when variables have types, i.e., the type of the variables are checked before execution (usually at compilation). In contrast, in **dynamically typed** languages var...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003eNo programming language is either interpreted or compiled. A language is just a set of instructions to tell a computer how to perform tasks. And this language can be implemented in different ways. For...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e1. \"Compile\" the source code into a Python-specific lower level code (`*.pyc`, stored in `__pycache__`), called _bytecode_....","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e\u003e Step 1's \"compilation\" is qualitatively different from the compilation of so-called compiled languages. For starters compiling a C code results in a standalone executable. Another difference is that...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e- Numeric Types (`int`, `float`, `complex`)...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003ePython has two kinds of data types, **mutable** and **immutable**, which respectively can and cannot be modified after being created. Examples of mutable data types are lists, dictionaries and sets; e...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e# we change the value of x. since...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003ex += 1...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e# we change the value of x...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003eMutability also has implications on [memory allocation](#memory-management-in-python). Python knows at runtime how much memory an immutable data type requires. However, the memory requirements of muta...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003eA **namespace** is a mapping from names to objects. In fact, underlying a namespace there is a dictionary: its keys are symbolic names (e.g., `x`) and its values are the object they reference (e.g., a...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e- **Builtin** namespaces: it is created when the interpreter starts up. It contain names such as `print`, `int` or `len`....","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e- **Global** namespaces: _The_ global namespace contains every name created at the main level of the program. This dictionary can be examined using `globals()`. But, _other_ global namespaces are poss...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e- **Local** namespaces: one is created every time a function is called, and is \"forgotten\" when it terminates. This dictionary can be examined using `locals()`....","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e- **Enclosed** namespaces: when a function calls another function, the child has access to its parent's namespace....","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003eNamespaces are related to scopes, which are the parts of the code in which a specific set of namespaces can be accessed. When a Python needs to lookup a name, if resolves it by examining the namespace...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e\t# use foo defined within f_enclosed...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e\t\t# use foo defined within f_local...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e\t# f_local's foo is gone...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e\t\t# modifies the foo from the...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e\t# f_enclosed's foo is changed even...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e\t\t# modifies the foo from the...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e\t# f_enclosed's remains unchanged...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003efoo = \"original\"...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003eprint(f\"foo = {foo}\")...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003eIn CPython, all the objects live in a _private_ [heap]({% post_url 2024-02-10-hardware %}#memory-allocation). Memory management is handled exclusively by the Python memory manager. In other words, and...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003eWhen an object is created, the memory manager allocates some memory for it in the heap, and its reference is stored in the relevant namespace....","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003eConversely, the garbage collector is an algorithm that deallocates objects when they are no longer needed. The main mechanism uses the [reference count]({% post_url 2024-01-07-python-objects %}#refcou...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003eThe global interpreter lock (GIL) is a mechanism to make CPython's thread safe, by only allows one thread to execute Python bytecode at a time. This vastly simplifies CPython's implementation and writ...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e1. Multiprocessing, i.e., launching multiple Python processes, each with their own interpreter, memory, and GIL....","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003eA Python module is simply a file containing Python functions, classes, constants and runnable code. When we want to use them, we need to _import_ the module using the `import` statement. For instance:...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e1. Built-in modules: written in C, and part of the Python executable....","\u003cb\u003eThe Basics of Python\u003c\u002fb\u003e\u003cbr\u003e- [StackOverflow: If Python is interpreted, what are .pyc files?](https:\u002f\u002fstackoverflow.com\u002fquestions\u002f2998215\u002fif-python-is-interpreted-what-are-pyc-files)...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e# The inner workings of diction...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eDictionaries and sets are ideal data structures to collect items when 1. the data has no intrinsic order; and 2. elements can be retrieved using _keys_, i.e., so-called _hashable_ objects (further des...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eHash maps rely on the key objects implementing a hash method (`.__hash__()`). This function maps each object to a fixed-byte integer. When we apply the `hash()` function to the object, its hash method...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003ehash((1))      # 1...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003ehash((1., 1.)) # 8389048192121911274...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e2...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e14...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eIf the number of _empty_ buckets is large enough, a new key can be mapped to an empty bucket with high probability. (Empty buckets contain a `NULL` value.) In that case, we will simply store the key-v...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eHowever, it is possible that the bucket is already occupied. In that case, Python will first check if the keys are equal. That is why 1. we store the key object in the bucket; and 2. the key object ne...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eWhen a value is deleted, we cannot simply overwrite it with a `NULL`. That would make the bucket identical to a \"virgin\" bucket, and potentially disrupt the probing strategy, leading to inconsistent r...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e**Note:** User-defined classes are hashable by default, even if they don't implement `__hash__`, `__eq__` or `__cmp__`. The hash is computed using the object's `id()`, and all objects compare unequal....","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eUnderstanding what underlies dictionaries and sets allows us to estimate the time complexity of the different operations....","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e**Lookup**: given a key, in the vast majority of cases a lookup is done in $$O(1)$$. The actual time depends on how fast the hash function is. Collisions are the main hurdle to lookup: in the worst ca...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e**Insertion**: for similar reasons, the amortized time complexity is $$O(1)$$ and the worst case is $$O(n)$$....","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e**Deletion**: for similar reasons, the amortized time complexity is $$O(1)$$ and the worst case is $$O(n)$$....","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e**Resizing**: Python doubles the capacity of a dictionary when it becomes 2\u002f3 full. Similarly, the capacity of a set gets quadrupled when it becomes 2\u002f3 full. When such a thing happens, all key-value ...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eclass Dictionary:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e    \"\"\"...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e        \"\"\"...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e    def __setitem__(self, key: Hashable, value: Any) -\u003e None:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e        Parameters:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e        Returns:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e    def __getitem__(self, key: Hashable) -\u003e Any:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e        Raises:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e    def __contains__(self, key: Hashable) -\u003e bool:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e        Parameters:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e        Returns:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e        - None...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e    def __resize_check(self) -\u003e None:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e        Returns:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e        # reinsert all existing key-value pairs...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e        self.__size = new_size...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e    def __find_key_bucket(self, key: Hashable) -\u003e int:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e        Raises:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e            # stop once we have checked all buckets...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e            if isinstance(self.__buckets[idx], tuple):...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e            idx += 1...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e# 75% is full, which will trigger a resizing...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003emy_dict[140] = \"d\"...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003emy_dict[1] = 2...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003edel my_dict[1]...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003emy_dict[1] = \"x\"...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eSince Python 3.6, Python dictionaries preserve insertion order, i.e., the items are printed in the same order in which they were inserted in the dictionary:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eAfter Python 3.10, there are three ways of merging two dictionaries. Two of them are equivalent: unpacking using the `**` operator and the merge operator `|`:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eAn alternative is `dict.update()`, wich merges the dictionaries in place, updating the values when a key is shared:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eThe [`dict.setdefault`](https:\u002f\u002fdocs.python.org\u002f3.8\u002flibrary\u002fstdtypes.html#dict.setdefault) method is useful to assign a value to a key if and only if the key is missing:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eprint(f\"Number of carrots: {ingredients['carrots']}\")...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eThe [`collections.defaultdict`](https:\u002f\u002fdocs.python.org\u002f3\u002flibrary\u002fcollections.html#collections.defaultdict) goes one step beyond. They are a good replacement for dictionaries when there is a unique de...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003efor ingredient, amount in ingredients.items():...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eprint(ingredients_dd)...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eThe `collections.Counter` is a type of dictionary specialized in counting objects, i.e., the values are integers. It can be initialized from an existing dictionary:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003eWhen we have two lists of the same length, we can quickly combine them using `zip`:...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython dictionaries\u003c\u002fb\u003e\u003cbr\u003e- D. Beazley, [Advanced Python Mastery](https:\u002f\u002fgithub.com\u002fdabeaz-course\u002fpython-mastery)...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e[Similarly to the computer's memory]({% post_url 2024-02-10-hardware %}), lists and tuples can be visualized as a sequence of equally-sized buckets. Each bucket can store a fixed-length integer (e.g.,...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e- Lists are mutable: we can keep adding and removing items to the buckets. Hence, sometimes we might need to store more than $$N - 1 $$ elements originally requested. That is why they are stored in so...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e- Tuples, on the other hand, are immutable. Hence, they are supported by _static_ arrays, which cannot be resized. Hence, tuples only take up the strictly required memory, making them more lightweight...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e**Lookup**: since the buckets in the array are equally-sized and consecutive, we can quickly retrieve any item by knowing where the array starts and the index of its bucket. For instance, if our array...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e**Search**: if we need to find a particular object in an unsorted array, we need to perform a [linear search](https:\u002f\u002fen.wikipedia.org\u002fwiki\u002fLinear_search). This algorithm has a complexity $$O(n)$$. If...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e**Sort**: Python uses [Timsort](https:\u002f\u002fen.wikipedia.org\u002fwiki\u002fTimsort), a combination of heuristics, and insertion and merge sort. Best case is $$O(n)$$, worst case is $$O(n \\log n)$$....","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e### Lists...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e**Insertion**: we can replace an existing element in $$O(1)$$. That is also the case in most insertions of a new element at the end using `append()`. However, when the list's array gets full (the wors...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e**Insertion**: though tuples are immutable, we can consider the combination of two tuples into a longer one as an insertion operation. If they have sizes $$m$$ and $$n$$, each item needs to be copied ...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003eThe [`list.sort`](https:\u002f\u002fdocs.python.org\u002f3\u002flibrary\u002fstdtypes.html#list.sort) method orders a list's elements in ascending order. It will work as long as the items have defined the `\u003c` comparison opera...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003eanimals = [...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003eWe can use unpacking to swap multiple of a list in place, without requiring additional temporary variables:...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003eIn some cases we might want to unpack a tuple whose length we don't know a priori. In such cases, we can use an starred expression, which will receive all the values that are not captured by another i...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e1 2 [] 3...","\u003cb\u003ePython lists and tuples\u003c\u002fb\u003e\u003cbr\u003e- D. Beazley, [Advanced Python Mastery](https:\u002f\u002fgithub.com\u002fdabeaz-course\u002fpython-mastery)...","\u003cb\u003ePython functions\u003c\u002fb\u003e\u003cbr\u003e# Function's argu...","\u003cb\u003ePython functions\u003c\u002fb\u003e\u003cbr\u003eThe distiction between mutable and immutable datatypes has implications when they are passed to functions as arguments. When an immutable datatype is passed, Python creates a copy and assigns it to a ...","\u003cb\u003ePython functions\u003c\u002fb\u003e\u003cbr\u003eb = 8...","\u003cb\u003ePython functions\u003c\u002fb\u003e\u003cbr\u003eSometimes we might define some default value for a function's arguments. However it is often not a good idea to use mutable datatypes as a default. The default object is only created once, leading to ...","\u003cb\u003ePython functions\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003ePython functions\u003c\u002fb\u003e\u003cbr\u003eHey There...","\u003cb\u003ePython functions\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePython functions\u003c\u002fb\u003e\u003cbr\u003eAs Python objects, functions are first-class citizens, which unlocks several useful features, like closures and decorators....","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e# The inner workings of NumPy arrays...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003eThe main selling point of NumPy is the speed up in computations it offers. However, to understand that, we need to first understand the underpinnings of the NumPy array, or `ndarray`. The `ndarray` is...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e# Python references - which, as we will see soon,...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003enp.array([int, float, str])...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003eThe **metadata** includes important information about the data buffer. We can access the metadata like this:...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e 'version': 3}...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e# we sequentially iterate the...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003earray([5, 7, 9])...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003eFirst, Python's native data structures are highly **fragmented**. This severely hampers the prefetcher, and [cache misses]({% post_url 2024-02-10-hardware %}#cache-and-prefetching) are common. In othe...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003eSecond, Python is **dynamically** typed. This means that every operation between two numbers becomes a complex interaction between two heavy data structures. Internally, Python needs to find out the t...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003eVectorization has another meaning in hardware. Specifically, it refers to SIMD, the ability of the CPU to [handle multiple numbers in a single instruction]({% post_url 2024-02-10-hardware %}#registers...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003eBy default, `ndarrays` store matrices in a row-major order, that is, as a concatenation of the rows of the matrix. In other words, the elements from the same row live close (sharing cache lines), but ...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e# the default order is \"C\",...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e# time row operation...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e# time column operation...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003eConsistenly, shifting to column-major order (`order = \"F\"`) produces the opposite result.Carefully considering the operations we will be carrying out can have a major impact....","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003eNumPy introduced an important but tricky concept: data _views_. A views is just a new way to access the data buffer of an existing `ndarray`, with different metadata. Some operations produce views, li...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003ey = x[:2]...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003eCasting is the conversion of data from one type into another. The simplest form of casting is simply changing the type of an `ndarray`:...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003eassert y.base is None...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003eWe can explicitly trigger a reinterpretation of the data buffer under another type using `ndarray.view()`. Note that produces a view, not a re-casting of the original `ndarray`. Let's see an example:...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e- M. Gorelick & I. Ozsvald, High Performance Python: Practical Performant Programming for Humans. Chapter 5. Matrix and Vector Computation....","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e  - [The limits of Python vectorization as a performance technique](https:\u002f\u002fpythonspeed.com\u002farticles\u002fvectorization-python-alternatives\u002f)...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e  - [How vectorization speeds up your Python code](https:\u002f\u002fpythonspeed.com\u002farticles\u002fvectorization-python\u002f)...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e  - [Massive memory overhead: Numbers in Python and how NumPy helps](https:\u002f\u002fpythonspeed.com\u002farticles\u002fpython-integers-memory\u002f)...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e- [What scientists must know about hardware to write fast code](https:\u002f\u002fviralinstruction.com\u002fposts\u002fhardware\u002f)...","\u003cb\u003eVectors and matrices in Python\u003c\u002fb\u003e\u003cbr\u003e- [Scipy lecture notes: Advanced NumPy](https:\u002f\u002fscipy-lectures.org\u002fadvanced\u002fadvanced_numpy\u002f)...","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003eIn plain terms,...","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003eIn plain terms, the **CPU** is the part of the computer that carries out the computations themselves. It does so in a stream of discrete operations, called _CPU instructions_. Roughly, one instruction...","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003eThe **RAM** is the (temporary) memory of the computer, where the data lives. We can picture it as a grid of buckets, each of which can contain 1 byte of information. (From now on, I will use the terms...","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003e- The buckets are arranged into rows of 64, called _cache lines_....","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003eOne byte, 8 bits, can take 256 different values. In consequence, it can store an integer from 0 to 255. If we need to store a larger value, we need to use multiple bytes....","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003e- Load data...","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003eWhen we execute a program, it interacts with the operating systems kernel to handle its resources. The memory assigned to a program is split into two components: the _stack_ and the _heap_. They work ...","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003eThe **stack** is the memory that serves as scratch space for the program. It handles function calls, local variables and context. It appropriately works as a stack, as a Last-In-First-Out (LIFO) struc...","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003eThe **heap** is the memory set aside for memory allocation: when a program needs more memory, it places a request to the kernel, which will _allocate_ the requested amount from the heap, i.e., reserve...","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003eReading a byte directly from RAM takes around 500 CPU cycles. However, this can be sped up by copying the data to the CPU's cache, which is closer to the CPU and faster. However, the cache can only ho...","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003eCPUs have a component, called _prefetcher_, which tries to mitigate cache misses. To achieve that, it actively tries to predict which pieces of data the CPU will need in the near future, and preemptiv...","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003eThe registers are the small sized slots on which the CPU acts on. Traditionally they had 8 bytes in size, just enough for one 64-bit integer or float. For instance, adding two such numbers requires th...","\u003cb\u003eHow computers work\u003c\u002fb\u003e\u003cbr\u003e- [What scientists must know about hardware to write fast code](https:\u002f\u002fviralinstruction.com\u002fposts\u002fhardware\u002f)...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e# Strings...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e# Strings...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eWhile Python offers multiple ways of formatting strings (i.e., combining predefined text and variables), [F-strings](https:\u002f\u002fdocs.python.org\u002f3\u002ftutorial\u002finputoutput.html#formatted-string-literals) are ...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eThe [`enumerate`](https:\u002f\u002fdocs.python.org\u002f3\u002flibrary\u002ffunctions.html#enumerate) function creates a lazy generator over an iterable that will return a tuple (index, item). It can take a second parameter,...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eThe [`zip`](https:\u002f\u002fdocs.python.org\u002f3\u002flibrary\u002ffunctions.html#zip) function combines two or more iterators, generating a lazy generator which yields the next item from each. It is particularly useful t...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003efor number, square in zip(numbers, squared):...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e2 2...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eThe [`list.sort`](https:\u002f\u002fdocs.python.org\u002f3\u002flibrary\u002fstdtypes.html#list.sort) method orders a list's elements in ascending order. It will work as long as the items have defined the `\u003c` comparison opera...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eanimals = [...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eThe [walrus operator](https:\u002f\u002fdocs.python.org\u002f3\u002freference\u002fexpressions.html#assignment-expressions) (`:=`) allows to assign variables in the middle of expressions:...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e    - y (int): The potential divisor....","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e(False, 1)...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eWe can use underscores `_` as visual separators between any pair of digits in integers, floats or complex numbers:...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eMost decimal floating-point numbers cannot be represented as binary floating-point numbers. Instead, computers just store an approximation. This behavior is not evident by just asking Python to displa...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eIn this series, we have seen multiple examples in which the type of a variable is specified. For instance:...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eThe stdlib's [`typing`](https:\u002f\u002fdocs.python.org\u002f3\u002flibrary\u002ftyping.html) module gives many options to control type hints. (Widely used packages bring their own typing hints, like [numpy](https:\u002f\u002fnumpy.o...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eThe decorator `@typing.overload` allows to overload functions, that is, have a function behave differently depending on the argument type....","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e    ......","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003ePython is a dynamically typed language. Hence, typing hints are just, that, hints. However, we can use [mypy](https:\u002f\u002fgithub.com\u002fpython\u002fmypy) on our entire codebase to check that types are used correc...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eSome people are really concerned by performance. Their concern is such that they are willing to sacrifice code readability for minor gains in performance. Such people might get satisfaction from repla...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eThe `\u003e\u003e` and the `\u003c\u003c` operators shift the bit representation to the left and to the right, respectively. This can be used to quickly divide or multiply integers by powers of two:...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eThe `&` operator is the bitwise AND operator. When we use `&` between any integer and a 1, we are effectively cheching if the last bit is a 1 (odd) or a 0 (even):...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eThe `~` operator is the complement operator, which switches 1s by 0s and vice versa. Let's see it in action:...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eHandling exceptions with `try: ... except: ...` is a common in Python code. But there are some additional nuances:...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003eA context manager is a programming construct that makes it easy to allocate and release resources. It is useful to handle file operations, network connections or database transactions, when it is impo...","\u003cb\u003eQuirks of Python\u003c\u002fb\u003e\u003cbr\u003e- D. Beazley, [Advanced Python Mastery](https:\u002f\u002fgithub.com\u002fdabeaz-course\u002fpython-mastery)...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eDivide and conquer algorithms work by breaking down a problem into _two or more_ smaller subproblems of the same type. These subproblems are tackled recursively, until the subproblem is simple enough ...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eThe input of interval problems is a list of lists, each of which contains a pair `[start_i, end_i]` representing an interval. Typical questions revolve around how much they overlap with each other, or...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e**Note:** There are many corner cases, like no intervals, intervals which end and start at the same time or intervals that englobe other intervals. Make sure to think it through....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e**Note:** If the intervals are not sorted, the first step is _almost always_ **sorting them**, either by start or by end. This usually brings the time complexity to $$O(n \\log n)$$. In some cases we n...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eSorting consists on arranging the elements of an input array according to some criteria. There are multiple ways to sort an input, each offerintg different trade-offs:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e- Memory usage: _in-place_ approaches sort the items in place, without using extra space....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e| Algorithm                        | Time complexity           | Space complexity |...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e        for j in range(len(x) - i):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    # recursively sort the two halves...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    merged = []...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    # since slicing forgives out of bounds starts...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    pivot = x[-1] # preferrable to modifying the input with x.pop()...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    higher = []...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e- [Sorting Out The Basics Behind Sorting Algorithms](https:\u002f\u002fmedium.com\u002fbasecs\u002fsorting-out-the-basics-behind-sorting-algorithms-b0a032873add)...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eTraversing a linked list simply consists on passing through every element. We can do that starting from the head, following the pointer to the next node and so on....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eOften multiple pointers are needed in order to perform certain operations on the list, like reversing it or deleting an element in the middle....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    while curr:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e        if counter & 1:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eUsing two pointers that iterate the list at different speeds can help with multiple problems: finding the middle of a list, detecting cycles, or finding the element at a certain distance from the end....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eA very useful algorithm to know is how to iterate a BST in order, from the smallest to the largest value in the tree. It has a very compact recursive implementation:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e        root = stack.pop()...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eIn a depth-first traversal (DFT), given a starting node, we recursively visit each of its neighbors before moving to the next one. In a 2D grid, it would involve picking a direction, and following it ...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e1. When we visit a node, we push all of its neighbors. Hence, each frame in the stack is a node to visit....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e}...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    while stack:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eb...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e**Note:** Watch out for _cycles_. Without explicing handling, we might get stuck in infinite traversals. We can keep track of which nodes we have visited using a set, and exit early as soon as we re-v...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e**Note:** Some corner cases are the empty graph, graphs with one or two nodes, graphs with multiple components and graphs with cycles....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eIn a breadth-first traversal (BFT), given a starting node, we first visit its neighbors, then their neighbors, and so on....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eIn a 2D grid, it doesn't favour any direction. Instead, it looks like a water ripple....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e1. When we visit a node, we push all of its neighbors to the queue. As in DFT, each item is a node to visit....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003edef breadth_first_print(graph: dict[str, set[str]], seed: str) -\u003e None:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    while queue:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003ed...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eA topological sort (or _top sort_) is an algorithm whose input is a DAG, and whose output is an array such that every node appears after all the nodes that point at it. (Note that, in the presence of ...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e1. Compute the indegree of every node, store it in a hash map....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003ePut together, the time complexity of top sort is $$O(\\|V\\| + \\|E\\|)$$, and the space complexity, $$O(\\|V\\|)$$....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eAs for graph related problems, problems involving trees often require traversals, either [depth](#depth-first-traversal) or [breadth](#breadth-first-traversal) first. The same principles and data stru...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e- [Graph Algorithms for Technical Interviews - Full Course](https:\u002f\u002fwww.youtube.com\u002fwatch?v=tWVWeAqZ0WU)...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eThe two pointer approach can be used in problems involving searching, comparing and modifying elements in a sequence. A naive approach would involve two loops, and hence take $$O(n^2)$$ time. Instead,...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e**Note:** Some two pointer problems require the sequence to be sorted to move the pointers efficiently. For instance, to find the two elements that produce a sum, having a sorted array is key to know ...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e**Note:** Sometimes we need to iterate an $$m \\times n$$ table. While we can use two pointers for that, we can to with a single pointer $$i \\in [0, m \\times n)$$: `row = i \u002f\u002f n`, `col = i % n`....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eSliding window problems are a type of same direction pointer problems. They are optimization problems involving **contiguous** sequences (substrings, subarrays, etc.), particularly involving cumulativ...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e- The candidate solutions are built incrementally....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eSince solutions are built incrementally, backtracting they can be visualized as a **depth-first search** on a tree. At each node, the algorithm checks if it will lead to a valid solution. If the answe...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e**Note:** Because of the need to backtrack, a recursive implementation of the DFS is often more convenient, since undoing a step simply involves invoking `return`. A stack might require a more elabora...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eAs we will see in a few examples, the solution to a backtracking problem looks like this:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    for child in get_children(candidate):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eA famous application of backtracking is solving the [eight queens puzzle](https:\u002f\u002fen.wikipedia.org\u002fwiki\u002fEight_queens_puzzle):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e\u003e The eight queens puzzle is the problem of placing eight chess queens on an 8\u00d78 chessboard so that no two queens threaten each other; thus, a solution requires that no two queens share the same row, ...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003edef under_attack(row, col):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e        # check the diagonals...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e        return count + 1...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eboard = [[0, 0, 0, 1, 0, 0, 0, 0, 5],...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    for i in range(9):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e            for num in range(1, 10):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    for i in range(size):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eThe key to the problem is identifying the _trivially_ smallest input, the case for which the answer is trivially simple....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eRecursion is a technique in to solve problems which in turn depend on solving smaller subproblems. It permeates many other methods, like [backtracking](#backtracking-problems), [merge sort](#merge-sor...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e1. Definition of the **base case(s)**, the case(s) in which solving a problem is trivial, and a solution is provided, stopping the recursion....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eThe space complexity of recursion will be, at least, the length of the stack which accumulates all the function calls....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e**Note:** CPython's recursion limit is 1,000. This can limit to the depth of the problems we can tackle....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eIn DP, combining recursion and memoization is a powerful way to trade space complexity for time complexity. Specifically, since problems are overlapping, it is likely we are solving the same subproble...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eHere is a recipe for solving these problems (from [here](https:\u002f\u002fwww.youtube.com\u002fwatch?v=oBt53YbR9Kk)):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e1. Visualize the problem as a tree...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e- `m`: the average length of the elements of the input. For instance, if the input is a list, `m = len(input)`; it it is an integer, it is `m = input`. This will impact the height of the tree....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e**Brute force:** for every node, we have a `n` options. Usually, the time complexity of DP problems will be exponential, of $$O(n^m*k)$$, where $k$ is the complexity of a single recursive call. The me...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e**Memoized:** memoization reduces the branching factor by storing previous results. In other words, it trades time complexity for space complexity; usually both become polynomial....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e   1. Design the size of the table based on the inputs. Often the size of the table is one unit longer in each dimension than the respective inputs. That allows us to include the trivial case (usually...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e   1. Infuse the trivial answer into the table, the case for which we immediately know the answer...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e1. Iterate through the table, filling the positions ahead based on the current position....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e1. Note that sometimes the trivial case might not have the solution we need to solve the algorithm. Watch out for such situations....","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eThese are some materials that helped me understand dynamic programming (the order matters!):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e1. [A graphical introduction to dynamic programming](https:\u002f\u002favikdas.com\u002f2019\u002f04\u002f15\u002fa-graphical-introduction-to-dynamic-programming.html)...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    if target in memo: return memo[target]...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e        if solution is not None and len(solution) \u003c length_best_solution:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(best_sum(7, [5, 3, 4, 7]))...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    for word in dictionary:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(can_construct(\"abcdef\", [\"ab\", \"abc\", \"cd\", \"def\", \"abcd\"]))...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    for word in dictionary:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(count_construct(\"abcdef\", [\"ab\", \"abc\", \"cd\", \"def\", \"abcd\"]))...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    for word in dictionary:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(all_construct(\"abcdef\", [\"ab\", \"abc\", \"cd\", \"def\", \"abcd\", \"ef\", \"c\"]))...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    for i in range(n):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e    grid[1][1] = 1...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(grid_traveler(1, 1))...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e````...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e        for num in nums:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(can_sum_t(7, [2 ,3])) # True...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e        for num in nums:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e            continue...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(best_sum_t(7, [2 ,3])) # [2, 2, 3]...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e        prefix = target[:i]...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e            if target.startswith(prefix + word):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(can_construct_t(\"abcdef\", [\"ab\", \"abc\", \"cd\", \"def\", \"abcd\"])) # True...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e        for word in words:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e            if target.startswith(prefix + word):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(count_construct_t(\"abcdef\", [\"ab\", \"abc\", \"cd\", \"def\", \"abcd\"])) # 1...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003edef all_construct_t(target: str, words: list[str]) -\u003e list[list[str]]:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e        for word in words:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e            if target.startswith(prefix + word):...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e                if grid[i + len(word)]:...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(all_construct_t(\"abcdef\", [\"ab\", \"abc\", \"cd\", \"def\", \"abcd\", \"ef\", \"c\"])) # [['ab', 'cd', 'ef'], ['ab', 'c', 'def'], ['abc', 'def'], ['abcd', 'ef']]...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(all_construct_t(\"purple\", [\"purp\", \"p\", \"ur\", \"le\", \"purpl\"])) # [['purp', 'le'], ['p', 'ur', 'p', 'le']]...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(all_construct_t(\"skateboard\", [\"bo\", \"rd\", \"ate\", \"t\", \"ska\", \"sk\", \"boar\"])) # []...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003eprint(all_construct_t(\"enterapotentpot\", [\"a\", \"p\", \"ent\", \"enter\", \"ot\", \"o\", \"t\"])) # # [['enter', 'a', 'p', 'ot', 'ent', 'p', 'ot'], ['enter', 'a', 'p', 'ot', 'ent', 'p', 'o', 't'], ['enter', 'a', ...","\u003cb\u003eCatalog of Algorithms\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e# 1. Problem statement...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003eThe interviewer might come with a written down problem statement. They might share it with us ahead of our meeting or right at the start....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e      - What are its data types? Is it sorted? Do we know the range of the integers? (Can they be negative?) A batch of a stream? Et cetera....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e      - Expected input size: if they know it, might give an idea of the complexity we should aim for. For inputs of size 1 to 100, $$O(n^2)$$ is acceptable; for larger inputs, we should do better....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e   1. Ask about the specific runtime our solution will need. That will be very useful to screen out solutions and algorithms....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003eWhile it can be tempting to start implementing a solution right away, it is worth spending some time drafting the problem. After all, our interviewer will have given it some thought already, and could...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e1. Try to match this problem to the problems you have seen. Here's a cheat sheet for [data structures]({% post_url 2024-02-15-data-structures %}):...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e   - Linked lists: if we require fast insertions and deletions, especially when order matters...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e   - Union-finds: if we're investigating the if sets are connected or cycles exist in a graph...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e     And here's a list of common [algorithms]({% post_url 2024-02-15-algorithms %}):...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e1. Don't be shy! Let the interviewer hear out your thought process. They will surely appreciate knowing whats on your mind, and be able to chip in. Specially, if they do say something, _listen_. After...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e1. Once you seem to have converged to a specific approach, state the main parts of the algorithm and make sure they understand and agree....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e   - We might want to start with a suboptimal solution, as long as we let them know that we know that! Once we have that working, we can identify the main bottlenecks and go back to the drawing board....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003eDuring the implementation phase, it might help to go from the big picture to the small picture. Start by defining the global flow of the program, calling unimplemented functions with clear names. This...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003eIn order to allow our interviewer follow our logic, it is important that they can follow along:...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e- Make sure they are ok with us using additional dependencies. They might prefer to keep the algorithm lean!...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e- If you realize your solution might not work, let them know. You might need to go back to brainstorming....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e- Keep your code clean: avoid duplicated code, use helper functions, keep function and variable names understandable....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e- Scan the code for mistakes. For instance, when working with arrays, index errors are common....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003eOnce our solution is ready, it might be a good idea to give it a go. Simply call your function on a few examples. Consider:...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003eIf some examples fail, we need to debug our code. Throw in a few print statements, predict what you expect to see, and go for it....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003eAfter successfully presenting a solution, our interviewer might have some follow-up questions:...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e  - Time and space complexity? Usually, we should consider the worst case complexity, but if the amortized case is significantly better you should point it out....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e    - While abstracting specific aspects into functions is helpful, it might also be less efficient (e.g., if we have to iterate the input multiple times instead of one)....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e  - Consider non-technical constraints, such as development time, maintainability, or extensibility....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e- Identify the best theoretical time complexity. This involves considering what is the minimum number of operations involved. For instance if we need to visit every element, probably $$O(n)$$ is optim...","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e\u003e Some algorithms have some implicit and potentially unexpected behaviors. Visit the [algorithms]({% post_url 2024-02-15-algorithms %}) post, and `Ctrl + F` \"Note:\" in order to find some of them....","\u003cb\u003eHow to take coding interviews\u003c\u002fb\u003e\u003cbr\u003e- [\"Blind 75\" problem set](https:\u002f\u002fwww.teamblind.com\u002fpost\u002fNew-Year-Gift---Curated-List-of-Top-75-LeetCode-Questions-to-Save-Your-Time-OaM1orEU)...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eGraphs are data structures composed of a set of objects (_nodes_) and pairwise relationships between them (_edges_). Notably, edges can have properties, like a direction or a weight....","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e- Adjacency matrices: matrices in which every row $$i$$ contains the edges of node $$i$$. Specifically, $$\\text{row}_{ij}$$ is 1 if nodes $$i$$ and $$j$$ are connected, and 0 otherwise. They are symme...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eA common type of graph in computer science are grids, in which nodes are laid in a grid, and they are connected to the nodes selected top, bottom, left and right....","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eA tree is a graph in which there is only one path between every pair of nodes. Some concepts related to trees are: root, the (only) node on level 1; parent, the connected node in the level above; chil...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eOften trees are represented using classes. Specifically, we would have an object `Node` like:...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e(Min-)Heaps are binary trees in which the value of every parent is lower or equal than any of its children. This gives them their most interesting property: the minimum element is always on top. (Simi...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eIn Python, [`heapq`](https:\u002f\u002fdocs.python.org\u002f3\u002flibrary\u002fheapq.html) provides an implementation of the heap. Any populated list can be transformed in-place into a heap:...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e  - Push, then pop:...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e**Note:** Heaps are great to recover the smallest element, but not the k\u003csup\u003eth\u003c\u002fsup\u003e smallest one. [BSTs](#binary-search-trees) might me more appropriate for that....","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eBinary serach trees (BSTs) are binary trees in which every node meets two properties:...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e- All descendants on the left are smaller than the parent node....","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e- Search: done recursively on the tree. When balanced, search is as good as binary search on a sorted array....","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eThe time complexity of both is $$O(\\log n)$$ when the tree is **balanced**; otherwise it is $$O(n)$$. (Balanced trees are those whose height is small compared to the number of nodes. Visually, they lo...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e# Tries...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e- Nodes represent characters, except for the root, represents the string start....","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e1. Saving space when storing words sharing the same prefix, since they only store the prefix once....","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eThese two properties make them excellent at handling spell checking and autocomplete functions....","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eUnion-finds, also known as Disjoint-sets, store a collection of non-overlapping sets. Internally, sets are represented as directed trees, in which every member points towards the root of the tree. The...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e- **Find:** returns the set an element belongs to. Specifically, it returns its representative....","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eUnion-finds can be represented as an array, in which every member of the universal set is one element. Members linked to a set take as value the index of another member of the set, often the root. Con...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eEvery set has a property, the _rank_, which approximates its depth. Union is performed _by rank_: the root with the highest rank is picked as the new root. Find performs an additional step, called _pa...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e    def find(self, x):...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003e        return self.parent[x]...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eBloom filters are data structures to probabilistically check if an element is a member of a set. It can be used when false positives are acceptable, but false negatives are not. For instance, if we ha...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eThe core structure underlying bloom filters is a bit array, which makes it highly compact in memory. When initialized, all the positions are set to 0. When inserting a given element, we apply multiple...","\u003cb\u003eCompendium of Data Structures\u003c\u002fb\u003e\u003cbr\u003eA linked list is a DAG in which almost every node has exactly one inbound edge and one outbound edge. The exceptions are the _head_, a node with no inbound egde, and the _tail_, a node with no outboun...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003e# Data structures prov...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003ePandas provides several data structures, out of which two are particularly popular: Series and DataFrames....","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003e## Series...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003eA Series is a vector-like structure, that extends [NumPy vectors]({% post_url 2024-02-04-python-vectors %}#the-inner-workings-of-numpy-arrays)....","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003edtype: int64...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003eDataFrames are matrix-like structures, which build on top of Series. They can be created in multiple ways, some of which are:...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003e- A dictionary of lists\u002farrays\u002fseries...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003e- An SQL query or table...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003eAs in NumPy vectors, we can access a Series' elements using their _positional_ indexes. But, furthermore, it has an _index_, a hash map structure which allows us to access each element in the array us...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003e- `.iloc[]` uses the positional indices, and slicing works as usual:...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003e  ```...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003eThanks to their dictionary-like properties, indexes allow to access an element in constant time. However, including non-unique indexes might lead to a worst case $$O(n)$$ lookup time....","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003eUnless otherwise specified, the index gets initialized to a (lazy) enumeration of the rows\u002fitems. We can access the index using `.index()`, and revert it to this default behaviour using `.reset_index(...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003e[MultiIndex](https:\u002f\u002fpandas.pydata.org\u002fdocs\u002fuser_guide\u002fadvanced.html) is an index in which is key is a (unique) tuple. We can create them from lists of lists or of tuples, from DataFrames, or from the...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003eclass_2 = [1, 2]...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003e                                   # the name of the levels themselves...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003e[As NumPy]({% post_url 2024-02-04-python-vectors %}#views-copies-and-in-place-operations), Pandas distinguishes between _viewing_ an object and _copying_ it....","\u003cb\u003ePandas\u003c\u002fb\u003e\u003cbr\u003e- [Pandas Illustrated: The Definitive Visual Guide to Pandas](https:\u002f\u002fbetterprogramming.pub\u002fpandas-illustrated-the-definitive-visual-guide-to-pandas-c31fa921a43)...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e```mermaid...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e```mermaid...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e    N === K...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e    S === L...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003eIn the 21st century, we define graphs as sets of objects (vertices) and pairwise relations between them (edges). Graphs are also known as networks; vertices as nodes; and edges as links. K\u00f6nigsberg is...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003eWhere $$V$$ denotes the set of vertices and $$E$$ the set of edges (pairs of vertices)....","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e\u003e **_Notation note:_** $$V$$ and $$E$$ above refer sets, specifically to the vertex and edge set of a specific graph ($$G$$). Note that they are in italics. In contrast, the $$\\text{V}$$ in $$\\text{V}...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e- Undirected graph: $$E \\subseteq \\{ \\{u, v\\} \\mid u, v \\in V \\}$$, i.e., the edges do not have directions....","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e      vertex_a === vertex_b...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e  ```...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e      vertex_a --\u003e vertex_b...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e      vertex_b --\u003e vertex_c...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e  \\end{cases}...","\u003cb\u003eIntroduction to Graphs\u003c\u002fb\u003e\u003cbr\u003e\u003e **Note:** unless specified otherwise, in this series I will focus on [_simple_]({% post_url 2025-01-23-graphs-glossary %}#simple-graph) graphs, which have at most one edge between any pair of vertic...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eIn an [undirected](#undirected-graph) graph, a [connected](#connected-graph) [subgraph](#subgraph) that is not part of a larger connected subgraph....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA [trail](#trail) in which the first and last vertices are equal. In contrast to the [cycle](#cycle), any vertex can be repeated....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003e## Cycle...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA [trail](#trail) in which _only_ the first and last vertices are equal. Except for the tails and in contrast to the [circuit](#circuit), vertices cannot be repeated....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eAn example of a flow is a heat diffusion process across a graph. In such processes, each vertex starts with a certain amount of heat and, at each time point, exchanges heat with its [neighbors](#neigh...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003e## Module...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA [subgraph](#subgraph) whose vertices are densely connected to each other, and loosely to the rest of the graph....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eAn orientation of an [undirected](#undirected-graph) graph is the [directed](#directed-graph) graph resulting of assigning a direction to each of its vertices. A [directed](#directed-graph) graph is o...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003e## Path...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA graph resulting from subsetting vertices from a larger graph, as well as a subset of the edges connecting them....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA [subgraph](#subgraph) containing _all_ the edges connecting the vertices in the original graph....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003e## Trail...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA set of 3 vertices and at least 2 edges between them, none of which are redundant or loops. _Open_ triplets have exactly 2 edges; _closed_ triplets have exactly 3....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003e## Walk...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA walk _on a graph_ is an alternating sequence of vertices and edges, such that every vertex is [incident](#incidence) with the previous and the following edge (if any)....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA vertex is adjacent with _another vertex_ if they are connected by an edge. $$u \\sim v$$ denote that $$u$$ and $$v$$ are adjacent....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003e## Degree...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eThe degree of a vertex in a (simple) [undirected](#undirected-graph) graph is the number of edges [incident](#incidence) with that vertex. In a (simple) [directed](#directed-graph) graph we distinguis...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eIn a [directed](#directed-graph) graph, the destination _of an edge_ is the vertex at the head of the edge....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eThe neighborhood of vertex $$v$$ is the [induced subgraph](#induced-subgraph) containing all the vertices [adjacent](#adjacency) to $$v$$....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA vertex is incident _with an edge_ if the vertex is one of the two vertices the edge connects....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003e## Source...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eIn a [directed](#directed-graph) graph, the source _of an edge_ is the vertex at the tail of the edge....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA [acyclical](#acyclical-graph) graph whose vertices can be divided into two sets such that no pair of vertices in the same set are [adjacent](#adjacency). Often, each of these sets are referred to as...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA simple, [undirected](#undirected-graph) graph in which every pair of vertices are connected by an edge. Complete graph are usually denoted by letter $$K$$ with a subindex that indicates the total nu...","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eAn [undirected](#undirected-graph) graph in which any two vertices are connected by at most one path. That is, a disjoint union of [trees](#tree)....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA graph in which we can find a path between any two nodes via a greedy strategy that choses the neighbor closest according to a distance function....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eAn [undirected](#undirected-graph) graph in which there is only one [path](#path) between every pair of nodes....","\u003cb\u003eGraph Glossary\u003c\u002fb\u003e\u003cbr\u003eA [triplet](#triplet) with 3 edges. It consists of _three_ closed triplets, each centered around each of the vertices....","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e# Matrices associated to grap...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003eA graph $$G = (V, E)$$ s.t. $$V = \\{v_1, \\dots, v_n\\}$$ and $$E = \\{e_1, \\dots, e_m \\}$$ has several important associated matrices. For convenience, I often refer to vertex $$v_i$$ simply by its index...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e```mermaid...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e    vertex_1 === vertex_2...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e[Vertex degree]({% post_url 2025-01-23-graphs-basics %}#degree) is ised to define the **degree** matrix $$D$$ is a diagonal $$n \\times n$$ matrix such that $$D_{ii} = \\deg i$$, and 0 elsewhere. For in...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e[Incidence]({% post_url 2025-01-23-graphs-glossary %}#incidence) is used to define the **incidence** matrix $$Q$$, a $$n \\times m$$ matrix such that $$Q_{ij}$$ equals:...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e- If $$G$$ is _directed_:...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e[Adjacency]({% post_url 2025-01-23-graphs-glossary %}#adjacency) is used to define the **adjacency** matrix $$A$$, a matrix $$n \\times n$$ such that the $$A_{ij}$$ equals:...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e- $$0$$ if vertices $$i$$ and $$j$$ are not adjacent (note that in simple graphs vertices are not self-adjacent)...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e1 & 1 & 0 & 0 \\\\...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003eThe **Laplacian** matrix $$L$$ is a $$n \\times n$$ matrix such that the $$L_{ij}$$ equals::...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e- For $$i \\neq j$$:...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003eMore concisely, $$L = D - A$$. Or, given any oriented incidence matrix $$Q(G)$$, $$L = QQ^T$$....","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e\\end{bmatrix}...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003eThe presence of [hubs]({% post_url 2025-01-23-graphs-glossary %}#hub) results in large diagonal entries in the Laplacian. There are normalized versions of the Laplacian that downweigh such vertices by...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003eThe **symmetrically** normalized Laplacian $$L_\\text{sym}$$ is a symmetric matrix derived as follows:...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003eThe **random walk** normalized Laplacian $$L_\\text{rw}$$ is a matrix closely related to [random walks]({% post_url 2025-01-27-graphs-random-walks %}) that is derived as follows:...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e**Spectral graph theory** studies how the eigenvalues and eigenvectors of a graph's associated matrices relate to its properties. Looking more closely at two of the matrices described above, we can se...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e- If $$G$$ is undirected, $$A$$ is both real and symmetric. Hence, it is diagonalizable and has only _real_ values....","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003eThe eigenvectors of $$L$$ are closely related to the connectivity of its associated graph....","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003eA simple, but ultimately insightful property of $$L$$ is that, for an undirected graph, the sum over the rows or the columns equals 0. In other words, multiplying $$L$$ by an all-ones vector $$\\mathbf...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003eMore generally, less _smooth_ eigenvectors (i.e., those in which consecutive elements change sharply) indicate a less connected. Equivalently, smaller eigenvalues correspond to smoother eigenvectors, ...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003eThe goal of **spectral clustering** is finding a partition of the graph into $$k$$ groups such that the are densely\u002fstrongly connected with each other, and sparsely\u002fweakly connected to the others. (If...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e```pseudocode...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e    \\STATE Compute degree matrix $$D$$ where $$D[i,i] = \\sum_{j=1}^n A[i,j]$$...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e    \\STATE Compute first $$k$$ eigenvectors $$u_1, \\ldots, u_k$$ of $$L_{\\text{sym}}$$...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e    \\FOR{$$i = 1$$ \\TO $$n$$}...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e    \\ENDFOR...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e\\end{algorithmic}...","\u003cb\u003eGraphs and Linear Algebra\u003c\u002fb\u003e\u003cbr\u003e- [A Tutorial on Spectral Clustering](https:\u002f\u002fpeople.csail.mit.edu\u002fdsontag\u002fcourses\u002fml14\u002fnotes\u002fLuxburg07_tutorial_spectral_clustering.pdf)...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003eA **random walk (RW)** is a [stochastic](https:\u002f\u002fen.wikipedia.org\u002fwiki\u002fStochastic_process), discrete process. At every time step a walker, located in one of the graph's vertices, picks one of its neig...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003eP = D^{-1} A...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e- At step 0, $$\\mathbf{\\pi}_0 = (0, 0, \\cdots, 1, \\cdots, 0)$$. That is, $$\\pi_0$$ is an $$n$$-dimensional row vector that is $$0$$ almost everywhere, with a $$1$$ at component $$i$$....","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e$$\\pi_t$$ is an $$n$$-dimensional row vector $$\\mathbf{\\pi}_t$$ in which $$\\pi_{tj}$$ represents the probability of the walker starting at vertex $$i$$ and being on vertex $j$ at time $t$....","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e$$\\mathbf{\\pi}_0 = c_1 \\mathbf{u}_1 + c_2 \\mathbf{u}_2 + \\cdots + c_n \\mathbf{u}_n$$...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e\\end{multline*}...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003eThe degree row-vector $$\\mathbf{d} = ({d_1}, \\cdots, d_n )$$ is a left eigenvector of $$P$$:...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003eThis is the stationary distribution of the random walk. It formalizes the intuitive result that high [degree]({% post_url 2025-02-09-graph-properties %}#degree) vertices are more likely to be visited....","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e\u003e **Ergodicity and _lazy_ random walks:** A unique stationary distribution does not always exists. A random walk is _ergodic_ if a stationary distribution exists and is the same for any $$\\pi_0$$. For...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003eThe [Laplacian]({% post_url 2025-01-23-graphs-linear-algebra %}#normalized-laplacian-matrices) and the transition matrices are deeply related:...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e- This result holds regardless of what the starting vertex is. In fact, $$\\pi_0$$ could be a probability distribution over the vertices....","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003eIn the **random walk with restart (RWR)**, the walker can return to its root vertex with a restart probability $$r \\in [0, 1]$$:...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003eA **Markov chain** is a sequence of events in which the probability of each event only depends on the state attained in the previous event. A random walk is a Markov chain: the probability of visiting...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e- _Time reversibility_...","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003eIn the context of Markov chains, the transition matrix $$P$$ is known as the **right stochastic matrix**....","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e- **_Row\u002fright_ stochastic matrix**: square matrix with non-negative entries where each row sums to $$1$$....","\u003cb\u003eRandom walks and Markov chains\u003c\u002fb\u003e\u003cbr\u003e- [Full title: The Unreasonable Effectiveness of Spectral Graph Theory: A Confluence of Algorithms, Geometry, and Physics](https:\u002f\u002fwww.youtube.com\u002fwatch?v=8XJes6XFjxM)...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003e# Local properties...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003eIn an undirected network, the **degree** of a vertex $$u$$ ($$\\deg u$$) refers to the number of edges that are incident on $$u$$. In a directed network, this concept is split between _indegree_ ([$$\\d...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003eThe **(local) clustering coefficient** _of a vertex_ measures the probability that its [neighbors]({% post_url 2025-01-23-graphs-glossary %}#neighborhood) are connected. It is computed as the ratio be...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003e[Often](https:\u002f\u002fr.igraph.org\u002freference\u002ftransitivity.html), the clustering coefficient of a directed graph is computed without considering the direction of the edges....","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003eThe **modularity** measures how well a graph can be divided into [modules]({% post_url 2025-01-23-graphs-glossary %}#modules). Given a partition of a graph into $$k$$ modules, the modularity $$Q$$ is ...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003ewhere $$e_{ii} = \\frac {\\| \\{\\{u, v\\} \\mid u \\in V_i, v \\in V_i, \\{u, v\\} \\in E \\} \\|} {\\|E\\|} $$,$$a*i = \\frac {\\| \\{\\{u, v\\} \\mid u \\in V_i, \\{u, v\\} \\in E \\} \\|} {\\|E\\|} $$ and $$V_i$$ is the set o...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003eThe **within-module degree** of a vertex is the module version of the [degree](#degree). It is often normalized as a z-score; the z-score for node $$i$$, mapped to module $$k$$:...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003ewhere $$\\kappa_i$$ is within-module degree (the number of edges between $$i$$ and other vertices in module $$k$$); $$\\bar \\kappa_k$$ is the average within-module degree; and $$\\sigma_{\\kappa_k}$$ is t...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003eThe **participation coefficient** of a vertex... TODO...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003eThe radius and the diameter measure how easy it is to traverse a graph. They both are quantities based on the maximum [distance]({% post_url 2025-01-23-graphs-glossary %}#distance) between any two ver...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003eThe **global clustering coefficient** _of a graph_ is the ratio between closed and open [triplets]({% post_url 2025-01-23-graphs-glossary %}#triplet) in that graph. Or, equivalently:...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003e[Often](https:\u002f\u002fr.igraph.org\u002freference\u002ftransitivity.html), the clustering coefficient of a directed graph is computed without considering the direction of the edges....","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003e**Centrality** assigns a score or a ranking to every vertex in the graph, which represents its importance in the network according to some metric. [Degree](#degree) and [participation](#participation)...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003eWe can clasify graphs into different types by using the [global properties](#global-properties) of their nodes....","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003e**Regular** graphs are those in which every node has the same degree. They have a high average [clustering coefficient](#local-clustering-coefficient) and a large [diameter](#radius-and-diameter)....","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003e[Milgram](https:\u002f\u002fen.wikipedia.org\u002fwiki\u002fStanley_Milgram) _et al._ conducted experiments that were key to understand the topology of social graphs....","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003eThey gave letters to randomly chosen people from Nebraska and Kansas, each of which was to reach a target random person from Massachusetts. To that end, they could only give it to their friend or rela...","\u003cb\u003eProperties of Graphs\u003c\u002fb\u003e\u003cbr\u003eThis ultimately lead to the postulation of the [six degrees of separation](https:\u002f\u002fen.wikipedia.org\u002fwiki\u002fSix_degrees_of_separation) and the realization that social graphs are small world graphs....","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eWhen dealing with statistical tests, Benjamin...","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eWhen dealing with statistical tests, Benjamini\u2013Hochberg and Benjamini\u2013Yekutieli are common procedures to keep the FDR below a level $$\\alpha$$. However, such strategies rely on certain assumptions; fo...","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eThe **knockoff** filter is a procedure to perform feature selection while keeping the FDR controlled. Given an outcome $$\\mathbf{Y}$$ and a feature matrix $$X$$, the goal is to select a subset of feat...","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eY \\perp X_{-S} \\mid X_S...","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eThe **Model-X** paradigm assumes that the explanatory variables are random variables with a known joint distribution. Although theoretically appealing, this assumption can be impractical for real-worl...","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eThe **Fixed-X** paradigm makes no assumptions on the distribution of the explanatory variables. Instead, they can be treated as fixed quantities. This makes it more applicable in practice. However, it...","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003e- $$F_{Y \\mid X}$$ must be linear and homoscedastic...","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eIntuitively, by comparing the association measure computed for each original feature against its knockoff, one can determine which features provide true signals. Specifically, the knockoff-based featu...","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eCreate synthetic copies of the features that retain the original correlation structure without any outcome information. An obvious question is how to synthesize such knockoff copies....","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eFor each feature, calculate the association measure $$D(\\mathbf{Y}, \\mathbf{X_k})$$ and its counterpart $$D(\\mathbf{Y}, \\tilde{\\mathbf{X}}_k)$$ on the knockoff....","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eKernel-based measures are powerful tools for detecting complex, non-linear dependencies:...","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003e- **HSIC (Hilbert-Schmidt Independence Criterion):** Computes the covariance between kernel-transformed versions of the feature and the outcome, capturing a broad range of dependency structures....","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eThese measures satisfy the sure independence screening property under bounded kernel conditions\u2014meaning that, with high probability, the truly active features are recovered when a proper threshold is ...","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003e\u003e A potential limitation of kernel knockoffs is its sometimes overly conservative nature. To keep the FDR low, the procedure may end up selecting very few\u2014or even no\u2014features. This suggests that the c...","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eDefine the statistic as $$w_k = D(Y, X_k) - D(Y, \\tilde{X}_k)$$. A larger $$w_k$$ indicates stronger evidence that the original feature is associated with the outcome....","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eIdentify the smallest threshold $$t$$ such that $$\\frac{\\#\\{w_k \\le -t\\}}{\\#\\{w_k \\ge t\\}} \\le \\alpha$$ where $$\\alpha$$ is the desired FDR level. Retain all features with $$w_k \\ge t$$....","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eA notable challenge arises when the number of features $$p$$ is large compared to the sample size $$n$$ (i.e., $$2p\u003en$$). In such high-dimensional settings, constructing knockoffs directly is infeasib...","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003e- Pre-screen Features: Use a subset of the data to rank and reduce the feature set....","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003eThis two-step approach helps maintain statistical power while ensuring robust FDR control....","\u003cb\u003eKnockoffs\u003c\u002fb\u003e\u003cbr\u003e- [Variable Selection with Knockoffs](https:\u002f\u002fweb.stanford.edu\u002fgroup\u002fcandes\u002fknockoffs\u002f)...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eWe will use `uv` for a p...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eWe will use `uv` for a prototypical machine learning project: train a neural network to classify images of handwritten digits from the [MNIST dataset](https:\u002f\u002fen.wikipedia.org\u002fwiki\u002fMNIST_database) usi...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e\u003cdiv style=\"width:50%; margin:0 auto;\"\u003e...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e\u003cdiv class=\"caption\"\u003e...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eClearly, I wasn\u2019t thrilled with my old workflow. Let's see how `uv` made it a more pleasant experience....","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eBefore diving into the details, it's worth justifying why we need _yet another tool_ for managing Python-centric data science projects....","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eFirst, `uv` is **fast**. As is common in new high-performance tools, it's written in Rust, a compiled language known for its performance. It also uses different strategies to speed up package installa...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eSecond, `uv` boosts **reproducibility**. As we will see below, it makes it easy to create and share virtual environments. This is key to ensure that multiple developers can work on a consistent enviro...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eThird, `uv` leverages **common standards** within the Python ecosystem. This reduces the risk of being locked into its ecosystem, and makes it easy to collaborate with other developers that use differ...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eLast, `uv` is **one** tool, which means that I don't need to remember the syntax of multiple tools, or how to use them together....","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eI'm always quite enthusiastic about the new, shinier tool. But before jumping straight into `uv`, it's worth considering the downsides of adopting it....","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eFirst, `uv` is **young**. In contrast, tools like `pip`, `conda` or `venv` have been around for more than a decade. I have no doubt they will be around for at least another decade and are unlikely to ...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eSecond, and on a related note, `uv` is **not widely adopted**. This means that I have had a hard time troubleshooting some errors. It has also meant that it's not a standard, and you might need to be ...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eLast, `uv` is mainly developed by [Astral](https:\u002f\u002fastral.sh), a VC-backed startup that hasn't started monetizing their products yet. It remains to be seen how their future business model will impact ...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eAfter [installing `uv`](https:\u002f\u002fdocs.astral.sh\u002fuv\u002fgetting-started\u002finstallation\u002f), we simply need to run `uv init` to start a new project:...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003euv init mnist-classifier...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e```toml...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eBy default, `uv init` creates an _application_ project. This is appropriate for scripts, like simple tools. This is why the command above created a `main.py` file, meant to be the entry point of our a...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eMultiple Python projects can co-exist on the same machine, each requiring different packages and versions of the same packages. This is facilitated by _virtual environments_, self-contained directorie...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e`uv` leverages Python's built-in package to handle virtual environments: `venv`. The virtual environment contains its own installation of Python, whose version is specified in `.python-version`. `uv i...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e3.10...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eThat's why `uv` does not require explicitly activating the environment. Instead, we can use `uv run \u003cscript\u003e.py` to run any Python script or command using the environment's Python. For instance, `uv i...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e    main()...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eUpon its first invocation, `uv run main.py` creates a virtual environment. To do this, it examines the (empty) `dependencies` list in `pyproject.toml` and resolves an (empty) set of packages....","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eTo start our little data science project, we'll need to install the [PyTorch](https:\u002f\u002fpytorch.org\u002f) library. Typically I would have run `conda install conda-forge::pytorch`; in `uv` we use `uv add tor...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e]...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eHowever, `torch` depends, in turn, on other packages, like `numpy`. Note that this is not reflected in `pyproject.toml`, which lists only our direct dependencies, not every transitive package. Further...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e```toml...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003esdist = { url = \"https:\u002f\u002ffiles.pythonhosted.org\u002fpackages\u002f0a\u002f10\u002fc23352565a6544bdc5353e0b15fc1c563352101f30e24bf500207a54df9a\u002ffilelock-3.18.0.tar.gz\", hash = \"sha256:adbc88eabb99d2fec8c9c1b229b171f18afa...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e    { url = \"https:\u002f\u002ffiles.pythonhosted.org\u002fpackages\u002f4d\u002f36\u002f2a115987e2d8c300a974597416d9de88f2444426de9571f4b59b2cca3acc\u002ffilelock-3.18.0-py3-none-any.whl\", hash = \"sha256:c401f4f8377c4464e6db25fff06205...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e]...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e`uv.lock` should be under git control, providing the exact recipe to replicate an environment. This is key, for instance, to ensure that all developers work on a consistent environment. It can also fa...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e\u003e If needed, `uv.lock` can be exported into a [`requirements.txt`](https:\u002f\u002fpip.pypa.io\u002fen\u002fstable\u002freference\u002frequirements-file-format\u002f) file for legacy tools, via `uv export --format=requirements-txt \u003er...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eBesides `uv add`, there are other commands that can be used to manage packages. For starters, its counterpart `uv remove \u003cpackage_name\u003e` will uninstall `\u003cpackage_name\u003e`. Another command that can trigg...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eSyncing refers to (un)installing packages in the project environment to match the lockfile. `uv run` will do this automatically, as we just saw. But it can also be forced manually with `uv sync`....","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eLast, when adding new packages, `uv` will tend to be conservative. It will install the most recent version of the package that is compatible with the current environment. To force a specific version, ...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e\u003e To keep compatibility with `pip` workflows, `uv` also supports `uv pip install \u003cpackage_name\u003e` and `uv pip uninstall \u003cpackage_name\u003e`. These will (un)install the package in the current environment, b...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eAs a data scientist, Jupyter notebooks are my bread and butter. In order to run Jupyter notebooks on our `uv` environment, we need to install the [IPython kernel `ipykernel`](https:\u002f\u002fpypi.org\u002fproject\u002f...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e`uv` allows you to add development dependencies with `uv add --dev ipykernel`, which will add the following to `pyproject.toml`:...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e    \"ipykernel\u003e=6.29.5\",...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eHere comes the actual data science, which I will just skim over. I wrote a simple script to train a convolutional neural network on the MNIST dataset. The script is located in [`train.py`](https:\u002f\u002fgit...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eNow that we have a working model, let's see how `uv` helps us package the model into a Docker image....","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eFirst, we need to pick our base image. Astral provides [multiple pre-built images](https:\u002f\u002fdocs.astral.sh\u002fuv\u002fguides\u002fintegration\u002fdocker\u002f#available-images) that include `uv` and different versions of Py...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eENV UV_LOCKED=1...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e\u003e Note: If you use GPU-specific packages, wheels may differ. See [Astral\u2019s docs](https:\u002f\u002fdocs.astral.sh\u002fuv\u002fguides\u002fintegration\u002fpytorch\u002f#installing-pytorch)....","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003edocker run mnist_classifier...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eSimpleCNN(...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003eWe have seen how `uv` can be used to manage Python projects, packages and environments. It satisfies my craving for reproducibility, is snappy and has simplified repetitive workflows. I look forward t...","\u003cb\u003eAn intro to uv\u003c\u002fb\u003e\u003cbr\u003e- [A year of uv: pros, cons, and should you migrate](https:\u002f\u002fwww.bitecode.dev\u002fp\u002fa-year-of-uv-pros-cons-and-should)...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e# Shapley values...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eSHAP values have their roots in game theory, specifically in **Shapley** values. Imagine a group of players collaborating to achieve a payout. The Shapley value is a method to find out how to fairly d...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eA core concept of Shapley values is **coalitions**: given $$n$$ players, a coalition is a subset of the players. Another concept is the **characteristic function**, $$v: 2^N \\rightarrow \\mathbb{R} $$,...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eThe grand coalition is the coalition of all players, $$N$$. Efficiency means that the sum of all Shapley values equals the value of the grand coalition, i.e., the entire payout is distributed among th...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eTwo players $$i$$ and $$j$$ are symmetric if their marginal contribution to any coalition not containing either player is the same. That is, if $$v(S \\cup \\{i\\}) = v(S \\cup \\{j\\})$$ for any coalition ...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eIf a player $$i$$ does not change the value of any coalition they join (i.e., $$v(S \\cup \\{i\\}) = v(S)$$ for all $$S \\subseteq N \\setminus \\{i\\}$$), they are a dummy player. The dummy player property ...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eIf two games with characteristic functions $$v_1$$ and $$v_2$$ are combined into a new game $$v_1 + v_2$$ (where $$(v_1+v_2)(S) = v_1(S) + v_2(S)$$ for any coalition $$S$$), the Shapley values are add...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eMachine learning models like linear regression are _interpretable_, as the model parameters indicate how each input feature contributes to the prediction. However, many complex models like neural netw...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eIntuitively, SHAP values quantify how much each feature's presence changes the prediction. Some features will have a negative contribution (pushing the prediction lower) and others a positive contribu...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eTo establish the connection to Shapley values, we map the game theory concepts to the machine learning context:...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e- The $$n$$ players become $$n$$ _predictive features_....","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eThe Shapley value $$\\phi_i$$ for feature $$i$$ in this context is then calculated as:...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e\u003e **_Simplified_ features:** We use $$\\mathbf{x}$$ for the features in the original space $$\\chi$$, a vector of length $$n$$. The SHAP theoretical framework uses a simplified feature vector $$\\mathbf{...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eThat covers the _Shapley_ part of SHAP; let's now focus on the _Additive exPlanation_ bit. The goal of SHAP is to obtain a local, additive explanation model $$g$$ for each prediction $$f(\\mathbf{x})$$...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eSince SHAP values are Shapley values, they meet all the properties specified above. But they also satisfy three additional properties that are desirable for model explainers....","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eWhen all simplified features are present ($$\\mathbf{x}' = \\mathbf{1}$$), the explanation model $$g$$ must equal the prediction $$f(\\mathbf{x})$$:...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eThe consistency ensures that if a model $$f$$ changes into another model $$f'$$, such that a feature's contribution doesn't decrease, the SHAP values do not decrease either. Formally, if...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eLet's understand SHAP values better by looking at an example. I trained a model that uses 10 clinical features (body mass index, cholesterol, age, and a few others) to predict a continuous measure of ...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e| Age         | Sex        | BMI        | Blood pressure | \u2026   | Target |...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e\u003e SHAP values can be computed on the dataset used to train the model (train set) or on a holdout set. Using a larger dataset like the train set might provide a more stable picture of overall feature c...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eSHAP values are implemented in Python via the [`shap`](https:\u002f\u002fshap.readthedocs.io\u002fen\u002flatest\u002findex.html) package. While I won't be showing any code here, you can see the code that generated the figure...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eSHAP values provide **local** explanations, showing the contribution of each feature to a particular prediction. I computed the SHAP values describing the importance of each of the 10 variables for ea...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e{% include figure.liquid loading=\"eager\" path=\"assets\u002fpython\u002f2025-04-01-shapley\u002fimg\u002fwaterfall_diabetes.webp\" class=\"img-fluid rounded z-depth-1\" %}...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eThe waterfall plot shows how the prediction for this patient (186.53) departs from the average prediction over the training set (152.132). The difference (34.398) is the total change attributed by the...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e{% include figure.liquid loading=\"eager\" path=\"assets\u002fpython\u002f2025-04-01-shapley\u002fimg\u002fbeeswarm_diabetes.webp\" class=\"img-fluid rounded z-depth-1\" %}...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eIn the swarmplot, each point represents the SHAP value for a patient for a specific feature. Features are shown on the y-axis, and their corresponding SHAP values on the x-axis. As in the waterfall pl...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eGlobal explanations can be derived by aggregating the local SHAP values over a dataset. A common global measure is the average absolute SHAP value for each feature:...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e{% include figure.liquid loading=\"eager\" path=\"assets\u002fpython\u002f2025-04-01-shapley\u002fimg\u002fglobal_diabetes.webp\" class=\"img-fluid rounded z-depth-1\" %}...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003ePlotting these averages shows which features have the largest impact on the model's predictions _on average_ across the dataset, providing a global measure of feature importance....","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eLastly, SHAP values can be used for clustering. While traditional clustering groups data points based on their original feature values, clustering in SHAP space groups points based on how features _co...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e\u003cstyle\u003e...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eApplying PCA to the SHAP values (\"supervised PCA\") and the original features (\"unsupervised PCA\") for this dataset, we can visualize how instances are grouped....","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eOne key limitation of interpreting SHAP values is their behavior with **highly correlated features**. When features are strongly correlated, the model might arbitrarily use one over the others, or dis...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eAnother point of consideration is **feature interactions**. While the fundamental Shapley value calculation inherently accounts for interactions (by averaging marginal contributions over different coa...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eFinally, it's important to remember that SHAP values explain _how the model makes a prediction_, not whether the prediction itself is correct. If the model is biased, overfit, or simply wrong for a gi...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e[Above](#shap-values) I described the general approach to compute SHAP values. Unfortunately, it is very computationally intensive: exploring all possible coalitions is equivalent to exploring all $$2...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003eThe permutation approximation approximates SHAP values by estimating the expected marginal contribution of each feature over many random permutations of the features. Let's study the permutation appro...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e1. Initializing a list to store the marginal contribution of each feature. In this example, I will focus on the contribution of the first feature, $$x_\\text{age}$$, so I will call this list just $$\\te...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e   1. A random ordering of the features is produced, e.g., $$(\\text{BP}, \\text{age}, \\text{BMI}, \\text{sex})$$, and a random sample $$\\mathbf{z}$$ is sampled from the background dataset $$X_\\text{bg}$...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e   1. Create two synthetic examples: - $$\\mathbf{x}_1 = (x_\\text{BP}, x_\\text{age}, z_\\text{BMI}, z_\\text{sex})$$ - $$\\mathbf{x}_2 = (x_\\text{BP}, z_\\text{age}, z_\\text{BMI}, z_\\text{sex})$$...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e      Note that the only difference between the two examples is the value of the age feature....","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e   1. Compute the marginal contribution of the age feature as $$\\delta = f(\\mathbf{x}_1) - f(\\mathbf{x}_2)$$....","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e1. Approximate the SHAP value as the average marginal contribution: $$\\phi_\\text{age} \\cong \\frac{1}{K} \\sum_i \\delta_{i}.$$...","\u003cb\u003eSHAP values\u003c\u002fb\u003e\u003cbr\u003e- [Interpretable Machine Learning: Shapley values](https:\u002f\u002fchristophm.github.io\u002finterpretable-ml-book\u002fshapley.html)...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eThis is the workflow that Hugging Face \ud83e\udd17 and its [`tr...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eThis is the workflow that Hugging Face \ud83e\udd17 and its [`transformers`](https:\u002f\u002fhuggingface.co\u002fdocs\u002ftransformers\u002findex) Python library aim to eradicate. `transformers` provides a unified API to fetch, use a...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eLet's dive into the `transformers` library. Although big tech is going crazy over LLMs, DNA language models are where the money is.\u003cd-footnote\u003eCitation required\u003c\u002fd-footnote\u003e In that spirit, in this po...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eI will be providing snippets of code along with the text. If you are still curious about the nitty-gritty, all the code is available [on Github](https:\u002f\u002fgithub.com\u002fhclimente\u002fhclimente.github.io\u002fblob\u002fm...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eThe [Nucleotide Transformer](https:\u002f\u002fwww.nature.com\u002farticles\u002fs41592-024-02523-z) (NT) is an encoder-only transformer, essentially a [BERT model](\u003chttps:\u002f\u002fen.wikipedia.org\u002fwiki\u002fBERT_(language_model)\u003e) ...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e{% include figure.liquid path=\"assets\u002fimg\u002fposts\u002f2025-05-02-hf-transformers\u002fnucleotide_transformer.jpg\" class=\"img-fluid\" %}...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e\u003cdiv class=\"caption\"\u003e...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e\u003c\u002fdiv\u003e...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e1. **Tokenizer:** First, we convert the input DNA sequence into a sequence of integers (_tokens_), each representing a subsequence of length 6 nucleotides (\"6-mers\"). The total number of tokens is 4,1...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e   In the case of our 18-nucleotide sequence `ATGGTAGCTACATCATCT`, the tokenizer transforms it into a tokenized sequence of length 4: `[3, 506, 3662, 1567]`. This includes the CLS token (`3`) and thre...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e2. **Embedding layer:** An embedding layer transforms the tokenized sequence of integers into an fixed-length vector of real values (_embedding_). On this embedding, a positional encoding is added to ...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e3. **Transformer encoder:** Here comes the main event: the stacked Transformer encoder blocks (since the NT is an encoder-only model, remember?). These blocks are where the magic actually happens, pro...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e4. **Token probabilities:** Finally the last layer's embedding is transformed into a probability of each token in each of the input positions. Since there were 3 input positions and 4,107 possible tok...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e   In our example, the masked token was `1567` and was in the last position. If our model has done a good job, the matrix entry (3, 1567) will be close to 1, and the rest of the entries in that row wi...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eBy repeating this process over and over, on DNA sequences obtained from very different species, the model learns to guess the hidden sequence from it's genomic context. But, **what is it _really_ lear...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eNow that the theory is out of the way, let's start exploring the Hugging Face ecosystem. There are two elements of it that vastly facilitate sharing and leveraging pre-trained models....","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eOne is the [Model Hub](https:\u002f\u002fhuggingface.co\u002fdocs\u002fhub\u002fen\u002findex), a repository for the community to share and discover pre-trained models. In this post I use the smallest NT, [a 50 million parameter m...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eThe other one is the many [`transformers` AutoClasses](https:\u002f\u002fhuggingface.co\u002fdocs\u002ftransformers\u002fmodel_doc\u002fauto). They abstract away the specific model architecture, and the changes that would be neede...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eBy using the `from_pretrained` method, we are loading both the architecture and the weights of the model. By default, the model is in evaluation mode; if we were to further fine-tune it, we would need...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eIf instead we wanted to leverage the pre-trained model for binary classification, we would run:...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e)...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eThe model cannot be applied directly to a DNA sequence, which needs to be [tokenized first](#a-worked-out-training-example). Another AutoClasses, the [AutoTokenizer](https:\u002f\u002fhuggingface.co\u002fdocs\u002ftransf...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eThe NT's [Model Card](https:\u002f\u002fhuggingface.co\u002fInstaDeepAI\u002fnucleotide-transformer-v2-50m-multi-species) shows how to embed DNA sequences. I copied that code below for your convenience:...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eimport torch...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e    )...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e# Create a dummy dna sequence and tokenize it...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e# Compute the embeddings...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e)...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e# Add embed dimension axis...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e# Compute mean embeddings per sequence...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003emean_sequence_embeddings = torch.sum(attention_mask*embeddings, axis=-2)\u002ftorch.sum(attention_mask, axis=1)...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e```mermaid...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e    %% Process nodes...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e    %% Data nodes...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e    %% Connections...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eThe attention mask is a binary mask that, for a given input sequence, identifies the padding tokens that are there just to make the sequence fit the desired shape. They help the model avoid wasting (C...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e[Hugging Face's `pipelines`](https:\u002f\u002fhuggingface.co\u002fdocs\u002ftransformers\u002fpipeline_tutorial) exist to encapsulate these inference steps while cutting the boilerplate code. In particular, every pipeline re...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e- A function to sanitize the pipeline user-provided arguments...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eI implemented a small pipeline to embed DNA sequences. Its inputs are Python strings and the output are numpy arrays....","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e    def _sanitize_parameters(...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e        Returns:...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e        if \"max_length\" in kwargs:...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e        unrecognized_params = set(kwargs.keys()) - recognized_params...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e    def preprocess(...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e        Args:...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e        Returns:...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e        tokens_ids = self.tokenizer.batch_encode_plus(...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e    def _forward(...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e        Returns:...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e        out = self.model(...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e    def postprocess(...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e        Returns:...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e)...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eI will be using the NT to embed protein-coding DNA sequences from six species: three animals (human, mouse and fruit fly); one plant (arabidopsis); one bacteria (_E. coli_); and one yeast (_S. cerevis...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eTo this end, I [downloaded the DNA sequences](https:\u002f\u002fgithub.com\u002fhclimente\u002fhclimente.github.io\u002fblob\u002fmain\u002fassets\u002fpython\u002f2025-05-02-hf-transformers\u002fprepare_data.sh) of all protein coding genes for the s...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eI [embedded the sequences](https:\u002f\u002fgithub.com\u002fhclimente\u002fhclimente.github.io\u002fblob\u002fmain\u002fassets\u002fpython\u002f2025-05-02-hf-transformers\u002fmain.ipynb) and used a UMAP to visualize the embeddings:...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e\u003cdiv class=\"l-page\"\u003e...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e\u003c\u002fdiv\u003e...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e\u003c\u002fdiv\u003e...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eEven with these limitations, sequences from the same species tend to inhabit similar regions of the underlying manifold. If you are unconvinced, just squint your eyes or toggle some species on and off...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e{% include figure.liquid loading=\"eager\" path=\"assets\u002fpython\u002f2025-05-02-hf-transformers\u002fimg\u002fconfusion_matrix_test.webp\" class=\"img-fluid\" %}...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eThe NT was trained via MLM, and it never got any explicit information about which species it was looking at. Hence, it's not too surprising that it can't separate different species right off the bat. ...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e)...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003etrainer = Trainer(...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eWe can create a new inference pipeline focus around classification. The pipeline will output both the probability of each class, as well as the embeddings, obtained from the last layer. Since this mod...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e\u003cdiv class=\"l-page\"\u003e...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003e\u003c\u002fdiv\u003e...","\u003cb\u003eDNA language model fine-tuning and inference\u003c\u002fb\u003e\u003cbr\u003eIn this post, I have given a primer on how to use Hugging Face's libraries for a particular flavor of BioML work. Yet, in my opinion, Hugging Face's greatest strength lies just in the boundaries of th...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e{% include figure.liquid loading=\"eager\" path=\"assets\u002fpython\u002f2025-05-29-precision-matrix\u002fimg\u002fcorrelations.webp\" class=\"img-fluid\" %}...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e\u003cdiv class=\"caption\"\u003e...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e\u003c\u002fdiv\u003e...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e    Returns...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e    for i in range(p):...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e                # fit a linear model...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e                # compute and center the residuals...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e            res_1 = residuals[(i, j)]...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e{% include figure.liquid loading=\"eager\" path=\"assets\u002fpython\u002f2025-05-29-precision-matrix\u002fimg\u002fpartial_correlations.webp\" class=\"img-fluid\" %}...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e\u003cdiv class=\"caption\"\u003e...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e\u003c\u002fdiv\u003e...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eA downside of this approach is its computational complexity. For an $$n \\times p$$ input matrix:...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e- Memory complexity: $$\\mathcal{O}(np^2)$$, dominated by storing $${p \\choose 2} = \\mathcal{O}(p^2)$$ residuals, each of length $$n$$....","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eThis is quite computational intensive, which will become a problem in real-world problems. Can we do better? Enter the **precision matrix**, a nice mathematical object to do this at scale....","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eThe **covariance** between two random variables, $$X_1$$ and $$X_2$$, is defined as:...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eThe covariance takes values in $$(-\\sigma_{X_1} \\sigma_{X_2}, \\sigma_{X_1} \\sigma_{X_2})$$, and measures the degree to which two random variables are linearly related. The **correlation** $$\\rho$$ nor...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eThe **covariance matrix** of a set of random variables ties the variance and the covariance together. If $$\\mathbf{X}$$ is a column vector such that...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e\\end{pmatrix}...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eBy normalizing the covariance matrix by dividing each item $$\\mathbf{\\Sigma}_{ij}$$ by $$\\sigma_{X_i} \\sigma_{X_j}$$, we obtain the **correlation matrix**:...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e\\end{pmatrix}...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e    1                                           & -\\rho_{X_1, X_2 \\mid X_3, \\dots, X_n}          & \\cdots & -\\rho_{X_1, X_n \\mid X_2, \\cdots, X_{n-1}}      \\\\...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e    -\\rho_{X_2, X_1 \\mid X_3, \\cdots, X_n}      & 1                                              & \\cdots & -\\rho_{X_2, X_n \\mid X_1, X_3, \\cdots, X_{n-1}} \\\\...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e    \\vdots                                      & \\vdots                                         & \\ddots & \\vdots                                          \\\\...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e    -\\rho_{X_n, X_1 \\mid X_2, \\cdots, X_{n-1}}  & -\\rho_{X_n, X_2 \\mid X_1, X_3 \\cdots, X_{n-1}} & \\cdots & 1...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eLet's revisit our motivating example equipped with our newfound knowledge: instead of fitting $$\\mathcal{O}(p^2)$$ linear models, let's reach the same result using linear algebra. First, we will estim...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e```python...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e    Returns...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e    # showing how the sausage is made...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e    normalization_factors = np.sqrt(np.outer(np.diag(precision), np.diag(precision)))...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e- Memory complexity: $$\\mathcal{O}(p^2)$$, dominated by the intermediate matrices....","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eFurthermore, this implementation is [vectorized]({% post_url 2024-02-04-python-vectors %}) which further boosts performance. As a quick benchmark, on a random $$1000 \\times 100$$ matrix, the original ...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eAs with many elegant results in linear algebra, things start breaking down when our covariance matrix is [ill-conditioned](https:\u002f\u002fen.wikipedia.org\u002fwiki\u002fCondition_number) or outright [non-invertible](...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eAdding a regularization step to the covariance matrix estimation will result in a better conditioned matrix. A common approach is _shrinking_ our empirical covariance towards another matrix, the _targ...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eThe problem becomes then tuning $$\\alpha$$. A common way to compute the $$\\alpha$$ is the [Ledoit-Wolf shrinkage method](https:\u002f\u002fweb.archive.org\u002fweb\u002f20141205061842\u002fhttp:\u002f\u002fwww.econ.uzh.ch\u002ffaculty\u002fledoi...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eAlternatively, we can use graphical lasso to estimate a sparse precision matrix. Conceptually, this is a bit easier to swallow: in many situations, most variables being conditionally uncorrelated is a...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eLet's bring this point home by looking at a high-dimensional example (20 samples, 20 features)....","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e{% include figure.liquid loading=\"eager\" path=\"assets\u002fpython\u002f2025-05-29-precision-matrix\u002fimg\u002fhigh_dimensional_experiments.webp\" class=\"img-fluid\" %}...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e\u003cdiv class=\"caption\"\u003e...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e\u003c\u002fdiv\u003e...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eMore than anything, this little exercise shows how hard this endeavour is, and serves as a good caution to high-dimensional statistics. Beware!...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003eUnder certain assumptions, the precision matrix helps us discover the internal structure of the data. When should we use what to estimate it?...","\u003cb\u003eCovariance and precision\u003c\u002fb\u003e\u003cbr\u003e1. **Empirical inverse (MLE):** fast and exact, but blows up if $$p$$ approaches $$n$$ or $$\\hat \u03a3$$ is singular. Use it when $$n \\gg p$$ and $$\\hat \u03a3$$ is well\u2011conditioned....","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eBut for us, entropy is not (only) about m...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eBut for us, entropy is not (only) about messy bedrooms, but about messy _data_. That's why I will focus on _Shannon's_ entropy $$H(P)$$, which is a property of a probability distribution $$P$$. For a ...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eIn a nutshell, entropy is the average surprise we'll experience when observing a realization of $$P$$: if an outcome is rare ($$P(x)$$ is small), observing it should be quite surprising ($$\\log \\frac{...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eA more tangible interpretation of entropy links it to the _encoding_ of a message. Imagine we want to encode the outcome of a probability distribution. We observe an outcome and want to unambiguously ...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e| Weather | Probability |...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e\u003e For easier computations, let's assume that probabilities remain independent and constant over time. Which, again, isn't too far from my reality. More formally, the outcomes are independent and ident...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eEvery morning, I look out the window exactly at 9am, and send my friend the weather report. Our first instinct is probably to just text them \"cloudy\", \"rainy\" or \"sunny\" as appropriate. If we encode t...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e| Weather | Probability | Codeword                                         | Codeword length |...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eIn the long term, the average message will take $$0.5 \\times 48 + 0.4 \\times 40 + 0.1 \\times 40 = 44$$ bits. Not a big deal I guess... But we can do much better! _Why waste time say lot word when few ...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eThe [Huffman coding](https:\u002f\u002fen.wikipedia.org\u002fwiki\u002fHuffman_coding) is a common solution to this problem which significantly shortens our average message by leveraging our knowledge of $$P$$:...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e| Weather | Probability | Codeword | Codeword length |...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e**Huffman coding** builds an optimal prefix code for a known distribution. Here's how it works for our weather example:...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e   | Weather | Probability |...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e2. **Merge lowest pairs:** Combine Sunny (0.1) and Rainy (0.4) \u2192 node with weight 0.5. Then combine with Cloudy (0.5) \u2192 final tree....","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e   | Weather | Codeword |...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eHuffman coding guarantees the shortest average length for any prefix code based on the true distribution....","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eThis is much better: we have gone from 44 bits to $$0.5 \\times 1 + 0.4 \\times 2 + 0.1 \\times 2 = 1.5$$ bits on average. Of course, for this to be possible, we need to have access to the true weather d...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eAre we satisfied yet? Not quite. Despite Huffman being optimal, our message length will be the same on rainy days and on sunny days. However, rainy days are 4 times more common! The core problem is th...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e| 10-day weather | Probability | Codeword                         | Codeword length |...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e| -------------- | ----------- | -------------------------------- | --------------- |...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e| CCCCCCCCCC     | 9.77e-04    | 0111001010                       | 10              |...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eThe average length of this code is 13.64 bits, or 1.364 bits per day. Batching outcomes together allows us to spend only _fractions_ of a bit. And it's easy to see how, if we kept batching more and mo...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e{% include figure.liquid loading=\"eager\" path=\"assets\u002fpython\u002f2025-07-14-cross-entropy\u002fimg\u002fentropy-batch_size_vs_avg_bits_per_day.webp\" class=\"img-fluid rounded z-depth-1\" %}...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eAnd this brings us to the key point: entropy represents the lower bound for the average message length required to _optimally_ encode each outcome of a random process. Even with the best encoding we c...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eAll this is fine, but a lingering question remains: what's the logarithm of the probability doing there? Why aren't we using any other transformation of the probability?...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eImagine the space of all possible codewords of a prefix code. If we decide to use the codeword \"0\", every other codeword needs to start by \"1\"; that choice cost us half of all possible codewords. Henc...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eWe just saw how knowing the underlying probability distribution gave us an edge in encoding the outcomes efficiently. However, here in the real world we rarely have access to _true_ probability distri...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eFor instance, we rely on very complex models to accurately predict the weather. But let's leave those aside, and use the simple model ($$Q_\\text{Barcelona}$$) and associated Huffman code I developed f...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e| Weather | Probability | Codeword | Codeword length |...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eAs you can imagine, after moving to London, my model of the weather was not that useful. In fact, I often experienced _surprise_, as outcomes that should be rare happened often. In consequence, when u...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eEntropy quantified our average surprise when observing a distribution's outcomes while knowing the true distribution. Similarly, the **cross-entropy** measures our surprise when observing a distributi...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eThis is higher than the average message length of 1.9 bits. Contrary to entropy, which is a hard-limit, our model _can_ do better than cross-entropy. This is because the cross-entropy leverages (optim...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e| Weather | P   | Codeword length | Q-optimal codeword length | Extra ($$+$$)\u002fSaved ($$-$$) bits |...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eNotice how we're saving a ton of bits on cloudy and rainy days; we got lucky. If we batch our weather reports, we get closer to encoding individual outcomes with fractional bits. Using the 10-day Barc...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e{% include figure.liquid loading=\"eager\" path=\"assets\u002fpython\u002f2025-07-14-cross-entropy\u002fimg\u002fcrossentropy-batch_size_vs_avg_bits_per_day.webp\" class=\"img-fluid rounded z-depth-1\" %}...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eAfter a few years in London my model became quite accurate, to the extent that $$Q_\\text{London} \\approx P_\\text{London}$$:...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eThis is an important result (the [Gibbs' inequality](https:\u002f\u002fen.wikipedia.org\u002fwiki\u002fGibbs%27_inequality)):...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eSince entropy is the lower bound for cross-entropy, the difference between both informs us about how well our model reflects the true distribution. This difference is also so important that it has its...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eIt can be interpreted as the _cost of being wrong_: how many extra bits we need to spend because our model departs from the true distribution....","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eUltimately, this is why I went down this rabbit hole. We\u2019ve covered distributions, processes, and encoding. But machine learning is one of the most important applications of cross-entropy via the [cro...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eLet's bring this point home by revisiting our weather model one last time. In this case, we want a model to predict tomorrow's weather using some sensible variables (like today's weather, temperature,...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e\u003e Note that $$p$$ is the one-hot (empirical) distribution on the observed class, not the true generative $$P$$, and $$q$$ is just the model's prediction for this example, not the overall distribution ...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003eThe model will consequently update its parameters to minimize this loss, also known as log-loss. Minimizing it is equivalent to [maximizing the probability of the data](https:\u002f\u002fen.wikipedia.org\u002fwiki\u002fM...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e$$...","\u003cb\u003eCross-entropy. Intuition and applications.\u003c\u002fb\u003e\u003cbr\u003e- [Visual Information Theory](https:\u002f\u002fcolah.github.io\u002fposts\u002f2015-09-Visual-Information\u002f)...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eHowever, large swaths of data ca...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eHowever, large swaths of data can't naturally fit in a table. This is the case with corpora of text, DNA sequences, or songs. In such cases, finding _equal_ elements is still easy by, for instance, ch...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eOur goal is to find all documents in a collection of $$N$$ items (like documents, images, or songs) that are similar, though not necessarily equal, to our query item. We will represent each item in a ...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e- **Embedding the items**, that is, finding a vector representation of each item that retains as much information as possible...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e**Embeddings** are just vectors that represent a piece of content\u2014a song, a text, or [a piece of DNA]({% post_url 2025-05-02-hf-transformers %}#embedding-dna-sequences). You can think of embeddings as...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eEmbedding the items provides many advantages: where we had atomic units of unstructured data, we now have numerical representations that can be mathematically operated on. For instance, we can go from...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e\u003cdiv class=\"l-page\"\u003e...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e\u003c\u002fdiv\u003e...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e\u003c\u002fdiv\u003e...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eI just glossed over a very important detail: embedding a whole document _is a bad idea_. We can see an embedding as a lossy compression of our document. But, since the dimensionality of our embeddings...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eInstead of dealing with the whole document, it's better to split each post into semantically coherent chunks (e.g., paragraphs) and then embedded the chunks individually. The recursive character split...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eIf we wanted to find equal documents, an efficient solution would be relatively straightforward: hash them and see which ones fall in the same bucket. But that's not the task we've embarked on. If the...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eMany distance and similarity measures have been defined for different kinds of data. In the vector spaces in which our embeddings live, the most popular ones are:...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e| Measure                |               Formula               | Meaning                                                        | Range                 |...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e| ---------------------- | :---------------------------------: | -------------------------------------------------------------- | --------------------- |...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e| **Cosine** similarity  | $$\\frac {u \\cdot v} {\\|u\\| \\|v\\|}$$ | Extent to which $u$ and $v$ point in the same direction        | $$[-1, 1]$$           |...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e| **Dot product**        | $$u \\cdot v$$                       | Same as cosine, but multiplied by the magnitude of $u$ and $v$ | $$(-\\infty, \\infty)$$ |...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e| **Euclidean** distance |   $$\\sqrt{\\sum_i (u_i - v_i)^2}$$   | Distance between the tips of $u$ and $v$ in Euclidean space    | $$[0, \\infty)$$       |...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eThe cosine similarity is a common choice to measure semantic similarity of embeddings. Although I haven't found a satisfying explanation for the why, the lengths of the vectors do not carry interestin...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e{% include figure.liquid loading=\"eager\" path=\"assets\u002fpython\u002f2025-08-16-rags\u002fimg\u002fposts_cosine_similarities_heatmap.webp\" class=\"img-fluid\" %}...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e```...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eI was lucky I am not a prolific writer, and I could compute all the distances. But this operation has a time complexity of $$O(N)$$ for the simple query, which makes it expensive for large collections...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eIn the past, [I described a method to find similar items using **local-sensitivity hashing** (LSH)]({% post_url 2017-11-04-finding-similar-items %}). The idea is to hash the items in such a way that s...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e**Skip lists** are a data structure that provides $$O(\\log n)$$ search time, same as binary search trees, and also $$O(\\log n)$$ insertion time. They consist of a set of [linked lists]({% post_url 202...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e{% include figure.liquid path=\"assets\u002fimg\u002fposts\u002f2025-08-16-rags\u002fskip_list_diagram.png\" class=\"img-fluid\" %}...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e\u003c\u002fdiv\u003e...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eHNSW graphs are _indexing_ structures, i.e., every time we add a new item to our collection, we will update the graph. The graph is built in such a way that it allows us to quickly find the nearest ne...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eVector databases efficiently encapsulate the above to efficiently find similar items. I will show how to do the above using the [Qdrant vector database](https:\u002f\u002fqdrant.tech\u002f)....","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eEfficient vector search has traditionally been very used in recommendation algorithms. However, the advent of LLM has infused them with renewed interest....","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003eWhen an LLM produces an output, it uses two sources of information: its _memory_ and the _query_. The LLM's memory consists of large swaths of patterns learnt during training and stored in its weights...","\u003cb\u003eHow do vector databases work?\u003c\u002fb\u003e\u003cbr\u003e- [My previous, pre-LLM write-up on this topic]({% post_url 2017-11-04-finding-similar-items %})..."],"x":{"dtype":"f4","bdata":"6Nm5P\u002feUwD8+4r4\u002fry\u002fMPyENtD\u002fvTLk\u002fN\u002fmwP2Gepj9Kx8k\u002fN9rMPydfzz\u002fjU9A\u002fBBW7P8hIrT+UEqg\u002f\u002ffNFQC6DNED83ilAoFYoQGcMLkBgci5A1SAwQHshK0CYPS9Apv0tQInRLEAf2StAWqkuQHnILkB+2TBAYawyQHwML0DApDNATkY3QMe+L0AqxSxAfr4nQDFjKkArHihAFJ4qQHZeLkBc0ypA+1emPwFEmz+8O6g\u002fPYSeP1lAoj+ck5g\u002fpPKjPw4t7T\u002ftMeQ\u002fQUPSP\u002fxSwj8Ha98\u002fxtvNP9gW4j\u002fAr84\u002f9MDQPynj5j\u002fkvx9AhmAiQAM9HUCwQB5ApbobQI5pHECRMB1AOMgeQD8uIkAcwkBADTH3P0fTFUDCUyVA9voTQH24x0CEcvZAgZ\u002f4QJS+\u002fUCyavJAR5P7QAE790A5X\u002fpAbSn+QD43AEHhDlBB3gD8QPoq\u002fECt9QBBXqoCQbxUAEGPGgFBpsf\u002fQKSQ90CE1YFAwDnSQBWyWUDM0VhAV65UQKABX0AglFlAnG9cQF\u002fvAUGv5VxAgBFfQGwWZ0BiMFpA\u002fFBiQCjKV0Aef2FAKJyuQBOuUUCeQlFA5TFLQHp4VEBICU1AONxHQIifVUCslFlAKKZVQEmASEDmfVdA4AZGQB2DzEA1ccxADErMQOniykBPRc1A5djMQBZy0EBJbM5A+rjKQNXOz0DW4chABmHLQORSz0D8FdBA7abOQDyP0ECm9c9AiODNQLKS0EBUK8dAfjPOQEm\u002fzUB4R8pA3svJQHY+zUBEK8xAIf3MQKTfykAoWsxAUc\u002fJQHXAyED85MhAfoHLQLY0y0BX9sxArAnAQHPhwEBOIrxAZazRQGw11UDKmNZA1wbVQOyg1kCm59VADajWQIuB1kB+f9ZA0GHLQNR20EAV9s9AtkTEQIXCxEBWX71AB9G\u002fQKXgv0ArR7tAl1cgQa5vIUE7ZCVBfHguQauwN0FZ0CpBrGwfQRPLMEFXUyRB7ng1QZS0LEFt0yJB8UsgQXSYKkE7iipBLEk8QQvWKkFBSztBfcIiQZQMIUEFOiJBk9sjQWLtIEFbrSFBZ1QiQU2cIkFewiFB8kIiQbISHkHRqSFBRHUgQa5bH0EKpiZB4IgeQb3uHUGNEB9B++peQfj6IEHhbiBBOgseQWdoJEFIsRlBpFMaQZxOG0F1qhhBqQMsQdiFF0FsyRdBKCgYQYHGF0GqlBdBcBAZQUeqIkGPwChBL8AlQZ6BIUG1xSNBFJ0nQfahJkFl2DJBAEgyQb6kO0GZiihBHC0jQdHFKUHtDypB83gqQSuRLEHbkSxBLaErQR6XMEEoSDBBJaYwQZ84MEHvlTBBL9QvQeOEMEH9\u002fzJBkgAwQQGjIEGl4R5BYyYhQZZFIkGeRyJBQAYnQTFfK0E4BCRBi7wiQTzTGEE03RlBVbgXQfSaGEGB7xZBNVIYQQc2G0EuyS9B29AVQSydEEELdRBB\u002f4oTQfqRF0FeDDhBozE6QYmRPUEWjztBLMEXQZsdGUF7HxJB5z4OQSy4EUEkNxJBVPkOQdbuEEF9pg9BIRUQQZDLEEFRQA9BSXsQQTwlDkEBQxJB2t8\u002fQUBnEEF46A5BibcPQe0jDkHatgxBeskNQXwLQEGMfUJB7sxDQbfIQ0HeQERBabdCQXdBQEHcrhhBq8U\u002fQedaP0HD1BpBMC0WQbtHGEERcTtB2Us+QfypG0ExdxRBnYlAQdeLP0F6KBlB2zkXQfnNP0GJKj9BzCBAQVfYP0FXQztBBD1AQYt2QEFV1ThB+Jc\u002fQcz5PUH3x0BB1BAeQVTlHkHeMyJBZookQTgsOUEwnUJBJUlEQXi7R0HIfEFBPwtDQTXeSkHpeh9BdTxQQY7ZXkFF1l5BNUlMQUYeTkEPjV5BxxQ7QctdO0EXzj1BnwE\u002fQasQP0ENZz5BENokQSDDJ0FlYCdBzvQoQQc\u002fJ0EBjjFBzNUvQZqqLUFZKiJB1i0pQXgUKUEo9S1BOJYmQS10I0FkBTRBr7EtQUROLkEGM0tBhCQiQRtQJEGElyZBaNgiQauPKEGjgDRBYI1EQeiKQkG8\u002f0FB\u002f2QxQfu3SUHmUylBHjExQQzPNEEXGSpBLpczQfBOK0E2ui5BbRIqQfGyMEE\u002fvi5BazQvQfGdLkFxhSNBHCAiQfc0IUG4TSVBgAkeQaeaJ0HUuxtBMjMcQQL\u002fG0Fb2hlBIckbQY6jGkHEgB1B0KMdQUjtHEFZnxtBwk4bQdZ7HEFuLhtBKzQqQfeXKUGn4S9BaRkyQSj3MEEfKDNBb5Q0QYI2L0HnWy9B42w9QdJYPUHW7z9BxYY+QXByPkHA1UpB1BofQdMQUEH4Bl9BgCVfQYVGTEFtMU1BvppeQalhMUEITTFBlzcwQb10L0H+Jy5BsM4xQYS3LUGZ4jFBxtAtQWTHKkFmXShBoGdCQQcXKkHn6i1BSK8wQVqeMEFHEDJBjh0xQaaFS0GvSytB+tAsQXlGH0GBzihBGas7QXNMP0FrtTxBd\u002fJDQbysR0H4RUZBXyBBQTYXQEHpCklBIvBJQX1MSUG26klBXWA\u002fQZaYPkH50kVBpV5FQfTIRkE3EEZBFS8oQf8VRUHXbUVB1AlEQQGoRUGOnz9B3HVDQR23RUFWLzhBck1HQT3nP0F5fUBB4bhCQU5JSUFjIEpBLGZIQalISUHysT1BMvg\u002fQfedPUHV\u002f0FBTOk9QW\u002fnQkFVR0pBo3pIQeyHSEF4Vz1B73FDQfq+PkH36UBBY3E9QcWsM0FGpz1BHpc+QQAFSkEipT1Byi00QZCiN0G5vUJB99A2QcNdQEH75ERBUbhIQd3lR0FJVEhBf4RIQZlfSUHJT0lB0X1KQebjR0FuMkBBboc4QcixO0GltTlB21I6QR1gNEHWqTdBIC4zQXa8N0HVtT5BMms4QZdeOUH+4yVBouo5QQSJS0HAxDJBm5EwQW7ZLkFixUxBowZMQQfaT0GGEU9BY2xLQcTvSkFzmE9BT+BMQUCrS0GUJlBBUHtNQeJZTEF1IFBB9mFNQSg9S0F\u002fx01BqAhOQVqKTEEEV1FBdYlLQS5OTEG7gFBBm\u002flLQSVBTEFuglFBd0ZMQRF6TUEuXVVBtSNVQR0YTUHBhU9BMDhUQcGPVUGwb01BP+ZNQZhAVEE5R1RBgd5UQZGJTEEadExBK5xNQSHjTEHoxkpBn+AsQRmeLEEGkDZBfOc3QXlkMUG\u002fzS5BAJwUQcrjRUERzD9B6Nw2QTfZLEFwOzFBKwowQb0gMEHdLSxB72MyQeyrLUFfrTJBtZc0QSZ+MUHN+TNBCfwsQYIrOUFVlTNBGUE2QQsMOEHnXThBGgwtQb1CPUHqvTtBNZY9QY\u002fjP0EEZkJB8T5FQV9jQkHISCBBYNEfQXnoHkFVyR9Bo1g+QTavPkHRlj5BUIY8QVZiPkFfWz1BKdpCQdsmUkEU20hBPe5AQZQ3QEE+qT9B2xJAQXqHQkHYgUNBTmhCQZ3bFkH6jRVBvApEQZcBKUG+HytBD1MrQQgsLEFu8yxBASosQeyxLEGuFixB4OgvQWYSMUEwKC5Bq7k7QUryOEFVnS5BAGg1QWY9NUH+CDJBaoY7QdblKUETTStBD8o+QamWQUF4pT1Bbk09QYKyPUF+jzVBDSYzQafKNUGhAzZBy8k1Qf76NkETID1B6WQ8QdwYO0FC\u002fTxB3Xo+QZOZPEENUztBEig8QS9GPEFuBzpBPIw8QQivOEEcKzpBTkY+QRU1PEFjuTtBUBU6QezeOUFqvTVBg+40QVQQNEHVWDdBRIs2QVmSNEFvRDRBCeo1QYRwN0EPUTtBxmQ7QSQCP0G7lUFBDkE9QRuyOEFmdDJB4uowQcAhQEEy+jJBEnUwQX2WLEEFETBBzHkxQVy\u002fMEHTUDJB8d4sQZb+L0F7BS1Bcx4zQRoVLUEnGyxBYQovQa\u002f3LkEHFS5BJ7AuQXvbMUE69jFBp8QuQbsnL0ExKjJBX0g2QdxDN0HQNS1BcS8sQRS8FUFEXjlBf2o3QSjpNUFhYy9B4icuQUlsLEFLSy1BrMEnQSk\u002fHEHfMihBFnMtQan1K0GUOC1BKXguQRw5LkH3pS5BRXorQapFKUH1yitBDyotQXLwLUEyMC1BZ0UvQSiEMEFOhy1BXYktQXrQNEH1mz1Bcg06QUbxOkG7XDpBwzo3Qe1DNEF+UzdBzX00QWjDOkHt1jtBYr46QS+BOkGQejxBFQY+QSMSPUFR0T5BJOg\u002fQViCPkGjwaBA+OmiQEjFo0AdwaVAYhCtQH3osUBA1aVAbpajQBzroUD6f6hAnfGpQB0jqEBEDKdAfQykQODVq0BudqNAyr2kQOEzo0C0G6JAvE2iQEHox0BFjtJAdwq6QHiB0UDNZcBARtjDQN6SwUB2+sBAokTCQK6qwEBeer9AyszAQGD6vkAeE8BAstDMQHqI0kBiAtNAtg7MQBFVyEDaYMpAxWPKQHRCykCDdspAS5vPQGIF1ECH4ONAfATSQKe60EDUuwdBHBAKQZYxCEEDL9BAPzHTQHdK0UDti9BAfCXPQFa90UDP2cxA\u002fyrSQFeszECYTdJA1qLHQApJ0EBI5tJAf5fQQGQC1ECZr9NAPGfUQNSaxEC+GsJAJHWUQLZSmUBh+6BAHIKrQNTipEBA0qFAAj6iQOfZokAwTqNAR9yUQNeelEAtGZ9AVb+fQIW\u002fl0CQ1a5AqzKWQJWVlUCZOpRAnJuVQMA8k0Byz5VAWIORQH9RlUAEPZRAtD2SQELxlkCnSZZAoyC4QMvKmECyXbdA6B2cQJ6ClkCTB7ZAjSWWQIKJlEBKMbhAcZCVQEyAkUBgB5ZAG6uTQGi\u002fk0Cog5FAt\u002faXQNfVokANXRRBxTN9QE4AlEAc0ZJAeemUQK4iy0DeAsFAbY7DQK5AxUDeccNAAz+7QJRTxEAR6dBAI4zNQCxI0UCjd9lAxaLXQIRq2kCEmddAMEfQQETOvkB4D75A34O+QPNnvUA9SdpAnefAQJEbI0EoPr5A+hjZQBgv1kBZVL9AabG8QN4zxUBpoL9AHKzBQPXU0kAnNNBAxGrYQIbR2UDYJd5AeA3cQMEm3ED1+EBB3PjNQFu6zkCefdBAYQLUQP+XyUDzjMtApJbQQGBI5EA8YuVAAxjsQOvz6kBRWthAe2rXQNTN1kD1u9RA+ZnaQItG2kBELNhA7oXbQPCQ2EB46r5AuKHJQGmlzEBVJ8pAJK3JQKd800CgK8pAF\u002frJQBSyx0DWysdAq6K5QMMcvUB3Sb1AccW+QHZHwkAcyMNA+ZnAQCIMyECXW8lAzCDLQMZGwUCFxwVBV4EGQdfBuUB377lAK1oIQexpCUGfmAtByFA2QSaYCUFGEQlBr4EJQV2NBUEPBblAyKO8QH4AA0GmhylBQ2cwQa5pK0E98w1BUKEOQZWtD0GcSRBBpygPQUh5D0G42xJBAxoQQS0\u002fD0HA+AxBhQIMQVH7DEHd7gpBECQTQZpAEkGzoRJBqpsSQZwdEUFzmgxBkf4JQVsrC0G8bwtBOWkLQS22C0FI1iFBn0EzQcAEC0HJJQlBT3EIQdPSCUHz6ghBf2kIQYS5CUE6RApB0Y4IQRPMyECOV7pA\u002fNu6QBfhBUGwQ7BAP\u002foIQZojB0E1JNdAhoTaQNBf1kDL0ddAQW3WQNjP30C4Tt1ACcfdQHAA4kCgBOBAinvhQG+64EDus+FAvQThQB9KPEGHNONAV2ThQERN3ECb7d9A0XriQOhHTEA6HzxAw6HdQKkvuUA6xNhAvfzTQACm1kB1NdxASlPYQPZE3kBX9uJApancQIKR1UD3w9VAySXbQAhm3ED6PN5ANYXZQAiyuUC7y9RAxPjTQPDt0UAJHNVAbWrUQA3C2ECW4dpAM47TQMea1UC4ktFArF\u002fIQJCo00Di+cJAwufbQLqDKUGJc\u002fhANJX0QG9j8UBoduBAuXPdQNoRyUBgNdZAh9zdQNCj3UD8VNtAbkf3QBFn8kDdi\u002fZA\u002fbhRQArN8kDP+vFAfB7yQC9V8EAMDLlAYPrZQD3z+ECVgvRAg4S9QDT3ukD9vUFBQUk\u002fQfBJ9EC+QPRAn3fvQAA36UA="},"y":{"dtype":"f4","bdata":"Pfp2v0tRfb9v+3q\u002fOESGv9Iaa794UXW\u002fIGlrvywpWb96b4S\u002fPQSHvw2+ib++m4u\u002fwEJ4vywsbr\u002fvJWG\u002fyt4tQIDbKEAgtThAg8E1QDOHI0CooSRAyqYuQNifIEBijCBAjHo9QE2IPkDc5jxAriokQFI\u002fOEAhOCRA5u8yQPV0IUBRaCdAPl02QNQoJEB9LjtAG7hAQOU4P0CD9DxA5jg8QPn+IUDSWB9AXiRhv71DT7+\u002fTmS\u002fRxtav8QCXL9sYFK\u002fmi5av5Xvlr+GqZC\u002f5nmKvxtwgL9c3Ja\u002f9fWJv8Dmmb\u002fS\u002f4y\u002fXkaNvy83k79FRLW\u002fdIC\u002fv2\u002fttr879bq\u002fZu23v3bcu78fnba\u002fzCy4v6SCtL8z1ri\u002fjSGdv954q79J47a\u002fZh2qv6S6UEDkeyxA6NUlQF1bI0B7OAtAyGgcQBN5JUAWlCpABdEwQHrtLECOZMNApXcwQJoLKUCWTi5AK18rQP8QKUCbCStAYaopQO0BJ0B3lae\u002fIgaOPZ1iy7+FTc6\u002f+J3Hv7MnxL9WFsS\u002f+KLJv1fckT43cr6\u002fRtS9v5vUqL9sra+\u002fqDK7v4Nux7+U+La\u002f+akPv9JRu7\u002fBZ72\u002fR+vAv8g2wr8ARri\u002fW56yv0Lux78ZLsi\u002fLmDOv2wmt7+S+8y\u002fTCq8v8cjqr5lpsG+TxievtVblL40Na6+iUp2vrp5D78mF5q\u002fBbq7v4BKhb980Mi\u002fYWC4v17Chr9BUXq\u002f+naav7AAdb+l03q\u002f8BGmv3ODgL\u002fz7b+\u002feCaVv4sjbL+YP36\u002fUCSEvyUdgb8Nh76\u002fQT7Hv1UUy7\u002f6R8i\u002fN8vGv5OEyr9rL62\u002fsXnMv8EQz79Nksi\u002fw2UVvxVBML8MtDO\u002fDOsgvzOANr+cky+\u002fuu1Qv4CLRr\u002fbAEO\u002f3l49v1OROr+ngDS\u002fRESEvlsLP72JFIG+4rXIvjtrAb\u002fQM76+p9q9vhLK4b6rGty+NMTtQHVb7kCMrshAwibOQFErv0DHEs5AgNPsQMlD1kBuVMJAX6LJQI6P0EDoQupAymDwQOSGzUANks5AjZW4QIH0yUAh\u002fbpAk8XuQKGK+0CGof5Adjr8QEs+9ED7qfxAycP\u002fQFuz\u002f0AssftA7vb\u002fQJwe70DWgQBBHjHyQHm78EDTTfdAT8zuQBCu7UCHQ+5AKimQQBqi4kCRCvtAxkvoQAqa4EDS0\u002fZAmEv8QBmW+0A6VP5ADij3QBBn\u002fkBgqP9Anb\u002f\u002fQEAz\u002fkBNAgBBAkMAQWfx30BRdd5AqGTZQDsh1ECoqc1AgTvXQP2Q20AeyMlAPjHJQHhUuECZaddAwjrEQIZbA0Fz+ANByIYDQbO\u002fBkFByAZB8ZYFQfwGCkEj4QpBT6sKQe+nCkF0+gpBc2EKQfqbCkFYygZB7v4JQe40u0Azq7dAyHW+QE+dy0Dqgs5AkufvQAvPsUCTrNxALobVQKoK5ECDycVAv2DCQL4bxEDXh8JAujfCQNw\u002fwUAkQsVA5ZXBQDy3zUDNJc5A7MPGQN7jv0AWH3FA3dh\u002fQEvzdkBuj29AAkbLQCXj5EDUHNlAo5nQQELW2UAMrNxAnp7UQHv+2EAsMNhAjU7dQAjs20B2Y9lAPefaQCpC0UB+FNRAfeKyQNU000ANTdVAWdvSQI5R0kDztdBAfnLTQOCtrkDXBNVA\u002fNXTQMUY00DwFNNArYfSQPFgBEGV3OJAdEoEQVUrBEH4G+VAKVXgQBbY5ED8OQFBHhMEQVGe4kA+1eFACn0EQc6eA0GxQudApsPjQLz1A0GMTwRBer0DQcpbA0HXDNZA8\u002fADQTCoAkGbc9RAnrwEQR07w0A6zwJBzz7cQL7uuEBISsFAySq9QDjzhUDSM4NA6h2AQH3Ug0AVTHxA2WF9QKMRhkB5D\u002fhAdBOGQHIUj0Aol45ABP+EQBuUhUDUXY5AXdPHQDB7wkAOOMZAK+K5QI4bvkBeGr9AOtLUQKnr4kDka9ZAW4\u002faQAX23ECgE\u002fFAsZDvQNGx7UA+m\u002fBArwGrQLjWr0DvZrFAspS2QAZLskAfma5AGRqwQGYgsEAP17pAwmCsQC2os0DNRbFAaxawQGoirUAwualAdvWqQAKEqUC4NKdAGo2xQLHHf0BQ\u002fK9ADc2rQOPCqUCr+LFAPDKrQP4Ft0A16r5A64GzQPoDtUAayrtAWsK+QO2evEDDhrFA\u002fdywQEIIrkA43K9AhUaoQPuhqEA8caVA80uqQNMtq0AiZ7ZAzY6vQLLLsEDOJbFAAZytQPhurkBGmapA9uurQKKyq0BIwahASy7lQPTP40CJU+lA\u002fBrUQEBux0CNSvJAqI7xQLv+y0DF9eVA3SLBQJdlwUB6B8hA\u002fOnDQIXow0A\u002f8YRAs\u002fr4QGUKhkCsHo9AdRyPQGWwhECdS4RAJkyOQGwV0kASSMdAEPrIQCOq2kAVNcJA0IO6QE9D1UCsfPRAEXXsQAc+5UCJMOFAoo\u002fGQJ2Z30DRy8RAX2jHQIdIy0AR+s9AldjMQIjZyUBZUOdAjavnQOY6uECqJuJAjYRjQK2LhkDJ+YJAYimCQP1ceUCdLnhA5blsQJGZq0DopYtAEYmKQLP0jUBDRY5Aj\u002fmsQMEBrECNgnFAcGNgQOUqTEBje0VA6hi\u002fQPlStUAQnLJAn7dKQBTHSUDL4zZAvTEwQFmnO0B7ZZNAu\u002fMtQJbyNUCN2\u002fI\u002fn3MQQNK0GUByKx1AoeQgQOqEG0CVOFhAL7lJQEZ1nz\u002fWMgNAIOrSP8wRB0AI9xhAVS0eQIAYHkAXNFVACeZlQE7ATEDt+VpAEUQ5QC8IsD8wmnVA1A52QJawokBpWXpAGYBDQCyzTEAfXx1Ae66LQBqePUAH95xA95ekQG\u002ftqkCiuqlAkJ6tQE5irED1EKtAH2OqQJ3joUCBVrZAVxReQJ4iWkA5WmFA84FlQNhzkEDD61pApE9IQP7bUkCxNDdAF6FfQG0HZ0DxZGtA64BoQFxmqUCuP0pA3KNXQG5LSkCUX7pA93m7QI2ixECvRLtA+bm4QAQey0CiLMhAjvnNQKHcy0CexMdAIs\u002fQQM8yzEATfMhAXhvQQFAnrUDG465AeCeyQAcgt0ADbbBAjEe1QK0yt0C4pbBAqHy3QAkIuUCuY7FAZN62QPm9xkBgoLZAjkm3QK1rzUC6FsVAFAi3QPUpuUDrgs5A74nHQBqft0CkXbtAoIq3QE4f0UAVudNAN3XRQKUWz0CKy9FAXNg5QCrcOEAdLXNA46NsQNDyT0CiokFAhSHBQEeYe0Bs\u002fg1AcfRAQKuLNkBZGE9AjKtIQHcdVEBzHjdAhJxFQDOOPEAKWn9AyCNaQNJRY0D7jXRA8uQ5QHNHakBXM15AQ\u002fViQLbJZ0D9EFhAo145QOY2CT96f94+MNjwPv46G0CzeCVAPKswQDTyOUAxfKFAnnymQL3BokACs6RA8EJAQJseKEA+zB1AP3JMQEj2NECJVjpAuoQXQJZ+rkA5eZNAKGgfQPoGIEAcrSFApcArQNceKkBYyiZA65MnQP0\u002fvkDHGL9AzvlrQFl9mkD8WZlAtE2ZQGJeo0DJgp9A2PKaQI3pmUCTwJlAy36kQIL0pEBqqJ5AwXSEQONukkDwM5tAqNWhQMwto0DXKcNAakjEQCcRt0DHxphA\u002f19NP98qoD8AXKFAFqloP3SpLj\u002fQ3To\u002fD0XVPtICUj9S9ko\u002fXlw6P8SGUD8hql0\u002fkuZfP0WjYz8j1JA\u002fHXCcP86OkT+a8Is\u002fEP6QP2QfAT9AYRw\u002fAqePP+YSTT\u002f8nlk\u002fCp6KPywljj8oc4o\u002fa1GDPwrqgj9dVDw\u002fO9dDP40JJD9ubR4\u002flnMtPySFHj\u002fSFSQ\u002fM+lNP\u002fUHST9FQIA\u002fBdl8P5\u002fIoj8lA44\u002faRaZP9iDcD\u002fWLtg7NPRxPSiUij+51CA\u002f0LwSPk0cZ72\u002frlA+fYqsPr6hNj7QSg8\u002fL6xPvTd7Nr+Z5sO+mk4WP6\u002f2jrymOhe+FafZvrVgzb6wLNK+wIJAv28bZL6h5KW+QDy7vrts2b7CJpy+hFxovnzhML6aNMG+gWe8vpIjxbqjCgq96SVKvgeOcL7yRGC\u002fFYF6v1wrdL+fYIC\u002f4Twbvzh8jr4ULze\u002fzlWEv0Xbq74gVX+\u002fzI54v7Cshr9OlBS\u002fPvnkvuwB975w+wC\u002fhxV+v5EJhL+IQ4q\u002f5bVvvzjxTb\u002fZQnG\u002fqfdQv\u002fUjhL7KGNU+nShAPkbZDT7DQf49KA6pPjyhlj5ZNp8+SWGyPubFUz4wgec9ZqkZPmop8z2vcZk+Ry36PvKCgD6BVbc+2eKaPqgDoT5UDZ+\u002fJ\u002fugv0+rj7\u002ffjoy\u002fNDL6vk6GJr+r1Hq\u002fihmOv+FVk7+v8JW\u002f17Zmv4XUfb+7iIK\u002fvoaZv3w8Ur\u002fAlJ+\u002fWIOHv5Hykr8+IqW\u002fpXKDv1UF9UCI4dBAO144QJy45kDH2fdAu7v1QPPk90DBnfhAJkD3QJmH9kDPw\u002fhAHhf4QCfq+EAumfhAN3TwQCHV6UD\u002fYuRABmzvQAd79EC+KPNAOjvxQP0x80BqO\u002fNAzLPtQMdu6UBfgZxA\u002fgrsQLvN7EAAcdJAsCfTQPDh00DENOpAUAnqQKAP7UCE8+tAfB3uQGvt7ECbePFA0EnrQCEJ8UB0pdNAVoLxQN6z6EBzWuVAIPbpQKjM50ANbtJA1ZbPQJEj9kBZyvZAu2yiPzTylT8Rjng\u002f5OFKP301ZD9DrHE\u002fkSV0PxBZbj9ya2o\u002fk3+fP+a0oT88UIA\u002fJBd3Pxbalz9z\u002fCc\u002fZBuOP3G0kT9Typc\u002fDUKQP9iNmz+YKYM\u002fdpGeP0nQsT\u002fgv7A\u002fyFKjP9XOsj\u002f\u002fB7k\u002fo9swQCs0xT9rHi9ASNbYP4cPuT\u002funitA7CW5P+gNrj8B\u002fTBAjWqqP1TDpz\u002fN2Jk\u002fx5GgP6PPkD+slos\u002fFQWBvinNZ7+jd4s9lUSAv1tJpL7gl5g\u002fA2OjP6wHjEB+apNA3xuPQLf1jUD6doxAStI4QPfFaEB5NYlAQ7eJQKHwiEA9cIdAR4WJQGjqikAkOY9AXjSEQKoKlEBFFJJA0RuUQNzTm0A50JhAj1ufQGiS5kBaLplA\u002feeYQKlHkEBvhpZA7FuaQJDyjEARbZdAL9CaQDE\u002fkEAWt5JAFTqYQOl8lUA6wpdAztiTQHj9lEBNk5o\u002fUPqRQO7Tj0DX4pFAYG2LQBf9lUCNeY9AFuiNQGGBpkBmRqdAXEuqQNq9qkCgg55AUxmeQPdooEAFy5xAbcaeQLm5nUAb1JtAZwSdQG7em0C1kZZAEfiQQExGhkDt6H9ATemDQESidkDxq1ZA7dRrQMFQgEBLJnxARbM0QPaZlEAfWJxAGfydQBAroUD3H55AmuqfQFOUdUCZMFRArV5nQBKKkUCUldo+AhvdPu5gMkB6Ay9Aq2YSP6piBj90p8w+QvujQOwI2j6YMOY+pBcIP3aD6j6bsjFA6j8qQHOcrj6FR25ATkRpQIlVaEDcjpY9\u002f\u002fWdPaKhCz67iMs9otQjPshVwj0xQxU9hJ3cPS4jxj0INZI+8+mtPm3ENr1rMOC9uTpQPbS1Zj2OaIE9SPxdPbZBNDqLdZg+Az1QPrBX4j6zm+Y+eacGP9X17j7j5J5AB9dnQK\u002f2KD+JhPK9OngHvhK0A75l7Su+Kl41vpQaN75EAxe+Q\u002fNOvoABTkAxCTVAPUwsQD\u002fVEL5Q6De\u002f\u002fv5UPTn64b2m0ZrAIkKdwKW5m8BLuZjAnqqZwLAJrsCKFKrA\u002fE2swJVjsMALQ67AocivwLG1r8C9KbDAUiuvwIxUKkBqGrLA\u002f9uvwDhHq8A6Va7AGxqxwH3JOEDfPj9AD4yrwKmYM0AUbqDAHYibwLiqncCf7afAMTyYwGctrMDus7HAkzOqwBzGmMDeQ5jAAvyowFUBqsAHcazADa2lwJYkNED1tJ7AAAGfwOeGmsBAmpfAJfqewLwymcCufaTA+TeWwOUwlsBzXcG\u002fX1c7vxz1jcCBp0u\u002fHkCRwGp6lkAcAixAAZMtQOo6MkBacU5Ais5PQAV6VEA2bFVA\u002fkxPQLzaU0DnUltAezQlQLZkG0DrtA9A7mc0QNgnC0DoVwdAY\u002fUIQGaMEUDuLjFAyQJVQMm5JUCn7ytAapw2QJweNUCTjXs\u002f+08qP\u002fIRMUA+gjJAdCJAQEkhPUA="},"type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"#C8D4E3","linecolor":"#C8D4E3","minorgridcolor":"#C8D4E3","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"contour"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"histogram2d"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scattermap":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermap"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"#C8D4E3"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""},"bgcolor":"white","radialaxis":{"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"yaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"},"zaxis":{"backgroundcolor":"white","gridcolor":"#DFE8F3","gridwidth":2,"linecolor":"#EBF0F8","showbackground":true,"ticks":"","zerolinecolor":"#EBF0F8"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"baxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""},"bgcolor":"white","caxis":{"gridcolor":"#DFE8F3","linecolor":"#A2B1C6","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"#EBF0F8","linecolor":"#EBF0F8","ticks":"","title":{"standoff":15},"zerolinecolor":"#EBF0F8","zerolinewidth":2}}},"xaxis":{"showgrid":false,"zeroline":false,"showline":true,"ticks":"","showticklabels":false,"linecolor":"black","linewidth":1,"title":{"text":"UMAP 1"}},"yaxis":{"showgrid":false,"zeroline":false,"showline":true,"ticks":"","showticklabels":false,"linecolor":"black","linewidth":1,"title":{"text":"UMAP 2"}},"margin":{"l":50,"r":180,"t":50,"b":50},"legend":{"orientation":"v","yanchor":"middle","y":0.5,"xanchor":"left","x":1.02},"colorway":["#4C78A8","#F58518","#E45756","#72B7B2","#54A24B","#EECA3B","#B279A2","#FF9DA6","#9D755D","#BAB0AC"]},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('umap_plot');
if(gd) {
  gd.on('plotly_click', function(data) {
    var pt = data.points[0];
    var url = pt.customdata;
    if(url) { window.open(url, '_blank'); }
  });
}

                        })                };            </script>        </div>
</body>
</html>