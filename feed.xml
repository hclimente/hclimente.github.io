<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://hclimente.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://hclimente.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-21T00:22:08+00:00</updated><id>https://hclimente.github.io/feed.xml</id><title type="html">blank</title><subtitle>Data Scientist. Machine learning + Genetics. </subtitle><entry><title type="html">How do vector databases work?</title><link href="https://hclimente.github.io/blog/rags/" rel="alternate" type="text/html" title="How do vector databases work?"/><published>2025-08-09T11:59:00+00:00</published><updated>2025-08-09T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/rags</id><content type="html" xml:base="https://hclimente.github.io/blog/rags/"><![CDATA[<p>A big part of data science revolves around structured data, data that can be neatly organized into tables. We love tables: they can be easily sliced, diced, summarized, and filtered using SQL or another similar language. To check if an item exists in our table, we can do that quickly by querying for rows matching certain criteria.</p> <p>However, large swaths of data can’t naturally fit in a table. This is the case with corpora of text, DNA sequences, or songs. In such cases, finding <em>equal</em> elements is still easy by, for instance, checking bit-wise equality. If we are feeling fancy, we might even do that efficiently using hash functions. However, <em>approximate matching</em> is even more important here. We want all the versions of <a href="https://www.youtube.com/watch?v=dQw4w9WgXcQ">our favorite song</a>; all the pieces of news reporting on the same event; all the pictures containing a cat. This is where vector databases come in.</p> <h1 id="formalizing-the-problem">Formalizing the problem</h1> <p>Our goal is to find all documents in a collection of \(N\) items (like documents, images, or songs) that are similar, though not necessarily equal, to our query item. We will represent each item in a \(D\)-dimensional space. This problem can be decomposed into three subproblems:</p> <ol> <li><strong>Embedding the items</strong>, that is, finding a \(D\)-dimensional, meaningful vector representation of each item</li> <li>Computing the <strong>similarity between items</strong></li> <li>Efficiently <strong>finding the nearest neighbors</strong> of the query item</li> </ol> <p>Let’s zoom in on each of these subproblems, then see how they come together in the context of large language models (LLMs) and retrieval-augmented generation (RAG).</p> <h1 id="the-embeddings">The embeddings</h1> <p><strong>Embeddings</strong> are vectors that meaningfully represent a piece of content—a song, a text, or <a href="/blog/hf-transformers/#embedding-dna-sequences">a sequence of DNA</a>. You can think of embeddings as the document’s coordinates in some arbitrary, very high-dimensional space. Related documents inhabit nearby regions of this space. If this sounds confusing, Simon Willison has a <a href="https://simonwillison.net/2023/Oct/23/embeddings/">great introduction to embeddings</a> that I recommend reading.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-08-16-rags/embedding.webp" sizes="95vw"/> <img src="/assets/img/posts/2025-08-16-rags/embedding.webp" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> High-level diagram on embedding a text document. First, the document is converted into a context unaware numerical representation, a vector of integers called <em>tokens</em>.<d-footnote>The rule of thumb in English is that one token equals 0.75 words. For instance, "the" is usually one token, but "unbelievable" could be three ("un", "believ" and "able").</d-footnote> This tokenized version of the document is the input of a language model. Note that some of the tokens from the original document are truncated out, since the document is longer than the encoder's fixed context window. The language model finds a context-aware representation of each token, resulting in one vector per token. Finally, these vectors are pooled together, e.g., by taking their mean, to obtain a single vector representing the whole document. Semantically-similar documents will be close to each other in the embedding space. </div> <p>Embeddings are computed by a <strong>pre-trained model</strong>; they are often one of the intermediate representations of the model. This ensures two things. First, that the embeddings are <em>meaningful</em>. After all, the model learned a good representation of the data during training.<d-footnote>As long as the training data is representative of our use case</d-footnote> This also ensures that semantically similar items are near each other. Second, that they have the <em>same dimensionality</em>, since we obtain all the embeddings from the same layer from the same model. Hence we can compare them and neatly arrange them into a matrix.</p> <p>Embedding the items provides many advantages: where we once had amorphous blobs of unstructured data, we now have numerical representations that can be mathematically operated on. For instance, we can go from the 29 individual posts in my blog to a \(29 \times 384\) matrix of their embeddings. We can try to visualize their representation in two dimensions using <a href="https://umap-learn.readthedocs.io/en/latest/">UMAP</a>, a popular dimensionality reduction technique:</p> <div class=".l-body-outset"> <iframe src="/assets/python/2025-08-16-rags/plotly/posts_umap.html" frameborder="0" scrolling="no" height="550px" width="100%"></iframe> </div> <div class="caption"> Scatter plot of the two UMAP dimensions from the 384-dimensional embeddings computed by applying the <a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2">all-MiniLM-L6-v2</a> LLM to my 29 blog posts. This model <a href="https://sbert.net/docs/sentence_transformer/pretrained_models.html#original-models">provides a good tradeoff</a> between performance and computational efficiency. They are colored by their highest ranking tag. Hover over the post to see the title; click on it to read the post. </div> <p>We can see that posts with similar tags are neatly close to each other. But the embeddings offer a bit more nuance than that. Posts about statistical methods live near those about machine learning. The post about <a href="/blog/hf-transformers/">data structures</a> lives between the posts related to Python and those discussing graphs.</p> <details><summary>Python implementation</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">from</span> <span class="n">fastembed</span>
<span class="kn">from</span> <span class="n">fastembed</span> <span class="kn">import</span> <span class="n">TextEmbedding</span>

<span class="c1"># Small, high-quality model that is lightweight on CPU
</span><span class="n">MODEL_NAME</span> <span class="o">=</span> <span class="sh">"</span><span class="s">sentence-transformers/all-MiniLM-L6-v2</span><span class="sh">"</span>

<span class="n">model</span> <span class="o">=</span> <span class="nc">TextEmbedding</span><span class="p">(</span><span class="n">MODEL_NAME</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_embeddings</span><span class="p">(</span>
    <span class="n">texts</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">model</span><span class="p">:</span> <span class="n">fastembed</span><span class="p">.</span><span class="n">text</span><span class="p">.</span><span class="n">TextEmbedding</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Compute embeddings using fastembed models.</span><span class="sh">"""</span>

    <span class="n">embeddings</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">embed</span><span class="p">(</span><span class="n">texts</span><span class="p">))</span>
    <span class="n">embeddings</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">embeddings</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">embeddings</span>
</code></pre></div></div> </details> <p>However, I just glossed over a very important detail: embedding a whole document <em>is a bad idea</em>. We can think of an embedding as lossy compression; and, since the dimensionality is fixed, cramming more content means losing more information. Not too unlike stuffing a novel into a tweet. That’s why many popular embedders are trained on sentences and short paragraphs, not on long texts. In fact, <code class="language-plaintext highlighter-rouge">all-MiniLM-L6-v2</code> only used the first 256 tokens of each post and discarded the rest.</p> <p>Instead of dealing with the whole document, it’s better to split each post into semantically coherent chunks (e.g., paragraphs) and then embed the chunks individually. <em>Recursive character splitting</em> is a simple strategy to get reasonably-sized chunks. It starts by splitting the document into paragraphs. Most paragraphs will be shorter than the model’s context window, and are ready to be embedded. But those that remain too long are further split into sentences; and, if these are still too long, it keeps going, splitting them into subsentences, words and, finally, into individual characters if absolutely needed. Additionally, it is a good idea to pad each chunk with content from the preceding and the following chunk to ensure that some context is also considered by the model.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-08-16-rags/embedding_chunks.webp" sizes="95vw"/> <img src="/assets/img/posts/2025-08-16-rags/embedding_chunks.webp" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> High-level diagram of the embedding of the chunks of a text document. The steps are the same as in the embedding of the whole document, but now we first split the document into smaller chunks. Each chunk is then embedded individually, and hence its closest neighbors in the embedding space might or might not come from the same document. </div> <details><summary>Python implementation</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">split_text</span><span class="p">(</span>
    <span class="n">text</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">split_chars</span><span class="p">:</span> <span class="n">List</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="se">\n\n</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="se">\n</span><span class="sh">"</span><span class="p">,</span> <span class="p">[</span><span class="sh">"</span><span class="s">. </span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">! </span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">? </span><span class="sh">"</span><span class="p">],</span> <span class="sh">"</span><span class="s">; </span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">, </span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">],</span>
    <span class="n">max_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="sh">"""</span><span class="s">Recursively split text into chunks no larger than max_size.</span><span class="sh">"""</span>

    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_size</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">text</span><span class="p">]</span>
    <span class="k">elif</span> <span class="ow">not</span> <span class="n">split_chars</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">text</span><span class="p">[:</span><span class="n">max_size</span><span class="p">]]</span>

    <span class="n">splitter</span> <span class="o">=</span> <span class="n">split_chars</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">splitter</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">splitter</span> <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">splitter</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="sh">"</span><span class="s">|</span><span class="sh">"</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="nf">map</span><span class="p">(</span><span class="n">re</span><span class="p">.</span><span class="n">escape</span><span class="p">,</span> <span class="n">splitter</span><span class="p">))</span>
    <span class="p">)</span>
    <span class="n">splits</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">re</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">splitter</span><span class="p">,</span> <span class="n">text</span><span class="p">.</span><span class="nf">strip</span><span class="p">()):</span>
        <span class="n">splits</span><span class="p">.</span><span class="nf">extend</span><span class="p">(</span><span class="nf">split_text</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">split_chars</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">max_size</span><span class="o">=</span><span class="n">max_size</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">splits</span>
</code></pre></div></div> </details> <p>I applied this strategy to my 29 blog posts, obtaining 1,388 chunks of text. I then embedded each chunk individually. Here is the UMAP plot of the resulting embeddings:</p> <div class=".l-body-outset"> <iframe src="/assets/python/2025-08-16-rags/plotly/paragraphs_umap.html" frameborder="0" scrolling="no" height="600px" width="100%"></iframe> </div> <div class="caption"> Scatter plot of the two UMAP dimensions from the 384-dimensional embeddings computed by applying the <a href="https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2">all-MiniLM-L6-v2</a> LLM to my 1,388 chunks of text from my 29 blog posts. They are colored by their highest post of origin tag. Hover over the point to see the title of their post of origin and the first words of the chunked text. </div> <p>The results here are now more nuanced. In general, the points are grouped by their post of origin, denoted by their color, which is a good sanity check. On the top right we find chunks coming from my posts on Python, which are understandably quite similar.</p> <h1 id="the-distance-measure">The distance measure</h1> <p>Now that we have a numerical representation of our items, we can start comparing them. But how do we define <em>similarity</em>?</p> <p>If our goal was to find <em>identical</em> documents, an efficient solution would be relatively straightforward: hash them and see which ones fall in the same bucket. But that’s not the task we’ve embarked on. If the number of documents is large enough, eye-balling the UMAP plot is not an option either. We need a <strong>distance</strong> measure, a function whose inputs are two items and whose output is a real value telling us how <em>far</em> they are. The distance will be small when the two items are alike, and large when they are not. Analogously, we can define a <strong>similarity</strong> measure, which is inversely related to distance.</p> <p>Many distance and similarity measures have been defined for different kinds of data. In the vector spaces in which our embeddings live, the most popular ones are:</p> <table> <thead> <tr> <th>Measure</th> <th style="text-align: center">Formula</th> <th>Meaning</th> <th>Range</th> </tr> </thead> <tbody> <tr> <td><strong>Cosine</strong> similarity</td> <td style="text-align: center">\(\frac {u \cdot v} {|u| |v|}\)</td> <td>Extent to which $u$ and $v$ point in the same direction</td> <td>\([-1, 1]\)</td> </tr> <tr> <td><strong>Dot product</strong></td> <td style="text-align: center">\(u \cdot v\)</td> <td>Same as cosine, but multiplied by the magnitude of $u$ and $v$</td> <td>\((-\infty, \infty)\)</td> </tr> <tr> <td><strong>Euclidean</strong> distance</td> <td style="text-align: center">\(\sqrt{\sum_i (u_i - v_i)^2}\)</td> <td>Distance between the tips of $u$ and $v$ in Euclidean space</td> <td>\([0, \infty)\)</td> </tr> </tbody> </table> <p>The cosine similarity is a common choice to measure semantic similarity of embeddings. The intuition is that vector direction matters more than magnitude—two documents about the same topic should be similar regardless of their length. Furthermore, in practice negative cosine similarities between embeddings are rare, so the range of interest is really \([0, 1]\).</p> <details><summary>Python implementation</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">cosine_similarity</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Compute the cosine similarity matrix between the rows in X.</span><span class="sh">"""</span>
    <span class="n">norms</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">X_norm</span> <span class="o">=</span> <span class="n">X</span> <span class="o">/</span> <span class="p">(</span><span class="n">norms</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>  <span class="c1"># Add epsilon to avoid division by zero
</span>    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">X_norm</span><span class="p">,</span> <span class="n">X_norm</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
</code></pre></div></div> </details> <p>For instance, here is the similarity matrix between all 1,388 text chunks:</p> <div class=".l-body-outset"> <iframe src="/assets/python/2025-08-16-rags/plotly/paragraph_similarity_heatmap.html" frameborder="0" scrolling="no" height="550px" width="100%"></iframe> </div> <div class="caption"> Pairwise cosine similarities between all 1,388 text chunks. </div> <h1 id="nearest-neighbor-search">Nearest neighbor search</h1> <p>Let’s say we are interested in the 5 chunks most related to interpretable machine learning. A way to finding them is to compare the embedding of our query (<code class="language-plaintext highlighter-rouge">Interpretable machine learning</code>) against that of all my chunks. Here are the five chunks with the highest cosine similarity:</p> <table> <thead> <tr> <th>Post title</th> <th>Cosine similarity</th> <th>Text sample</th> </tr> </thead> <tbody> <tr> <td>SHAP values</td> <td>0.514</td> <td>Machine learning models like linear regression…</td> </tr> <tr> <td>SHAP values</td> <td>0.505</td> <td>- Interpretable Machine Learning: Shapley valu…</td> </tr> <tr> <td>SHAP values</td> <td>0.403</td> <td>To establish the connection to Shapley values,…</td> </tr> <tr> <td>SHAP values</td> <td>0.391</td> <td>Let’s understand SHAP values better by looking…</td> </tr> <tr> <td>SHAP values</td> <td>0.388</td> <td>Global explanations can be derived by aggregat…</td> </tr> </tbody> </table> <p>I would say the search worked reasonably well!</p> <p>However, this brute-force approach has a time complexity of \(O(D \cdot N)\), where \(D\) is the dimension of the embeddings (384) and \(N\) is the number of chunks (1,388). For large collections, this becomes prohibitively slow. That’s why we need approximate methods that can find good matches efficiently.</p> <p>In the past, <a href="/blog/finding-similar-items/">I described</a> a method to find similar items using <strong>local-sensitivity hashing</strong> (LSH). The idea is to hash the items in such a way that similar items are likely to fall in the same bucket. This way, we can quickly scan over a corpus and find the items that are similar to our query. However, LSH has high memory requirements and requires careful parameter tuning. Here I will focus on <strong>hierarchical navigable small world graphs</strong> (HNSW) instead, a more modern method that is the backbone of vector databases. They build on two concepts: <em>skip lists</em> and <em>navigable small world graphs</em>.</p> <details><summary>Skip lists</summary> <p><a href="/blog/data-structures/#skip-lists"><strong>Skip lists</strong></a> are a data structure consisting of a set of <a href="/blog/data-structures/#linked-lists">linked lists</a>, containing nested subsets of the items in the collection:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-08-16-rags/skip_list.drawio-480.webp 480w,/assets/img/posts/2025-08-16-rags/skip_list.drawio-800.webp 800w,/assets/img/posts/2025-08-16-rags/skip_list.drawio-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-08-16-rags/skip_list.drawio.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Example of search path for a value (9) in a 5-layered skip list. </div> <p>The topmost list contains only a few items, while the bottommost list contains all the items. Each item in a list points to the next item in the same list, and also to the next item in the lists below it. This allows us to quickly traverse the lists and find or insert items in logarithmic time with high probability.</p> </details> <details><summary>Navigable small world graphs</summary> <p><a href="/blog/graph-properties/#small-world-graphs">Small world graphs</a> are graphs with two key properties: small mean shortest-paths and high clustering coefficients. The classic example is the “six degrees of separation” phenomenon in social networks, where any two people are connected through at most six intermediate connections.</p> <p><strong>Navigable small world graphs</strong> extend this concept by ensuring we can find a path between any two nodes via a greedy strategy that chooses the neighbor closest according to a <a href="#the-distance-measure">distance function</a>. The key insight is that not all small world graphs are navigable: you need the right balance of local and long-range connections.</p> <p>In a navigable small world graph:</p> <ul> <li><strong>Local connections</strong>: each node connects to its immediate neighbors (high clustering); they are akin to <em>local streets</em> in a city.</li> <li><strong>Long-range connections</strong>: some nodes have connections that “jump” across the graph (short paths); they are akin to <em>highways</em> connecting distant parts of the city.</li> <li><strong>Greedy navigability</strong>: at each step, you can always find a neighbor that gets you closer to your target.</li> </ul> <p>The challenge is constructing these graphs so that the greedy algorithm actually works. If you have too many random long-range connections, you might get stuck in local optima. If you have too few, the paths become too long. The magic happens when the probability of a long-range connection decreases with distance \(d\) in a specific way (roughly proportional to \(1/d^k\) where \(k\) is the dimensionality of the space).</p> </details> <h2 id="the-search-algorithm">The search algorithm</h2> <p>HNSW graphs combine the layered structure of skip lists with the navigability properties of small world graphs to create an efficient approximate nearest neighbor search algorithm.</p> <p><em>Like skip lists</em>, HNSW graphs are organized in layers (typically 3-6 layers). The bottommost layer contains all the items in the collection, while the upper layers contain progressively fewer items. Each item has a randomly assigned maximum layer level, with the probability of being in a given layer following an exponential decay. This ensures that most items are in the lower layers, while only a few “hub” items exist in the upper layers,</p> <p><em>Like navigable small world graphs</em>, each item in a layer is connected to several of its nearest neighbors in the same layer. Additionally, items connect to themselves in lower layers, creating vertical connections that allow movement between layers.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-08-16-rags/hnsw.drawio-480.webp 480w,/assets/img/posts/2025-08-16-rags/hnsw.drawio-800.webp 800w,/assets/img/posts/2025-08-16-rags/hnsw.drawio-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-08-16-rags/hnsw.drawio.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Example of search path for query item in a 3-layered HNSW graph. </div> <p>The search process is what makes HNSW particularly effective:</p> <ol> <li><strong>Start high</strong>: begin at the top layer with a default entry point</li> <li><strong>Greedy descent</strong>: at each layer, greedily move to the neighbor closest to your query</li> <li><strong>Layer transition</strong>: when you can’t improve further, drop to the next layer down</li> <li><strong>Refine at bottom</strong>: perform a more thorough search in the bottommost layer</li> </ol> <p>This multi-scale approach allows HNSW to quickly “zoom in” on the right region of the space. The upper layers provide coarse navigation (like highways), while the bottom layer provides fine-grained search (like local streets).</p> <h2 id="vector-databases">Vector databases</h2> <p>Vector databases like <a href="https://qdrant.tech/">Qdrant</a> are specialized in storing embeddings and finding the nearest neighbors of a query embedding. They do the latter via HNSW graphs, which they use as <em>indexing</em> structures. They are built incrementally: every time we add a new item to our collection, we update the graph. Graph building requires specifying some hyperparameters that affect its performance:</p> <ul> <li><strong>M</strong>: the maximum number of connections per node (typically 12-48)</li> <li><strong>efConstruction</strong>: the size of candidate set during construction (affects build quality vs. speed)</li> <li><strong>ef</strong>: the size of candidate set during search (affects accuracy vs. speed)</li> </ul> <p>The navigability property inherited from small world graphs is what makes this greedy strategy work: you can start from any entry point and confidently “walk” toward your query, finding good approximate neighbors without exhaustive search.</p> <p>On top of fast nearest neighbor search, vector databases provide additional functionality like ACID transactions, filtering by metadata, versioning, and replication. They are optimized for high-dimensional data and can handle millions of items efficiently.</p> <h1 id="why-does-this-matter-llms-and-rags">Why does this matter? LLMs and RAGs</h1> <p>Typically, an LLM leverages two sources of information to produce an output: its <em>memory</em> and the provided <em>query</em>. The LLM’s memory consists of large swaths of patterns learned during training and stored in its weights. The query is the user request, which gives the LLM relevant context, potentially additional information, and puts all those weights to find the most plausible answer. Vector databases can extend LLMs, allowing them to efficiently retrieve relevant documents from a corpus and leverage them in its answer. This is called <strong>retrieval-augmented generation</strong> or RAG.</p> <p>The idea of RAG is straightforward. First we embed the corpus and store the embeddings in a vector database. When a query arrives, we embed it and find its closest neighbors from the database. Then, both the query and the retrieved chunks are passed to the LLM, which uses both to generate the final answer. As a proof of concept, I <a href="https://github.com/hclimente/hclimente.github.io/blob/main/assets/python/2025-08-16-rags/rag_system.py">built a simple RAG system</a> that leverages the embeddings of my blog posts and the <a href="https://qdrant.tech/">Qdrant vector database</a> to answer questions:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>uv run rag_cli.py <span class="s2">"What's the best way of doing interpretable ML?"</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Setting up RAG system with qwen3-1.7b model...
⏳ Loading embedding model: sentence-transformers/all-MiniLM-L6-v2
✅ Embedding model loaded

⏳ Loading documents from: ../../../_posts
✅ Loaded 29 documents
⏳ Chunking documents...
        ✂️ Created 1388 chunks
                Computing embeddings for 1388 texts...
                Embeddings computed (shape=(1388, 384))
✅ Vector database ready with 1388 chunks

⏳ Creating RAG system with qwen3-1.7b (Qwen/Qwen3-1.7B)
        ⏳ Loading small LLM: Qwen/Qwen3-1.7B. This may take a few minutes on
        first run...
✅ RAG system initialized successfully!
        ⏳ Processing query: What's the best way of doing interpretable ML?
        ⏳ Retrieving relevant contexts...
                Computing embeddings for 1 texts...
                Embeddings computed (shape=(1, 384))
        ✅ Found 3 relevant chunks
                1. SHAP values (similarity: 0.470)
                2. How do vector databases work? (similarity: 0.438)
                3. SHAP values (similarity: 0.429)
        💭 Generating answer...

============================================================
❓ Query: What's the best way of doing interpretable ML?
------------------------------------------------------------
💡 Answer: The best way of doing interpretable ML is to use SHAP values, which
provide a way to explain the output of any machine learning model. SHAP values
are based on the Shapley value concept from game theory, which helps quantify
the contribution of each feature to a model's prediction. This method allows
for a clear understanding of how individual features affect the model's output,
making it a powerful tool for interpreting complex models like neural networks
or random forests.

The provided context mentions that SHAP values are covered in the book
"Interpretable Machine Learning: Shapley values" and other resources, which
further supports the recommendation of SHAP as a key method for achieving
interpretability in machine learning models.
</code></pre></div></div> <p>To improve its answers, the first step would be to introduce a benchmark to evaluate the quality of the answers. Then, I would try to improve the chunking strategy, the embedding model, and the LLM. Finally, I would try to tune the hyperparameters of the vector database to see if that improves the quality of the retrieved chunks. But that will be left for another day.</p> <h1 id="references">References</h1> <ul> <li><a href="/blog/finding-similar-items/">My previous, pre-LLM write-up on this topic</a></li> <li><a href="https://simonwillison.net/2023/Oct/23/embeddings/">Embeddings: What they are and why they matter</a></li> <li><a href="https://www.pinecone.io/learn/series/faiss/hnsw/">Pinecone: Hierarchical Navigable Small Worlds</a></li> <li><a href="https://medium.com/thedeephub/understading-hnsw-hierarchical-navigable-small-world-ff1a72d98605">Understanding HNSW — Hierarchical Navigable Small World</a></li> </ul>]]></content><author><name></name></author><category term="machine_learning"/><category term="graphs"/><summary type="html"><![CDATA[Finding similar documents in large collections]]></summary></entry><entry><title type="html">Cross-entropy. Intuition and applications.</title><link href="https://hclimente.github.io/blog/cross-entropy/" rel="alternate" type="text/html" title="Cross-entropy. Intuition and applications."/><published>2025-08-01T11:59:00+00:00</published><updated>2025-08-01T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/cross-entropy</id><content type="html" xml:base="https://hclimente.github.io/blog/cross-entropy/"><![CDATA[<p>In pop science, <strong>entropy</strong> is considered a measure of <em>disorder</em>: a system has high entropy when it is disordered (e.g., my college bedroom), and low entropy when it is ordered (e.g., a chocolate box). This meaning probably has its roots in thermodynamics, where my college bedroom was evidence of the universe getting ever closer to its <a href="https://en.wikipedia.org/wiki/Heat_death_of_the_universe">heat death</a>.</p> <p>But for us, entropy is not (only) about messy bedrooms, but about messy <em>data</em>. That’s why I will focus on <em>Shannon’s</em> entropy \(H(P)\), which is a property of a probability distribution \(P\). For a discrete random variable:</p> \[H(P) = \sum_x P(x) \log_2 \frac{1}{P(x)}.\] <p>As stated, using the binary logarithm, entropy is measured in <a href="https://en.wikipedia.org/wiki/Bit">bits</a>; when using the natural logarithm instead, the unit of measure is nats. From here on, \(\log\) means \(\log_2\).</p> <h1 id="what-does-entropy-really-mean">What does entropy <em>really</em> mean?</h1> <p>In a nutshell, entropy is the average surprise we’ll experience when observing a realization of \(P\): if an outcome is rare (\(P(x)\) is small), observing it should be quite surprising (\(\log \frac{1}{P(x)}\) is large); if it is very common, the surprise should be low.</p> <p>A more tangible interpretation of entropy links it to the <em>encoding</em> of a message. Imagine we want to encode the outcome of a probability distribution. We observe an outcome and want to unambiguously communicate it to a friend. For instance, let’s say the weather in my city follows the following probability distribution:</p> <table> <thead> <tr> <th>Weather</th> <th>Probability</th> </tr> </thead> <tbody> <tr> <td>Cloudy</td> <td>0.5</td> </tr> <tr> <td>Rainy</td> <td>0.4</td> </tr> <tr> <td>Sunny</td> <td>0.1</td> </tr> </tbody> </table> <p>(Yes, I live in London.)</p> <blockquote> <p>For easier computations, let’s assume that probabilities remain independent and constant over time. Which, again, isn’t too far from my reality. More formally, the outcomes are independent and identically distributed.</p> </blockquote> <p>Every morning, I look out the window exactly at 9am, and send my friend the weather report. Our first instinct is probably to just text them “cloudy”, “rainy” or “sunny” as appropriate. If we encode these strings in <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a>:</p> <table> <thead> <tr> <th>Weather</th> <th>Probability</th> <th>Codeword</th> <th>Codeword length</th> </tr> </thead> <tbody> <tr> <td>Cloudy</td> <td>0.5</td> <td>011000110110110001101111011101010110010001111001</td> <td>48</td> </tr> <tr> <td>Rainy</td> <td>0.4</td> <td>0111001001100001011010010110111001111001</td> <td>40</td> </tr> <tr> <td>Sunny</td> <td>0.1</td> <td>0111001101110101011011100110111001111001</td> <td>40</td> </tr> </tbody> </table> <p>In the long term, the average message will take \(0.5 \times 48 + 0.4 \times 40 + 0.1 \times 40 = 44\) bits. Not a big deal I guess… But we can do much better! <em>Why waste time say lot word when few word do trick?</em> For instance, we could associate each string to an integer or an emoji (8 bits). But we can do even better than that, we can generate our own <em>codewords</em>. To this end, we need to generate a <a href="https://en.wikipedia.org/wiki/Prefix_code">prefix code</a>, i.e., one in which no codeword can prefix another.</p> <p>The <a href="https://en.wikipedia.org/wiki/Huffman_coding">Huffman coding</a> is a common solution to this problem which significantly shortens our average message by leveraging our knowledge of \(P\):</p> <table> <thead> <tr> <th>Weather</th> <th>Probability</th> <th>Codeword</th> <th>Codeword length</th> </tr> </thead> <tbody> <tr> <td>Cloudy</td> <td>0.5</td> <td>0</td> <td>1</td> </tr> <tr> <td>Rainy</td> <td>0.4</td> <td>10</td> <td>2</td> </tr> <tr> <td>Sunny</td> <td>0.1</td> <td>11</td> <td>2</td> </tr> </tbody> </table> <details><summary><strong>Huffman coding</strong></summary> <p><strong>Huffman coding</strong> builds an optimal prefix code for a known distribution. Here’s how it works for our weather example:</p> <ol> <li> <p><strong>Start with probabilities:</strong></p> <table> <thead> <tr> <th>Weather</th> <th>Probability</th> </tr> </thead> <tbody> <tr> <td>Cloudy</td> <td>0.5</td> </tr> <tr> <td>Rainy</td> <td>0.4</td> </tr> <tr> <td>Sunny</td> <td>0.1</td> </tr> </tbody> </table> </li> <li> <p><strong>Merge lowest pairs:</strong> Combine Sunny (0.1) and Rainy (0.4) → node with weight 0.5. Then combine with Cloudy (0.5) → final tree.</p> </li> <li> <p><strong>Assign bits:</strong> Traverse the tree, assigning 0/1 at each split.</p> <table> <thead> <tr> <th>Weather</th> <th>Codeword</th> </tr> </thead> <tbody> <tr> <td>Cloudy</td> <td>0</td> </tr> <tr> <td>Rainy</td> <td>10</td> </tr> <tr> <td>Sunny</td> <td>11</td> </tr> </tbody> </table> </li> </ol> <p>Huffman coding guarantees the shortest average length for any prefix code based on the true distribution.</p> </details> <p>This is much better: we have gone from 44 bits to \(0.5 \times 1 + 0.4 \times 2 + 0.1 \times 2 = 1.5\) bits on average. Of course, for this to be possible, we need to have access to the true weather distribution. Otherwise, our bit allocation won’t be optimal.</p> <p>Are we satisfied yet? Not quite. Despite Huffman being optimal, our message length will be the same on rainy days and on sunny days. However, rainy days are 4 times more common! The core problem is that our messages have an <em>integer</em> length, and we would need <em>fractional</em> lengths to do better. But we can do better if we make some compromises. Imagine we only want to batch-send the weather report every 10 days. Then, there are \(3^{10}\) possible sequences of 10 days. The most likely one is a streak of ten cloudy days, which occurs with probability \(0.5^{10}\). Consequently, the Huffman coding assigns a much shorter codeword to this string than to the most unlikely string, a streak of ten sunny days:</p> <table> <thead> <tr> <th>10-day weather</th> <th>Probability</th> <th>Codeword</th> <th>Codeword length</th> </tr> </thead> <tbody> <tr> <td>CCCCCCCCCC</td> <td>9.77e-04</td> <td>0111001010</td> <td>10</td> </tr> <tr> <td>CCCCCCCCCR</td> <td>7.81e-04</td> <td>0000101101</td> <td>10</td> </tr> <tr> <td>CCCCCCCCRC</td> <td>7.81e-04</td> <td>0000101110</td> <td>10</td> </tr> <tr> <td>…</td> <td>…</td> <td>…</td> <td>…</td> </tr> <tr> <td>SSSSSSSSSR</td> <td>4.00e-10</td> <td>0111001001100000001100111110100</td> <td>31</td> </tr> <tr> <td>RSSSSSSSSS</td> <td>4.00e-10</td> <td>11000100010100011010000101101111</td> <td>32</td> </tr> <tr> <td>SSSSSSSSSS</td> <td>1.00e-10</td> <td>11000100010100011010000101101110</td> <td>32</td> </tr> </tbody> </table> <p>The average length of this code is 13.64 bits, or 1.364 bits per day. Batching outcomes together allows us to spend only <em>fractions</em> of a bit. And it’s easy to see how, if we kept batching more and more days together, each single day would require less and less bits.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-07-14-cross-entropy/img/entropy-batch_size_vs_avg_bits_per_day.webp" sizes="95vw"/> <img src="/assets/python/2025-07-14-cross-entropy/img/entropy-batch_size_vs_avg_bits_per_day.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>And this brings us to the key point: entropy represents the lower bound for the average message length required to <em>optimally</em> encode each outcome of a random process. Even with the best encoding we can come up with and incredibly large batches, we can’t compress the message below the entropy limit. In the case of our distribution:</p> \[H(P) = 0.5 \times \log \frac 1 {0.5} + 0.4 \times \log \frac 1 {0.4} + 0.1 \times \log \frac 1 {0.1} = 1.361 \text{ bits}\] <p>The Huffman encoding was doing pretty well after all!</p> <details><summary><strong>But <em>why</em> logarithms?</strong></summary> <p>All this is fine, but a lingering question remains: what’s the logarithm of the probability doing there? Why aren’t we using any other transformation of the probability?</p> <p>Imagine the space of all possible codewords of a prefix code. If we decide to use the codeword “0”, every other codeword needs to start by “1”; that choice cost us half of all possible codewords. Hence, if we are going to spend that precious codeword into one outcome, it better happen at least half the time. Note that \(- \log 0.5 = 1\). Similarly, a codeword like “00” still allows for words prefixed by “01”, “10” and “11”; it cost us only one fourth of the space. Note that \(- \log 0.25 = 2\).</p> <p>\(- \log P(x)\) gives us the optimal length of an outcome’s codeword.</p> </details> <h1 id="cross-entropy">Cross-entropy</h1> <p>We just saw how knowing the underlying probability distribution gave us an edge in encoding the outcomes efficiently. However, here in the real world we rarely have access to <em>true</em> probability distributions, if such a thing even exists. At most, we have access to our best guess of what the true probability distribution is. And these guesses are rarely completely correct.</p> <p>For instance, we rely on very complex models to accurately predict the weather. But let’s leave those aside, and use the simple model (\(Q_\text{Barcelona}\)) and associated Huffman code I developed for Barcelona’s weather:</p> <table> <thead> <tr> <th>Weather</th> <th>Probability</th> <th>Codeword</th> <th>Codeword length</th> </tr> </thead> <tbody> <tr> <td>Cloudy</td> <td>0.2</td> <td>11</td> <td>2</td> </tr> <tr> <td>Rainy</td> <td>0.1</td> <td>10</td> <td>2</td> </tr> <tr> <td>Sunny</td> <td>0.7</td> <td>0</td> <td>1</td> </tr> </tbody> </table> <p>As you can imagine, after moving to London, my model of the weather was not that useful. In fact, I often experienced <em>surprise</em>, as outcomes that should be rare happened often. In consequence, when using this code in London, my average message took up 1.9 bits.</p> <p>Entropy quantified our average surprise when observing a distribution’s outcomes while knowing the true distribution. Similarly, the <strong>cross-entropy</strong> measures our surprise when observing a distribution’s outcomes while only having a <em>model</em> of the true distribution. If \(P\) is the true distribution and \(Q\) is our model:</p> \[H(P, Q) = \sum_x P(x) \log \frac{1}{Q(x)}.\] <p>Just like entropy, \(\log \frac{1}{Q(x)}\) measures the degree of surprise we expect as per our model, which is weighted by the actual frequency with which we observe the outcome. It is also measured in bits.</p> <blockquote> <p>Note that order matters! \(H(P, Q) \neq H(Q, P)\).</p> </blockquote> <h2 id="why-theory-and-practice-can-differ">Why theory and practice can differ</h2> <p>The cross-entropy of my model \(Q_\text{Barcelona}\) on the London weather is:</p> \[H(P_\text{London}, Q_\text{Barcelona}) = 0.5 \times \log \frac 1 {0.2} + 0.4 \times \log \frac 1 {0.1} + 0.1 \times \log \frac 1 {0.7} \approx 2.54 \text{ bits}.\] <p>This is higher than the average message length of 1.9 bits. Contrary to entropy, which is a hard-limit, our model <em>can</em> do better than cross-entropy. This is because the cross-entropy leverages (optimal) fractional lengths, but our Huffman codes use non-fractional lengths, underestimating some outcomes and overestimating others:</p> <table> <thead> <tr> <th>Weather</th> <th>P</th> <th>Codeword length</th> <th>Q-optimal codeword length</th> <th>Extra (\(+\))/Saved (\(-\)) bits</th> </tr> </thead> <tbody> <tr> <td>Cloudy</td> <td>0.5</td> <td>2</td> <td>2.32</td> <td>\(-0.32 \times 0.5 = -0.16\)</td> </tr> <tr> <td>Rainy</td> <td>0.4</td> <td>2</td> <td>3.32</td> <td>\(-1.32 \times 0.4 = -0.53\)</td> </tr> <tr> <td>Sunny</td> <td>0.1</td> <td>1</td> <td>0.51</td> <td>\(0.49 \times 0.1 = 0.05\)</td> </tr> </tbody> </table> <p>Notice how we’re saving a ton of bits on cloudy and rainy days; we got lucky. If we batch our weather reports, we get closer to encoding individual outcomes with fractional bits. Using the 10-day Barcelona code to report London weather, the average length of my message was \(2.53 \text{ bits}\), which is much closer to \(H(P, Q) \approx 2.54 \text{ bits}\). The cross-entropy <em>is</em> a lower bound if and only if we achieve the optimal coding for \(Q\).</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-07-14-cross-entropy/img/crossentropy-batch_size_vs_avg_bits_per_day.webp" sizes="95vw"/> <img src="/assets/python/2025-07-14-cross-entropy/img/crossentropy-batch_size_vs_avg_bits_per_day.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="why-does-this-all-matter">Why does this all matter?</h1> <p>After a few years in London my model became quite accurate, to the extent that \(Q_\text{London} \approx P_\text{London}\):</p> \[H(P_\text{London}, Q_\text{London}) = 0.5 \times \log \frac 1 {0.5} + 0.4 \times \log \frac 1 {0.4} + 0.1 \times \log \frac 1 {0.1} \approx 1.36 \text{ bits}.\] <p>This is an important result (the <a href="https://en.wikipedia.org/wiki/Gibbs%27_inequality">Gibbs’ inequality</a>):</p> \[H(P, Q) \geq H(P, P) = H(P)\] <details><summary><strong>Kullback-Leibler (KL) divergence</strong></summary> <p>Since entropy is the lower bound for cross-entropy, the difference between both informs us about how well our model reflects the true distribution. This difference is also so important that it has its own name: <a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback-Leibler (KL) divergence</a>.</p> \[D_{KL}(P || Q) = H(P, Q) - H(P)\] <p>It can be interpreted as the <em>cost of being wrong</em>: how many extra bits we need to spend because our model departs from the true distribution.</p> </details> <p>Ultimately, this is why I went down this rabbit hole. We’ve covered distributions, processes, and encoding. But machine learning is one of the most important applications of cross-entropy via the <a href="https://en.wikipedia.org/wiki/Loss_function">cross-entropy loss</a>. During model <em>training</em>, many machine learning algorithms minimize the cross-entropy between the learned probability distribution (like <a href="https://en.wikipedia.org/wiki/Discriminative_model">\(P(Y \mid X)\)</a> or <a href="https://en.wikipedia.org/wiki/Generative_model">\(P(X, Y)\)</a>) and the one observed in the data.</p> <p>Let’s bring this point home by revisiting our weather model one last time. In this case, we want a model to predict tomorrow’s weather using some sensible variables (like today’s weather, temperature, humidity and wind), encapsulated into a vector \(x\). After some complex calculations it emits a probability vector \(q(x) = [q_C, q_R, q_S]\). Say, for a given day, it predicts \(q(x) = [0.35, 0.6, 0.05]\). Then, the day arrives, and we observe the true outcome: \(p = [1, 0, 0]\). Turns out our model was quite wrong!</p> <blockquote> <p>Note that \(p\) is the one-hot (empirical) distribution on the observed class, not the true generative \(P\), and \(q\) is just the model’s prediction for this example, not the overall distribution \(Q\)!</p> </blockquote> <p>The cross-entropy loss has a familiar form:</p> \[\mathcal{L}(p,q(x)) = 1 \times \log\frac{1}{q_C} + 0 \times \log\frac{1}{q_R} + 0 \times \log\frac{1}{q_S} = \log\frac{1}{q_C} = - \log q_C.\] <p>Or, more generally:</p> \[\mathcal{L}(p, q(x)) = -\sum_{i=1}^K p_i \log q(x)_i = -\log q(x)_y.\] <p>where \(K\) is the number of classes, and \(y\) is the index of the true class (\(1\) in our example, corresponding to class \(C\)).</p> <p>The model will consequently update its parameters to minimize this loss, also known as log-loss. Minimizing it is equivalent to <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation">maximizing the probability of the data</a>. During training we minimize the average of this loss over the whole training dataset \(\mathcal{D}\):</p> \[\mathcal{L} = \mathbb{E}_{(x,y) \sim \mathcal{D}} \bigl[-\log q(x)_y \bigr] = -\frac{1}{N}\sum_{i=1}^N \log q(x^{(i)})_{y^{(i)}}.\] <p>And that’s the objective in its entirety: to adjust the model’s parameters until it is, on average, least surprised by the correct answer. At least until it sees the test set…</p> <h1 id="further-readings">Further readings</h1> <ul> <li><a href="https://colah.github.io/posts/2015-09-Visual-Information/">Visual Information Theory</a></li> <li><a href="https://www.youtube.com/watch?v=KHVR587oW8I">The Key Equation Behind Probability (video)</a></li> </ul>]]></content><author><name></name></author><category term="information_theory"/><category term="machine_learning"/><category term="statistics"/><summary type="html"><![CDATA[The secret sauce of machine learning]]></summary></entry><entry><title type="html">Covariance and precision</title><link href="https://hclimente.github.io/blog/precision-matrix/" rel="alternate" type="text/html" title="Covariance and precision"/><published>2025-07-16T11:59:00+00:00</published><updated>2025-07-16T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/precision-matrix</id><content type="html" xml:base="https://hclimente.github.io/blog/precision-matrix/"><![CDATA[<p>Imagine we have a set of 3 variables (\(U\), \(X\), and \(Y\)), with one of them being upstream of the other two (\(X \leftarrow U \rightarrow Y\)):</p> \[U \sim N(0, 1)\] \[X = U + \varepsilon_X\] \[Y = U + \varepsilon_Y\] \[\varepsilon_X, \varepsilon_Y \sim N(0, 0.25)\] <p>We want to discover this structure from observational data. Since both \(X\) and \(Y\) are caused by \(U\), a correlation is not very enlightening and will just return the fully connected graph:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-05-29-precision-matrix/img/correlations.webp" sizes="95vw"/> <img src="/assets/python/2025-05-29-precision-matrix/img/correlations.webp" class="img-fluid" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Scatter plots of each pair of variables on 200 observations, each with the correlation between the variables and the associated P-value indicated above. </div> <p>A sensible way of going about it is to study the correlation between each pair of variables after adjusting for the remaining variable. If we assume all relationships are linear, these are called <strong>partial correlations</strong>. Partial correlations are designed to reveal direct relationships by removing the influence of confounding variables. Here is a naive implementation:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">pcorr_residuals</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Compute the matrix of partial correlations from the residuals of linear regression models.

    Parameters
    ----------
    X : np.ndarray
        The input data matrix.

    Returns
    -------
    np.ndarray
        The matrix of partial correlations.
    </span><span class="sh">"""</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>

    <span class="n">residuals</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">empty</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
            <span class="n">covariates_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">i</span> <span class="ow">and</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">X_covars</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">covariates_indices</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">target</span><span class="p">,</span> <span class="n">excluded</span> <span class="ow">in</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">)]:</span>

                <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">target</span><span class="p">]</span>

                <span class="c1"># fit a linear model
</span>                <span class="n">beta</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">lstsq</span><span class="p">(</span><span class="n">X_covars</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">X_covars</span> <span class="o">@</span> <span class="n">beta</span>

                <span class="c1"># compute and center the residuals
</span>                <span class="n">r</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span>
                <span class="n">residuals</span><span class="p">[(</span><span class="n">target</span><span class="p">,</span> <span class="n">excluded</span><span class="p">)]</span> <span class="o">=</span> <span class="n">r</span> <span class="o">-</span> <span class="n">r</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>

    <span class="n">pcorr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>

            <span class="n">res_1</span> <span class="o">=</span> <span class="n">residuals</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span>
            <span class="n">res_2</span> <span class="o">=</span> <span class="n">residuals</span><span class="p">[(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span>
            <span class="n">corr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">res_1</span><span class="p">,</span> <span class="n">res_2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">res_1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">res_2</span><span class="p">))</span>

            <span class="n">pcorr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">pcorr</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">corr</span>

    <span class="k">return</span> <span class="n">pcorr</span>
</code></pre></div></div> <p>Partial correlations correctly identify that \(U\) is correlated with both \(X\) and \(Y\), and in turn that those are not correlated once we account for the effect of \(U\):</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-05-29-precision-matrix/img/partial_correlations.webp" sizes="95vw"/> <img src="/assets/python/2025-05-29-precision-matrix/img/partial_correlations.webp" class="img-fluid" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Scatter plots of the residuals of each pair of variables on 200 observations, each with the <em>partial correlation</em> between the variables and its associated P-value indicated above. </div> <p>Note that while \(\hat{\rho}_{X, U} \approx \rho_{X, U} = 0.8944\), \(\hat{\rho}_{X, U \mid Y} \neq \rho_{X, U}\). This is because \(Y\) contains an additional noise term that makes the adjustment imperfect. Also note that we have identified the <strong>structure</strong> of the data (\(X - U - Y\)), but not its <strong>causal</strong> structure (\(X \rightarrow U \rightarrow Y\), \(X \leftarrow U \leftarrow Y\) or \(X \rightarrow U \rightarrow Y\)).</p> <p>A downside of this approach is its computational complexity. For an \(n \times p\) input matrix:</p> <ul> <li>Memory complexity: \(\mathcal{O}(np^2)\), dominated by storing \({p \choose 2} = \mathcal{O}(p^2)\) residuals, each of length \(n\).</li> <li>Time complexity: \(\mathcal{O}(np^4)\), dominated by computing \({p \choose 2} = \mathcal{O}(p^2)\) least squares problems, each of complexity \(\mathcal{O}(np^2)\).</li> </ul> <p>This is quite computational intensive, which will become a problem in real-world problems. Can we do better? Enter the <strong>precision matrix</strong>, a nice mathematical object to do this at scale.</p> <h1 id="the-precision-matrix">The precision matrix</h1> <details><summary>Need to dust off the basics? Variance, covariance and correlation</summary> <p>The <strong>variance</strong> of a random variable \(X\) is defined as</p> \[\sigma_X^2 = \mathbf{E}(X - \mathbf{E}(X))^2\] <p>The variance takes values in \([0, \infty)\), and measures how disperse the outcomes of the RV are from its mean. Notably, the <strong>(scalar) precision</strong> is defined as \(\frac 1 \sigma_X^2\), so high variance equals low precision and vice versa.</p> <p>The <strong>covariance</strong> between two random variables, \(X_1\) and \(X_2\), is defined as:</p> \[\text{Cov}(X_1, X_2) = \mathbf{E}((X_1 - \mathbf{E}(X_1))(X_2 - \mathbf{E}(X_2))).\] <p>Observe that if \(X_1 = X_2\), \(\sigma_{X_1}^2 = \sigma_{X_2}^2 = \text{Cov}(X_1, X_2)\).</p> <p>The covariance takes values in \((-\sigma_{X_1} \sigma_{X_2}, \sigma_{X_1} \sigma_{X_2})\), and measures the degree to which two random variables are linearly related. The <strong>correlation</strong> \(\rho\) normalizes the covariance, rescaling it to the \([-1, 1]\) range:</p> \[\rho_{X_1, X_2} = \frac {\text{Cov}(X_1, X_2)} {\sigma_{X_1} \sigma_{X_2}}\] </details> <p>The <strong>covariance matrix</strong> of a set of random variables ties the variance and the covariance together. If \(\mathbf{X}\) is a column vector such that</p> \[\mathbf{X} = \begin{pmatrix} X_1 \\ X_2 \\ \vdots \\ X_n \end{pmatrix}\] <p>then its associated covariance matrix \(\mathbf{\Sigma}\) is</p> \[\mathbf{\Sigma} = \begin{pmatrix} \sigma_{X_1}^2 &amp; \text{Cov}(X_1, X_2) &amp; \cdots &amp; \text{Cov}(X_1, X_n) \\ \text{Cov}(X_2, X_1) &amp; \sigma_{X_2}^2 &amp; \cdots &amp; \text{Cov}(X_2, X_n) \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \text{Cov}(X_n, X_1) &amp; \text{Cov}(X_n, X_2) &amp; \cdots &amp; \sigma_{X_n}^2 \end{pmatrix}\] <p>Since always \(\text{Cov}(X_i, X_j) = \text{Cov}(X_j, X_i)\), \(\mathbf{\Sigma}\) is <em>symmetric</em>. It is, in fact, <em>positive semi-definite</em> (<a href="https://statproofbook.github.io/P/covmat-psd.html">proof</a>).</p> <p>By normalizing the covariance matrix by dividing each item \(\mathbf{\Sigma}_{ij}\) by \(\sigma_{X_i} \sigma_{X_j}\), we obtain the <strong>correlation matrix</strong>:</p> \[P = \begin{pmatrix} 1 &amp; \rho_{X_1, X_2} &amp; \cdots &amp; \rho_{X_1, X_n} \\ \rho_{X_2, X_1} &amp; 1 &amp; \cdots &amp; \rho_{X_1, X_n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \rho_{X_n, X_1} &amp; \rho_{X_n, X_2} &amp; \cdots &amp; 1 \end{pmatrix}\] <p>Finally, the <strong>precision matrix</strong> \(\mathbf{\Sigma}^{-1}\) is the inverse of the covariance matrix, i.e., \(\mathbf{\Sigma} \mathbf{\Sigma}^{-1} = \mathbf{I}\). \(\mathbf{\Sigma}\) is not guaranteed to be invertible, and hence \(\mathbf{\Sigma}^{-1}\) may not exist. Let’s ignore this case for now, and jump to where things start getting interesting. \(\mathbf{\Sigma}^{-1}\) can be decomposed as follows:</p> \[\mathbf{\Sigma}^{-1} = D \begin{pmatrix} 1 &amp; -\rho_{X_1, X_2 \mid X_3, \dots, X_n} &amp; \cdots &amp; -\rho_{X_1, X_n \mid X_2, \cdots, X_{n-1}} \\ -\rho_{X_2, X_1 \mid X_3, \cdots, X_n} &amp; 1 &amp; \cdots &amp; -\rho_{X_2, X_n \mid X_1, X_3, \cdots, X_{n-1}} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ -\rho_{X_n, X_1 \mid X_2, \cdots, X_{n-1}} &amp; -\rho_{X_n, X_2 \mid X_1, X_3 \cdots, X_{n-1}} &amp; \cdots &amp; 1 \end{pmatrix} D\] <p>where \(D\) is a normalization matrix:</p> \[D = \begin{pmatrix} \frac 1 {\sigma_{X_1 \mid X_2, \cdots, X_n}} &amp; &amp; &amp; 0 \\ &amp; \frac 1 {\sigma_{X_2 \mid X_1, X_3, \cdots, X_n}} &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ 0 &amp; &amp; &amp; \frac 1 {\sigma_{X_n \mid X_1, \cdots, X_{n-1}}} \end{pmatrix}\] <p>The entries \(\rho_{X_., X_. \mid \dots}\) in the middle matrix are our precious <strong>partial correlations</strong>.</p> <h1 id="estimating-the-precision-matrix">Estimating the precision matrix</h1> <p>Let’s revisit our motivating example equipped with our newfound knowledge: instead of fitting \(\mathcal{O}(p^2)\) linear models, let’s reach the same result using linear algebra. First, we will estimate the covariance matrix using the maximum likelihood approach. Then, we will invert it to obtain the precision matrix.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">pcorr_linalg</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span> <span class="c1"># (n, p) -&gt; (p, p)
</span>    <span class="sh">"""</span><span class="s">
    Compute the matrix of partial correlations from the covariance matrix.

    Parameters
    ----------
    X : np.ndarray
        The input data matrix.

    Returns
    -------
    np.ndarray
        The matrix of partial correlations.
    </span><span class="sh">"""</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>

    <span class="c1"># showing how the sausage is made
</span>    <span class="c1"># but could be replaced by covariance = np.cov(X, rowvar=False)
</span>    <span class="n">centered_X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">covariance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">centered_X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">centered_X</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">precision</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">inv</span><span class="p">(</span><span class="n">covariance</span><span class="p">)</span>

    <span class="n">normalization_factors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">outer</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">precision</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">precision</span><span class="p">)))</span>
    <span class="n">partial_correlations</span> <span class="o">=</span> <span class="o">-</span> <span class="n">precision</span> <span class="o">/</span> <span class="n">normalization_factors</span>

    <span class="k">return</span> <span class="n">partial_correlations</span>
</code></pre></div></div> <p>This implementation is not only more compact, but has a more favorable computational complexity:</p> <ul> <li>Memory complexity: \(\mathcal{O}(p^2)\), dominated by the intermediate matrices.</li> <li>Time complexity: \(\mathcal{O}(np^2 + p^3)\), dominated by the computation of the covariance matrix and by the matrix inversion.</li> </ul> <p>Furthermore, this implementation is <a href="/blog/python-vectors/">vectorized</a> which further boosts performance. As a quick benchmark, on a random \(1000 \times 100\) matrix, the original <code class="language-plaintext highlighter-rouge">pcorr_residuals</code> took 40.85 seconds; the updated <code class="language-plaintext highlighter-rouge">pcorr_linalg</code> took only 0.0007 seconds.</p> <p>As with many elegant results in linear algebra, things start breaking down when our covariance matrix is <a href="https://en.wikipedia.org/wiki/Condition_number">ill-conditioned</a> or outright <a href="https://en.wikipedia.org/wiki/Singular_matrix">non-invertible</a>. In <a href="https://en.wikipedia.org/wiki/High-dimensional_statistics">high-dimensional problems</a>, \(\Sigma\) is non-invertible (and hard to estimate in the first place). In such cases, we could use <a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">the pseudoinverse matrix</a> instead of the inverse. But that’s just a patch: we will get results, but we are outside of the theory and interpreting the results is not as straightforward. However, when the matrix is ill-conditioned, there is a potential path to salvation: <a href="https://scikit-learn.org/stable/modules/covariance.html">regularization</a>.</p> <h1 id="regularized-estimation">Regularized estimation</h1> <p>Adding a regularization step to the covariance matrix estimation will result in a better conditioned matrix. A common approach is <em>shrinking</em> our empirical covariance towards another matrix, the <em>target</em>:</p> \[\hat{\mathbf{\Sigma}} = (1 - \alpha) \hat{\mathbf{\Sigma}}_\text{MLE} + \alpha T\] <p>where \(\alpha \in [0, 1]\) is a parameter and \(T\) is the target matrix, a highly structured matrix that encodes our assumption about what a <em>true</em> covariance matrix should look like. A possible and aggressive target matrix is a diagonal matrix, which encodes the assumption of zero covariance between variables. By upweighting the diagonal elements and downweighting the off-diagonal elements, this matrix will have a better condition than \(\Sigma_\text{MLE}\).</p> <p>The problem becomes then tuning \(\alpha\). A common way to compute the \(\alpha\) is the <a href="https://web.archive.org/web/20141205061842/http://www.econ.uzh.ch/faculty/ledoit/publications/honey.pdf">Ledoit-Wolf shrinkage method</a>, which finds the \(\alpha\) that minimizes the mean squared error between the real and the estimated matrix. Its <a href="https://github.com/scikit-learn/scikit-learn/blob/68483539614102ba8e083277ed7123e6a9fece53/sklearn/covariance/_shrunk_covariance.py#L25">scikit-learn implementation</a> assumes that the target matrix is \(T = \mu I\), where \(\mu\) is the average variance.</p> <p>Alternatively, we can use graphical lasso to estimate a sparse precision matrix. Conceptually, this is a bit easier to swallow: in many situations, most variables being conditionally uncorrelated is a valid assumption. The <a href="https://en.wikipedia.org/wiki/Graphical_lasso">graphical lasso</a> does just that; it is a penalized estimator of the precision matrix.</p> \[\hat{\mathbf{\Sigma}}^{-1} = \operatorname{argmin}_{\mathbf{\Sigma}^{-1} \succ 0} \left(\operatorname{tr}(\mathbf{\Sigma} \mathbf{\Sigma}^{-1}) - \log \det \mathbf{\Sigma}^{-1} - \lambda \|\mathbf{\Sigma}^{-1}\|_1 \right).\] <p>The \(- \lambda \|\mathbf{\Sigma}^{-1}\|_1\) term will favor sparse matrices, with a strength proportional to the magnitude of \(\lambda\). While tuning \(\lambda\) is in itself a challenge, a common approach is using <a href="https://scikit-learn.org/stable/modules/generated/sklearn.covariance.GraphicalLassoCV.html">cross-validation</a>.</p> <p>Let’s bring this point home by looking at a high-dimensional example (20 samples, 20 features).</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-05-29-precision-matrix/img/high_dimensional_experiments.webp" sizes="95vw"/> <img src="/assets/python/2025-05-29-precision-matrix/img/high_dimensional_experiments.webp" class="img-fluid" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Ground truth and estimated covariance matrix, precision matrix and structure of a high-dimensional example. The data generation process involved 20 samples, with 20 features each, sampled from a 0-mean multivariate Normal distribution. The estimated structure using the Ledoit-Wolf used a soft threshold (abs(correlation) &gt; 0.1); otherwise, the fully connected graph would be shown. </div> <p>As we can see, <strong>maximum likelihood estimation</strong> absolutely fails. Due to the extremely ill-conditioned covariance matrix, the precision matrix is completely off scale, with values ranging from -1.8e+15 to 1.0e+15. <strong>Ledoit-Wolf</strong> succeeds at computing a sensible-looking precision matrix. But recovering a structure, e.g., by thresholding it, is quite a hard task. Last, <strong>graphical lasso</strong> is able to find a relatively sparse structure. While it is still far from the ground truth, it prunes away most of the spurious correlations and keeps most of the true links. <a href="https://scikit-learn.org/stable/modules/covariance.html#sparse-inverse-covariance">As expected</a>, most of the true links are larger in absolute value, and further pruning it would return something close to the true structure.</p> <p>More than anything, this little exercise shows how hard this endeavour is, and serves as a good caution to high-dimensional statistics. Beware!</p> <h2 id="conclusions">Conclusions</h2> <p>Under certain assumptions, the precision matrix helps us discover the internal structure of the data. When should we use what to estimate it?</p> <ol> <li><strong>Empirical inverse (MLE):</strong> fast and exact, but blows up if \(p\) approaches \(n\) or \(\hat Σ\) is singular. Use it when \(n \gg p\) and \(\hat Σ\) is well‑conditioned.</li> <li><strong>Shrinkage (Ledoit-Wolf):</strong> automatically picks \(\alpha\) to stabilize \(\hat Σ\), yielding a dense but well‑behaved precision. Use it when \(\frac p n\) is moderate.</li> <li><strong>Graphical Lasso (cross‑validated \(\lambda\)):</strong> trades off likelihood vs. sparsity to prune weak edges and reveal a parsimonious conditional‑independence network. Use it in high‑dimensional settings.</li> </ol>]]></content><author><name></name></author><category term="linear_algebra"/><category term="graphs"/><category term="statistics"/><summary type="html"><![CDATA[Learning the hidden structure of data]]></summary></entry><entry><title type="html">DNA language model fine-tuning and inference</title><link href="https://hclimente.github.io/blog/hf-transformers/" rel="alternate" type="text/html" title="DNA language model fine-tuning and inference"/><published>2025-05-29T11:59:00+00:00</published><updated>2025-05-29T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/hf-transformers</id><content type="html" xml:base="https://hclimente.github.io/blog/hf-transformers/"><![CDATA[<p>Picture this. A relevant model was just published. The results look compelling. You want to give it a try on your own data. If you have ever been there, the next steps will be painfully familiar: search for code in the paper; find a Zenodo hyperlink; download a tarball, extract it; look for a README, find none; cry; crawl through Jupyter notebooks to understand how the code is meant to be run; et cetera. After a couple of hours, maybe you can get the code working with a nagging discomfort that you might have missed something.</p> <p>This is the workflow that Hugging Face 🤗 and its <a href="https://huggingface.co/docs/transformers/index"><code class="language-plaintext highlighter-rouge">transformers</code></a> Python library aim to eradicate. <code class="language-plaintext highlighter-rouge">transformers</code> provides a unified API to fetch, use and fine-tune many models, making it easy to switch between them without having to learn a new API each time, which has turned it into a staple of LLM work.</p> <p>Let’s dive into the <code class="language-plaintext highlighter-rouge">transformers</code> library. Although big tech is going crazy over LLMs, DNA language models are where the money is.<d-footnote>Citation required</d-footnote> In that spirit, in this post I use <code class="language-plaintext highlighter-rouge">transformers</code> to showcase an application of the <a href="https://www.nature.com/articles/s41592-024-02523-z">Nucleotide Transformer</a> (NT), a DNA language model. And I use the NT to showcase <code class="language-plaintext highlighter-rouge">transformers</code>.</p> <p>I will be providing snippets of code along with the text. If you are still curious about the nitty-gritty, all the code is available <a href="https://github.com/hclimente/hclimente.github.io/blob/main/assets/python/2025-05-02-hf-transformers/">on Github</a>.</p> <h1 id="a-worked-out-training-example">A worked-out training example</h1> <p>The <a href="https://www.nature.com/articles/s41592-024-02523-z">Nucleotide Transformer</a> (NT) is an encoder-only transformer, essentially a <a href="https://en.wikipedia.org/wiki/BERT_(language_model)">BERT model</a> trained on the genomes of 850 species via masked language modelling (MLM).</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-05-02-hf-transformers/nucleotide_transformer-480.webp 480w,/assets/img/posts/2025-05-02-hf-transformers/nucleotide_transformer-800.webp 800w,/assets/img/posts/2025-05-02-hf-transformers/nucleotide_transformer-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-05-02-hf-transformers/nucleotide_transformer.jpg" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Training of the NT using masked language modelling (MLM). Adapted from Figure 1 in the <a href="https://www.nature.com/articles/s41592-024-02523-z">NT article</a>. </div> <p>In MLM a random bit of the input DNA sequence will be hidden from the model. The task of the model is to retrieve the masked subsequences using the rest of the sequence. Let’s say that the input sequence is <code class="language-plaintext highlighter-rouge">ATGGTAGCTACATCATCT</code>. The model will receive as input <code class="language-plaintext highlighter-rouge">ATGGTAGCTACA&lt;MASK&gt;</code> and we expect it to correctly guess that <code class="language-plaintext highlighter-rouge">&lt;MASK&gt;</code> equals <code class="language-plaintext highlighter-rouge">TCATCT</code>. The figure below gives the basic idea. Let’s break MLM down into its four steps:</p> <ol> <li> <p><strong>Tokenizer:</strong> First, we convert the input DNA sequence into a sequence of integers (<em>tokens</em>), each representing a subsequence of length 6 nucleotides (“6-mers”). The total number of tokens is 4,107: one for each of the \(4^6 = 4096\) possible 6-mers and 11 special tokens (<a href="https://en.wikipedia.org/wiki/Sentence_embedding">CLS</a>, MASK, PAD and a few others).<d-footnote>You can learn more about the tokenizer in the <a href="https://github.com/hclimente/hclimente.github.io/blob/main/assets/python/2025-05-02-hf-transformers/supplementary.ipynb">supplementary notes</a>.</d-footnote></p> <p>In the case of our 18-nucleotide sequence <code class="language-plaintext highlighter-rouge">ATGGTAGCTACATCATCT</code>, the tokenizer transforms it into a tokenized sequence of length 4: <code class="language-plaintext highlighter-rouge">[3, 506, 3662, 1567]</code>. This includes the CLS token (<code class="language-plaintext highlighter-rouge">3</code>) and three tokens representing three 6-mers. During training, a random subset of 15% of the tokens are replaced by the MASK token (<code class="language-plaintext highlighter-rouge">2</code>). These are the parts of the sequence that the model will try to recover. Let’s mask the last token in our example: <code class="language-plaintext highlighter-rouge">[3, 506, 3662, 2]</code>.</p> </li> <li> <p><strong>Embedding layer:</strong> An embedding layer transforms the tokenized sequence of integers into an fixed-length vector of real values (<em>embedding</em>). On this embedding, a positional encoding is added to preserve information about the position of each token.</p> </li> <li> <p><strong>Transformer encoder:</strong> Here comes the main event: the stacked Transformer encoder blocks (since the NT is an encoder-only model, remember?). These blocks are where the magic actually happens, processing the initial embeddings to create context-aware representations. Each block uses self-attention mechanisms to let tokens interact across the sequence and feed-forward networks for position-specific processing.</p> </li> <li> <p><strong>Token probabilities:</strong> Finally the last layer’s embedding is transformed into a probability of each token in each of the input positions. Since there were 3 input positions and 4,107 possible tokens, the output for our sequence will be a matrix of size 3 × 4,107. The rows will sum to 1.</p> <p>In our example, the masked token was <code class="language-plaintext highlighter-rouge">1567</code> and was in the last position. If our model has done a good job, the matrix entry (3, 1567) will be close to 1, and the rest of the entries in that row will be close to 0. During training, the trainer evaluates the model’s output using the <a href="https://en.wikipedia.org/wiki/Cross-entropy">cross-entropy</a> loss, and adjusts the parameters of the model by <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a>.</p> </li> </ol> <p>By repeating this process over and over, on DNA sequences obtained from very different species, the model learns to guess the hidden sequence from it’s genomic context. But, <strong>what is it <em>really</em> learning?</strong> My intuition is that it’s picking up general patterns across genomes. For instance, after looking at many protein-coding sequences it might learn the pattern that we would adscribe to an alpha helix. By putting together some of such patterns, it might learn that protein-coding sequences are related. Then, it could leverage this knowledge in the MLM task to predict a sequence that preserves the alpha helix with the observed codon usage. Similarly, it might learn that another mask is around the right genomic distance from an ORF, and deduce it should predict what we recognize as a promoter. In all this proess the NT has no access to phenotypic information or explicit knowledge about promoters, genes or alpha helices. It is flying blind regarding how this DNA sequence plays out in the real world. Although it is getting a glimpse of evolutionary constraints by being exposed to different genomes, it won’t be able to learn sophisticated genomic regulation patterns.</p> <h1 id="loading-a-pre-trained-model">Loading a pre-trained model</h1> <p>Now that the theory is out of the way, let’s start exploring the Hugging Face ecosystem. There are two elements of it that vastly facilitate sharing and leveraging pre-trained models.</p> <p>One is the <a href="https://huggingface.co/docs/hub/en/index">Model Hub</a>, a repository for the community to share and discover pre-trained models. In this post I use the smallest NT, <a href="https://huggingface.co/InstaDeepAI/nucleotide-transformer-v2-50m-multi-species">a 50 million parameter model</a>, available from <a href="https://huggingface.co/InstaDeepAI">InstaDeep’s hub organization</a>.</p> <p>The other one is the many <a href="https://huggingface.co/docs/transformers/model_doc/auto"><code class="language-plaintext highlighter-rouge">transformers</code> AutoClasses</a>. They abstract away the specific model architecture, and the changes that would be needed to make it fit our use-case. For instance, fetching the NT adapted for masked language modeling is as easy as running:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForMaskedLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
  <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
  <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
    (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
    (decoder): Linear(in_features=512, out_features=4107, bias=False)
  )
)
</code></pre></div></div> <p>As expected, the output is a vector of length 4,107, one for each possible token.</p> <p>By using the <code class="language-plaintext highlighter-rouge">from_pretrained</code> method, we are loading both the architecture and the weights of the model. By default, the model is in evaluation mode; if we were to further fine-tune it, we would need to set it to training mode using <code class="language-plaintext highlighter-rouge">model.train()</code>. In contrast, we could use <code class="language-plaintext highlighter-rouge">from_config</code> to load the model architecture only. This would be appropriate to train the model from scratch.</p> <p>If instead we wanted to leverage the pre-trained model for binary classification, we would run:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
    (dropout): Dropout(p=0.0, inplace=False)
    (out_proj): Linear(in_features=512, out_features=2, bias=True)
  )
)
</code></pre></div></div> <p>As we can see, this added a (disabled) dropout layer, and a linear layer with two outputs, as requested.</p> <p>The model cannot be applied directly to a DNA sequence, which needs to be <a href="#a-worked-out-training-example">tokenized first</a>. Another AutoClasses, the <a href="https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoTokenizer">AutoTokenizer</a>, has got our back:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
  <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
  <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</code></pre></div></div> <h1 id="building-an-inference-pipeline">Building an inference pipeline</h1> <p>The NT’s <a href="https://huggingface.co/InstaDeepAI/nucleotide-transformer-v2-50m-multi-species">Model Card</a> shows how to embed DNA sequences. I copied that code below for your convenience:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForMaskedLM</span>
<span class="kn">import</span> <span class="n">torch</span>

<span class="c1"># Import the tokenizer and the model
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForMaskedLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>

<span class="c1"># Choose the length to which the input sequences are padded. By default, the
# model max length is chosen, but feel free to decrease it as the time taken to
# obtain the embeddings increases significantly with it.
</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">model_max_length</span>

<span class="c1"># Create a dummy dna sequence and tokenize it
</span><span class="n">sequences</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">ATGGTAGCTACATCATCT</span><span class="sh">"</span><span class="p">]</span>
<span class="n">tokens_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">batch_encode_plus</span><span class="p">(</span>
    <span class="n">sequences</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">max_length</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span><span class="p">)[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span>

<span class="c1"># Compute the embeddings
</span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">tokens_ids</span> <span class="o">!=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span>
<span class="n">torch_outs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span>
    <span class="n">tokens_ids</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
    <span class="n">encoder_attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="c1"># Compute sequences embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch_outs</span><span class="p">[</span><span class="sh">'</span><span class="s">hidden_states</span><span class="sh">'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Embeddings shape: </span><span class="si">{</span><span class="n">embeddings</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Embeddings per token: </span><span class="si">{</span><span class="n">embeddings</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Add embed dimension axis
</span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Compute mean embeddings per sequence
</span><span class="n">mean_sequence_embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">attention_mask</span><span class="o">*</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Mean sequence embeddings: </span><span class="si">{</span><span class="n">mean_sequence_embeddings</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

</code></pre></div></div> <p>This is a representation of a common workflow in inference, which looks like this:</p> <pre><code class="language-mermaid">---
config:
  layout: elk
  look: handDrawn
---
flowchart LR
    %% Style definitions
    classDef process fill:#a8dadc,stroke:#2f4f4f,stroke-width:2px,rx:8,ry:8,color:#000
    classDef data fill:#f9c74f,stroke:#2f4f4f,stroke-width:2px,rx:8,ry:8,color:#000

    %% Process nodes
    P2[Tokenizer]:::process
    P3[Model Inference]:::process
    P5[Postprocessing]:::process

    %% Data nodes
    D1[DNA Sequence]:::data
    D21[Tokens]:::data
    D22[Attention Mask]:::data
    D3[Embeddings]:::data
    D5[Masked Embeddings]:::data

    %% Connections
    D1 --&gt; P2
    P2 --&gt; D21
    P2 --&gt; D22
    D21 --&gt; P3
    D22 --&gt; P3
    P3 --&gt; D3
    D22 --&gt; P5
    D3  --&gt; P5
    P5 --&gt; D5
</code></pre> <details><summary>Wondering what is the attention mask?</summary> <p>The attention mask is a binary mask that, for a given input sequence, identifies the padding tokens that are there just to make the sequence fit the desired shape. They help the model avoid wasting (C/G/T)PU cycles on processing useless information. Or even worse, learning the wrong information, when we are not in inference mode. This mask is passed along through the model, and forces the attention scores for these padding tokens to effectively become zero.</p> </details> <p><a href="https://huggingface.co/docs/transformers/pipeline_tutorial">Hugging Face’s <code class="language-plaintext highlighter-rouge">pipelines</code></a> exist to encapsulate these inference steps while cutting the boilerplate code. In particular, every pipeline requires defining four steps:</p> <ul> <li>A function to sanitize the pipeline user-provided arguments</li> <li>A preprocessing function that converts inputs (DNA sequences) into tokenized sequences</li> <li>A forward function that passes the tokenized sequence through the model</li> <li>A postprocessing function that postprocess the model’s outputs</li> </ul> <p>I implemented a small pipeline to embed DNA sequences. Its inputs are Python strings and the output are numpy arrays.</p> <details><summary><code class="language-plaintext highlighter-rouge">DNAEmbeddingPipeline</code> class implementation</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="k">class</span> <span class="nc">DNAEmbeddingPipeline</span><span class="p">(</span><span class="n">Pipeline</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">_sanitize_parameters</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sh">"""</span><span class="s">
        Sanitize the parameters for the pipeline.

        Args:
            **kwargs: The parameters to be sanitized.

        Returns:
            Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]: A tuple containing
                the sanitized parameters for preprocessing, model forward pass, and
                postprocessing, respectively.
        </span><span class="sh">"""</span>
        <span class="n">preprocess_params</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">recognized_params</span> <span class="o">=</span> <span class="nf">set</span><span class="p">([</span><span class="sh">"</span><span class="s">max_length</span><span class="sh">"</span><span class="p">])</span>

        <span class="k">if</span> <span class="sh">"</span><span class="s">max_length</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">preprocess_params</span><span class="p">[</span><span class="sh">"</span><span class="s">max_length</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="sh">"</span><span class="s">max_length</span><span class="sh">"</span><span class="p">]</span>

        <span class="n">unrecognized_params</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">kwargs</span><span class="p">.</span><span class="nf">keys</span><span class="p">())</span> <span class="o">-</span> <span class="n">recognized_params</span>
        <span class="k">if</span> <span class="n">unrecognized_params</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Unrecognized pipeline parameters: </span><span class="si">{</span><span class="n">unrecognized_params</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">preprocess_params</span><span class="p">,</span> <span class="p">{},</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">model_inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">max_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">pt</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Preprocess the input sequences before passing them to the model.

        Args:
            model_inputs (Union[str, List[str]]): The input sequence(s) to be tokenized.
            max_length (Optional[int]): The maximum length of the tokenized sequences.
                If None, the maximum length of the tokenizer is used.

        Returns:
            List[pt.Tensor]: The tokenized input sequences.
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="n">max_length</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">max_length</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">model_max_length</span>

        <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">model_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">model_inputs</span><span class="p">]</span>

        <span class="n">tokens_ids</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">batch_encode_plus</span><span class="p">(</span>
            <span class="n">model_inputs</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">longest</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="p">)[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">tokens_ids</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">model_inputs</span><span class="p">:</span> <span class="n">pt</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Forward pass through the model.

        Args:
            model_inputs (pt.Tensor): The tokenized input sequence(s).

        Returns:
            Dict[str, Any]: The model outputs.
        </span><span class="sh">"""</span>
        <span class="c1"># find out which of the tokens are padding tokens
</span>        <span class="c1"># these tokens will be ignored by the model
</span>        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">model_inputs</span> <span class="o">!=</span> <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span>
            <span class="n">model_inputs</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">encoder_attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">out</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">attention_mask</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">postprocess</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">model_outputs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Compute the mean sequence embedding from the last hidden layer (size 512).

        Args:
            model_outputs (Dict[str, Any]): The model outputs.

        Returns:
            dict[str, np.ndarray]: The mean sequence embeddings for each input sequence.
        </span><span class="sh">"""</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">model_outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">hidden_states</span><span class="sh">"</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">detach</span><span class="p">()</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">model_outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">].</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">cpu</span><span class="p">()</span>
        <span class="n">masked_embeddings</span> <span class="o">=</span> <span class="n">attention_mask</span> <span class="o">*</span> <span class="n">embeddings</span>

        <span class="n">mean_sequence_embeddings</span> <span class="o">=</span> <span class="n">masked_embeddings</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">attention_mask</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">mean_sequence_embeddings</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
</code></pre></div></div> </details> <p>Once the pipeline is in place, embedding a sequence is as easy as:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForMaskedLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="nc">DNAEmbeddingPipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="n">embedding</span> <span class="o">=</span> <span class="nf">pipeline</span><span class="p">(</span><span class="sh">"</span><span class="s">ATGGTAGCTACATCATCTG</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>Encapsulating the model into its own inference pipeline has a few advantages. Beyond the obvious benefit of cleaner code by separating inference steps into logical abstractions, it makes swapping models a breeze, as you’ll see when we <a href="#fine-tuning-the-model">fine-tune the model</a>.</p> <h1 id="embedding-dna-sequences">Embedding DNA sequences</h1> <p>I will be using the NT to embed protein-coding DNA sequences from six species: three animals (human, mouse and fruit fly); one plant (arabidopsis); one bacteria (<em>E. coli</em>); and one yeast (<em>S. cerevisiae</em>). I aim to obtain embeddings such that the sequences from each species are on aggregate closer to each other than to the sequences from other species. Note that this is not something the model was trained to do. But I hope that the model picked up that a piece of bacterial DNA is very different from a chunk of human DNA.</p> <p>To this end, I <a href="https://github.com/hclimente/hclimente.github.io/blob/main/assets/python/2025-05-02-hf-transformers/prepare_data.sh">downloaded the DNA sequences</a> of all protein coding genes for the selected species. For each species I randomly subsampled 2,000 sequences of 60 nucleotides each. I chose the length of the sequence because of convenience: they are a common sequence length for FASTA files, and short enough for my modest home computer to handle. Half of them were the train set, used for model building; the other half constituted the test set, used exclusively for performance evaluation. All the results shown below are computed on the latter.</p> <p>I <a href="https://github.com/hclimente/hclimente.github.io/blob/main/assets/python/2025-05-02-hf-transformers/main.ipynb">embedded the sequences</a> and used a UMAP to visualize the embeddings:</p> <div class="l-page"> <iframe src="/assets/python/2025-05-02-hf-transformers/plotly/umap_embeddings.html" frameborder="0" scrolling="no" height="500px" width="100%"></iframe> </div> <div class="caption"> Scatter plot of the two UMAP dimensions from the embeddings computed by applying the <em>pre-trained</em> NT to the 6,000 DNA sequences test dataset, containing 1,000 sequences from each species. </div> <p>Some disclaimers need to be made. First, I took a minuscule sample of all protein coding sequences, which my sampling process slightly biases towards the beginning of the protein. Second, I am using the smallest NT, and its likely that larger models can represent these sequences more richly.</p> <p>Even with these limitations, sequences from the same species tend to inhabit similar regions of the underlying manifold. If you are unconvinced, just squint your eyes or toggle some species on and off. Since this is probably not too reassuring, maybe I can do better: I trained a multiclass logistic regression tasked with predicting the species from the sequence embeddings. This classifier achieved an accuracy of \(0.47\), convincingly above the accuracy of a random classifier (\(\frac 1 6 = 0.16\)). Furthermore, some of the errors are clearly between the two closest species from an evolutionary standpoint: human and mouse.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-05-02-hf-transformers/img/confusion_matrix_test.webp" sizes="95vw"/> <img src="/assets/python/2025-05-02-hf-transformers/img/confusion_matrix_test.webp" class="img-fluid" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="fine-tuning-the-model">Fine-tuning the model</h1> <p>The NT was trained via MLM, and it never got any explicit information about which species it was looking at. Hence, it’s not too surprising that it can’t separate different species right off the bat. Fine-tuning it to this task should provide more relevant representations. <code class="language-plaintext highlighter-rouge">transformers</code> also provides an easy way of doing that using <code class="language-plaintext highlighter-rouge">transformers.Trainer</code>. (For the record, I am unconvinced Hugging Face provides a better solution than <a href="https://lightning.ai">Lightning</a> and others; however, it can be convenient if you are already in teh Hugging Face ecosystem.)</p> <p>We will start by importing the model using a the right AutoClass for the task:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">classif_nt</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">Trainer</code> makes fine-tuning the model quite easy. The task is to predict the species from the sequence. I froze the first few layers from the NT, which should capture low level features of the sequences, and will only train the last layers. Then, I specify the trainer configuration:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_args</span> <span class="o">=</span> <span class="nc">TrainingArguments</span><span class="p">(</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">eval_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">epoch</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">save_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">epoch</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">metric_for_best_model</span><span class="o">=</span><span class="sh">"</span><span class="s">accuracy</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>  <span class="c1"># not supported by mps
</span><span class="p">)</span>
<span class="n">data_collator</span> <span class="o">=</span> <span class="nc">DataCollatorWithPadding</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer_nt</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="nc">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">classif_nt</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">tr_train_ds</span><span class="p">,</span>    <span class="c1"># train on 90% of the train set
</span>    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">tr_val_ds</span><span class="p">,</span>       <span class="c1"># evaluate on 10% of the train set
</span>    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_trainer_metrics</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div> <p>Last, I just begin training with:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainer</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
</code></pre></div></div> <p>After the model is trained, as specified in the trainer arguments, the model with the best performance on the validation dataset will be the loaded.</p> <p>We can create a new inference pipeline focus around classification. The pipeline will output both the probability of each class, as well as the embeddings, obtained from the last layer. Since this model is tasked explicitly with telling apart sequences coming from different species, the embedding should provides a much better separation:</p> <div class="l-page"> <iframe src="/assets/python/2025-05-02-hf-transformers/plotly/umap_embeddings_ft-model.html" frameborder="0" scrolling="no" height="500px" width="100%"></iframe> </div> <div class="caption"> Scatter plot of the two UMAP dimensions from the embeddings computed by applying the <em>fine-tuned</em> NT to the 6,000 DNA sequences test dataset, containing 1,000 sequences from each species. </div> <p>Maybe this time you won’t even need to squint your eyes to agree.</p> <h1 id="conclusions">Conclusions</h1> <p>In this post, I have given a primer on how to use Hugging Face’s libraries for a particular flavor of BioML work. Yet, in my opinion, Hugging Face’s greatest strength lies just in the boundaries of this post’s focus: on its community. With its <a href="https://huggingface.co/docs/hub/en/models-the-hub">Model Hub</a> they have made it easy for researchers to quickly prototype and share models, and to build on top of existing ones.</p>]]></content><author><name></name></author><category term="python"/><category term="machine_learning"/><category term="huggingface"/><summary type="html"><![CDATA[Using Hugging Face transformers]]></summary></entry><entry><title type="html">An intro to uv</title><link href="https://hclimente.github.io/blog/python-uv/" rel="alternate" type="text/html" title="An intro to uv"/><published>2025-04-25T11:59:00+00:00</published><updated>2025-04-25T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/python-uv</id><content type="html" xml:base="https://hclimente.github.io/blog/python-uv/"><![CDATA[<p>Python veterans will be familiar with <code class="language-plaintext highlighter-rouge">pip</code>, <code class="language-plaintext highlighter-rouge">poetry</code>, <code class="language-plaintext highlighter-rouge">pyenv</code>, <code class="language-plaintext highlighter-rouge">conda</code> and a few other tools for managing projects, packages and environments. <a href="https://github.com/astral-sh/uv"><code class="language-plaintext highlighter-rouge">uv</code></a>’s goal is to replace them all while being blazingly fast.</p> <p>We will use <code class="language-plaintext highlighter-rouge">uv</code> for a prototypical machine learning project: train a neural network to classify images of handwritten digits from the <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST dataset</a> using a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a>. The input of the model will be a 28x28 pixel image, and the output will be a vector of 10 probabilities, one for each digit. If you are interested in the details of the model, you can check out the <a href="https://github.com/hclimente/hclimente.github.io/tree/main/assets/python/2025-03-15-python-uv/mnist-classifier">code</a>.</p> <div style="width:50%; margin:0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-03-15-python-uv/mnist-classifier/img/mnist_examples.webp" sizes="95vw"/> <img src="/assets/python/2025-03-15-python-uv/mnist-classifier/img/mnist_examples.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="Sample MNIST digits" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> A few examples from MNIST </div> <p>My previous workflow relied on <code class="language-plaintext highlighter-rouge">conda</code> to handle the project environment. I’d start by creating a new conda environment and installing several packages via slow <code class="language-plaintext highlighter-rouge">conda install</code> commands before getting to work. If during model development I needed additional packages, I’d run another <code class="language-plaintext highlighter-rouge">conda install</code> hoping to avoid the dreaded <code class="language-plaintext highlighter-rouge">Solving environment: failed with initial frozen solve. Retrying with flexible solve.</code> error. Once I’d finish, I’d dump my environment into an <code class="language-plaintext highlighter-rouge">environment.yaml</code>, strip-out dev-only dependencies, and hope that the final environment sufficiently resembles the one I worked on. Finally, I’d package the model into a Docker image to get it ready for production.</p> <p>Clearly, I wasn’t thrilled with my old workflow. Let’s see how <code class="language-plaintext highlighter-rouge">uv</code> made it a more pleasant experience.</p> <h1 id="why-uv">Why <code class="language-plaintext highlighter-rouge">uv</code>?</h1> <p>Before diving into the details, it’s worth justifying why we need <em>yet another tool</em> for managing Python-centric data science projects.</p> <p>First, <code class="language-plaintext highlighter-rouge">uv</code> is <strong>fast</strong>. As is common in new high-performance tools, it’s written in Rust, a compiled language known for its performance. It also uses different strategies to speed up package installation, like caching and parallelization. Anyone who has installed a package with <code class="language-plaintext highlighter-rouge">conda</code> knows that package resolution can be a pretty painful experience.</p> <p>Second, <code class="language-plaintext highlighter-rouge">uv</code> boosts <strong>reproducibility</strong>. As we will see below, it makes it easy to create and share virtual environments. This is key to ensure that multiple developers can work on a consistent environment. Furthermore, it facilitates moving projects from development to production.</p> <p>Third, <code class="language-plaintext highlighter-rouge">uv</code> leverages <strong>common standards</strong> within the Python ecosystem. This reduces the risk of being locked into its ecosystem, and makes it easy to collaborate with other developers that use different tools.</p> <p>Last, <code class="language-plaintext highlighter-rouge">uv</code> is <strong>one</strong> tool, which means that I don’t need to remember the syntax of multiple tools, or how to use them together.</p> <details><summary>Why <em>not</em> <code class="language-plaintext highlighter-rouge">uv</code>?</summary> <p>I’m always quite enthusiastic about the new, shinier tool. But before jumping straight into <code class="language-plaintext highlighter-rouge">uv</code>, it’s worth considering the downsides of adopting it.</p> <p>First, <code class="language-plaintext highlighter-rouge">uv</code> is <strong>young</strong>. In contrast, tools like <code class="language-plaintext highlighter-rouge">pip</code>, <code class="language-plaintext highlighter-rouge">conda</code> or <code class="language-plaintext highlighter-rouge">venv</code> have been around for more than a decade. I have no doubt they will be around for at least another decade and are unlikely to pull the rug from under me with breaking changes.</p> <p>Second, and on a related note, <code class="language-plaintext highlighter-rouge">uv</code> is <strong>not widely adopted</strong>. This means that I have had a hard time troubleshooting some errors. It has also meant that it’s not a standard, and you might need to be prepared to advocate for it in your team.</p> <p>Last, <code class="language-plaintext highlighter-rouge">uv</code> is mainly developed by <a href="https://astral.sh">Astral</a>, a VC-backed startup that hasn’t started monetizing their products yet. It remains to be seen how their future business model will impact their tools. I should highlight that <code class="language-plaintext highlighter-rouge">uv</code> is open-source and licensed under MIT, which is somewhat reassuring.</p> <p>I believe that it’s a worthwhile trade-off. But, you know, <em>caveat emptor</em>.</p> </details> <h1 id="starting-a-new-project">Starting a new project</h1> <p>After <a href="https://docs.astral.sh/uv/getting-started/installation/">installing <code class="language-plaintext highlighter-rouge">uv</code></a>, we simply need to run <code class="language-plaintext highlighter-rouge">uv init</code> to start a new project:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>uv init mnist-classifier
</code></pre></div></div> <p>This creates a directory <code class="language-plaintext highlighter-rouge">mnist-classifier</code> in the current directory containing a few files we’ll soon dig into. One of them is a <a href="https://packaging.python.org/en/latest/guides/writing-pyproject-toml/"><code class="language-plaintext highlighter-rouge">pyproject.toml</code></a> file that stores the project’s metadata and configuration. This is a standard file used by <a href="https://python-poetry.org/docs/pyproject/">many</a> <a href="https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/">tools</a> <a href="https://docs.astral.sh/ruff/configuration/">in</a> <a href="https://black.readthedocs.io/en/stable/usage_and_configuration/the_basics.html#command-line-options">the</a> <a href="https://docs.pytest.org/en/stable/reference/customize.html#pyproject-toml">Python</a> <a href="https://setuptools.pypa.io/en/latest/userguide/pyproject_config.html">ecosystem</a>. For instance, <code class="language-plaintext highlighter-rouge">pip install .</code> would install all the packages listed under the <code class="language-plaintext highlighter-rouge">dependencies</code> field. The <code class="language-plaintext highlighter-rouge">pyproject.toml</code> file created by <code class="language-plaintext highlighter-rouge">uv</code> looks like this:</p> <div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[project]</span>
<span class="py">name</span> <span class="p">=</span> <span class="s">"mnist-classifier"</span>
<span class="py">version</span> <span class="p">=</span> <span class="s">"0.1.0"</span>
<span class="py">description</span> <span class="p">=</span> <span class="s">"Add your description here"</span>
<span class="py">readme</span> <span class="p">=</span> <span class="s">"README.md"</span>
<span class="py">requires-python</span> <span class="p">=</span> <span class="py">"&gt;</span><span class="p">=</span><span class="mf">3.10</span><span class="s">"</span><span class="err">
</span><span class="py">dependencies</span> <span class="p">=</span> <span class="p">[]</span>
</code></pre></div></div> <p>Furthermore, it will start a git repository with a sensible <code class="language-plaintext highlighter-rouge">.gitignore</code>.</p> <details><summary>What about <em>package</em> projects?</summary> <p>By default, <code class="language-plaintext highlighter-rouge">uv init</code> creates an <em>application</em> project. This is appropriate for scripts, like simple tools. This is why the command above created a <code class="language-plaintext highlighter-rouge">main.py</code> file, meant to be the entry point of our application. Alternatively, we could create a <em>library</em> project with <code class="language-plaintext highlighter-rouge">uv init --package mnist-classifier-pkg</code>. This would create a new directory <code class="language-plaintext highlighter-rouge">mnist-classifier-pkg</code> and populate it with a standard structure and configuration suitable for a Python library.</p> </details> <h1 id="creating-the-project-environment">Creating the project environment</h1> <p>Multiple Python projects can co-exist on the same machine, each requiring different packages and versions of the same packages. This is facilitated by <em>virtual environments</em>, self-contained directories with their own Python interpreter and installed Python packages. There are multiple solutions to create and manage virtual environments, like <a href="https://docs.python.org/3/library/venv.html"><code class="language-plaintext highlighter-rouge">venv</code></a>, <a href="https://anaconda.org/anaconda/conda"><code class="language-plaintext highlighter-rouge">conda</code></a> or <a href="https://python-poetry.org/"><code class="language-plaintext highlighter-rouge">poetry</code></a>.</p> <p><code class="language-plaintext highlighter-rouge">uv</code> leverages Python’s built-in package to handle virtual environments: <code class="language-plaintext highlighter-rouge">venv</code>. The virtual environment contains its own installation of Python, whose version is specified in <code class="language-plaintext highlighter-rouge">.python-version</code>. <code class="language-plaintext highlighter-rouge">uv init</code> created this file:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3.10
</code></pre></div></div> <p>The virtual environment itself lives in the <code class="language-plaintext highlighter-rouge">.venv</code> directory. When Python runs from within an environment, it uses the packages installed in that environment, and only those packages. Typically we would activate this virtual environment from the terminal with <code class="language-plaintext highlighter-rouge">source .venv/bin/activate</code>. This will append <code class="language-plaintext highlighter-rouge">.venv/bin/</code> to our <code class="language-plaintext highlighter-rouge">PATH</code>, loading the <code class="language-plaintext highlighter-rouge">python</code> located there into our environment. However, this comes with an overhead: we need to remember to activate the environment before running any Python script, and we need to deactivate (<code class="language-plaintext highlighter-rouge">deactivate</code>) it when we are done. This is a source of errors, as we may forget to activate the environment or, worse, forget to deactivate it.</p> <p>That’s why <code class="language-plaintext highlighter-rouge">uv</code> does not require explicitly activating the environment. Instead, we can use <code class="language-plaintext highlighter-rouge">uv run &lt;script&gt;.py</code> to run any Python script or command using the environment’s Python. For instance, <code class="language-plaintext highlighter-rouge">uv init</code> created a short, example script, <code class="language-plaintext highlighter-rouge">main.py</code>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Hello from mnist-classifier!</span><span class="sh">"</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="nf">main</span><span class="p">()</span>
</code></pre></div></div> <p>As stated, we can run it using our default Python, as we are used to (<code class="language-plaintext highlighter-rouge">python main.py</code>), maybe after <code class="language-plaintext highlighter-rouge">source .venv/bin/activate</code>. But we can also run it using <code class="language-plaintext highlighter-rouge">uv run main.py</code>, which will run the script using the environment’s Python interpreter. Besides avoiding loading/unloading virtual environments, <code class="language-plaintext highlighter-rouge">uv run</code> will automatically create the project environment if it does not exist. Similarly, we can run an interactive Python session via <code class="language-plaintext highlighter-rouge">uv run python</code>.</p> <h2 id="installing-the-required-packages">Installing the required packages</h2> <p>Upon its first invocation, <code class="language-plaintext highlighter-rouge">uv run main.py</code> creates a virtual environment. To do this, it examines the (empty) <code class="language-plaintext highlighter-rouge">dependencies</code> list in <code class="language-plaintext highlighter-rouge">pyproject.toml</code> and resolves an (empty) set of packages.</p> <p>To start our little data science project, we’ll need to install the <a href="https://pytorch.org/">PyTorch</a> library. Typically I would have run <code class="language-plaintext highlighter-rouge">conda install conda-forge::pytorch</code>; in <code class="language-plaintext highlighter-rouge">uv</code> we use <code class="language-plaintext highlighter-rouge">uv add torch</code> instead. This installs the most recent version of the package that is compatible with our environment (2.7.0). The whole thing took 9 seconds. For comparison, installing <code class="language-plaintext highlighter-rouge">torch</code> with <code class="language-plaintext highlighter-rouge">conda</code> took 48 seconds. Upon installation, <code class="language-plaintext highlighter-rouge">pyproject.toml</code> gets automatically updated to:</p> <div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="py">dependencies</span> <span class="p">=</span> <span class="p">[</span>
    <span class="py">"torch&gt;</span><span class="p">=</span><span class="mf">2.7</span><span class="err">.</span><span class="mi">0</span><span class="s">",</span><span class="err">
</span><span class="p">]</span>
</code></pre></div></div> <p>This is great, as it allows us to keep track of the packages that we needed for our project, reducing our overhead down the road as the project matures.</p> <p>However, <code class="language-plaintext highlighter-rouge">torch</code> depends, in turn, on other packages, like <code class="language-plaintext highlighter-rouge">numpy</code>. Note that this is not reflected in <code class="language-plaintext highlighter-rouge">pyproject.toml</code>, which lists only our direct dependencies, not every transitive package. Furthermore, as we install additional packages like <code class="language-plaintext highlighter-rouge">torchvision</code> or <code class="language-plaintext highlighter-rouge">matplotlib</code>, <code class="language-plaintext highlighter-rouge">uv</code> will need to resolve all the dependencies and potential conflicts between the packages. <code class="language-plaintext highlighter-rouge">uv</code> keeps an additional file, the lockfile (<code class="language-plaintext highlighter-rouge">uv.lock</code>) that records the exact state of the environment with all the specific package resolutions. The lockfile is thus considerably more thorough than <code class="language-plaintext highlighter-rouge">pyproject.toml</code>. For instance, after <code class="language-plaintext highlighter-rouge">uv add torch</code> it expanded to 353 lines describing all the specific packages, their versions and the metadata that were installed in the environment. This is a small excerpt of the lockfile:</p> <div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[[package]]</span>
<span class="py">name</span> <span class="p">=</span> <span class="s">"filelock"</span>
<span class="py">version</span> <span class="p">=</span> <span class="s">"3.18.0"</span>
<span class="py">source</span> <span class="o">=</span> <span class="p">{</span> <span class="py">registry</span> <span class="p">=</span> <span class="s">"https://pypi.org/simple"</span> <span class="p">}</span>
<span class="py">sdist</span> <span class="o">=</span> <span class="p">{</span> <span class="py">url</span> <span class="p">=</span> <span class="s">"https://files.pythonhosted.org/packages/0a/10/c23352565a6544bdc5353e0b15fc1c563352101f30e24bf500207a54df9a/filelock-3.18.0.tar.gz"</span><span class="p">,</span> <span class="py">hash</span> <span class="p">=</span> <span class="s">"sha256:adbc88eabb99d2fec8c9c1b229b171f18afa655400173ddc653d5d01501fb9f2"</span><span class="p">,</span> <span class="py">size</span> <span class="p">=</span> <span class="mi">18075</span> <span class="p">}</span>
<span class="py">wheels</span> <span class="p">=</span> <span class="p">[</span>
    <span class="err">{</span> <span class="py">url</span> <span class="p">=</span> <span class="s">"https://files.pythonhosted.org/packages/4d/36/2a115987e2d8c300a974597416d9de88f2444426de9571f4b59b2cca3acc/filelock-3.18.0-py3-none-any.whl"</span><span class="p">,</span> <span class="py">hash</span> <span class="p">=</span> <span class="s">"sha256:c401f4f8377c4464e6db25fff06205fd89bdd83b65eb0488ed1b160f780e21de"</span><span class="p">,</span> <span class="py">size</span> <span class="p">=</span> <span class="mi">16215</span> <span class="err">}</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">uv.lock</code> should be under git control, providing the exact recipe to replicate an environment. This is key, for instance, to ensure that all developers work on a consistent environment. It can also facilitate moving our code to production, as we’ll see <a href="#training--shipping-the-model">below</a>.</p> <blockquote> <p>If needed, <code class="language-plaintext highlighter-rouge">uv.lock</code> can be exported into a <a href="https://pip.pypa.io/en/stable/reference/requirements-file-format/"><code class="language-plaintext highlighter-rouge">requirements.txt</code></a> file for legacy tools, via <code class="language-plaintext highlighter-rouge">uv export --format=requirements-txt &gt;requirements.txt</code>.</p> </blockquote> <details><summary>Other package management commands</summary> <p>Besides <code class="language-plaintext highlighter-rouge">uv add</code>, there are other commands that can be used to manage packages. For starters, its counterpart <code class="language-plaintext highlighter-rouge">uv remove &lt;package_name&gt;</code> will uninstall <code class="language-plaintext highlighter-rouge">&lt;package_name&gt;</code>. Another command that can trigger package management is <code class="language-plaintext highlighter-rouge">uv run &lt;script&gt;.py</code>. Before running the script, it will ensure that the lockfile is in sync with <code class="language-plaintext highlighter-rouge">pyproject.toml</code> and then ensure that the project environment is in sync with the lockfile.</p> <p>Syncing refers to (un)installing packages in the project environment to match the lockfile. <code class="language-plaintext highlighter-rouge">uv run</code> will do this automatically, as we just saw. But it can also be forced manually with <code class="language-plaintext highlighter-rouge">uv sync</code>.</p> <p>Last, when adding new packages, <code class="language-plaintext highlighter-rouge">uv</code> will tend to be conservative. It will install the most recent version of the package that is compatible with the current environment. To force a specific version, we can use <code class="language-plaintext highlighter-rouge">uv add &lt;package_name&gt;==&lt;version&gt;</code>. For instance, <code class="language-plaintext highlighter-rouge">uv add torch==2.0.1</code> will install version 2.0.1 of <code class="language-plaintext highlighter-rouge">torch</code>, even if a newer version is available. We can request <code class="language-plaintext highlighter-rouge">uv</code> to upgrade all packages if possible with <code class="language-plaintext highlighter-rouge">uv lock --upgrade</code>; or a specific package with <code class="language-plaintext highlighter-rouge">uv lock --upgrade-package &lt;package_name&gt;</code>.</p> <blockquote> <p>To keep compatibility with <code class="language-plaintext highlighter-rouge">pip</code> workflows, <code class="language-plaintext highlighter-rouge">uv</code> also supports <code class="language-plaintext highlighter-rouge">uv pip install &lt;package_name&gt;</code> and <code class="language-plaintext highlighter-rouge">uv pip uninstall &lt;package_name&gt;</code>. These will (un)install the package in the current environment, but it will not update <code class="language-plaintext highlighter-rouge">pyproject.toml</code> or <code class="language-plaintext highlighter-rouge">uv.lock</code>. For this reason, they should be avoided in favor of <code class="language-plaintext highlighter-rouge">uv add</code> and <code class="language-plaintext highlighter-rouge">uv remove</code>.</p> </blockquote> </details> <h2 id="installing-development-only-dependencies">Installing development-only dependencies</h2> <p>As a data scientist, Jupyter notebooks are my bread and butter. In order to run Jupyter notebooks on our <code class="language-plaintext highlighter-rouge">uv</code> environment, we need to install the <a href="https://pypi.org/project/ipykernel/">IPython kernel <code class="language-plaintext highlighter-rouge">ipykernel</code></a>. However, <code class="language-plaintext highlighter-rouge">ipykernel</code>’s role is different from other packages: it is not a dependency of our code, but a tool needed for development. Once my code is ready, I will distribute it as a standalone Python script that has no dependencies on <code class="language-plaintext highlighter-rouge">ipykernel</code>. The same principle applies to tools like <code class="language-plaintext highlighter-rouge">pytest</code>, used to test your code, but which the end-user shouldn’t require unless they intend to contribute to the project.</p> <p><code class="language-plaintext highlighter-rouge">uv</code> allows you to add development dependencies with <code class="language-plaintext highlighter-rouge">uv add --dev ipykernel</code>, which will add the following to <code class="language-plaintext highlighter-rouge">pyproject.toml</code>:</p> <div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[dependency-groups]</span>
<span class="py">dev</span> <span class="p">=</span> <span class="p">[</span>
    <span class="py">"ipykernel&gt;</span><span class="p">=</span><span class="mf">6.29</span><span class="err">.</span><span class="mi">5</span><span class="s">",</span><span class="err">
</span><span class="p">]</span>
</code></pre></div></div> <p>This should allow my tool of choice, Visual Studio Code, to find this virtual environment and run Jupyter notebooks on it. However, in my experience, it has been somewhat unreliable: Visual Studio Code only finds the kernel half of the time. A workaround is launching a JupyterLab server instance with <code class="language-plaintext highlighter-rouge">uv run --with jupyter jupyter lab</code> and connecting to it from the editor.</p> <h1 id="training--shipping-the-model">(Training &amp;) Shipping the model</h1> <p>Here comes the actual data science, which I will just skim over. I wrote a simple script to train a convolutional neural network on the MNIST dataset. The script is located in <a href="https://github.com/hclimente/hclimente.github.io/tree/main/assets/python/2025-03-15-python-uv/mnist-classifier/train.py"><code class="language-plaintext highlighter-rouge">train.py</code></a>, and can be run with <code class="language-plaintext highlighter-rouge">uv run train.py</code>. It achieves a 98% classification accuracy on the held-out samples. Neat!</p> <p>Now that we have a working model, let’s see how <code class="language-plaintext highlighter-rouge">uv</code> helps us package the model into a Docker image.</p> <p>First, we need to pick our base image. Astral provides <a href="https://docs.astral.sh/uv/guides/integration/docker/#available-images">multiple pre-built images</a> that include <code class="language-plaintext highlighter-rouge">uv</code> and different versions of Python. Then, deploying the model is as easy as copying the model weights and the prediction script <a href="https://github.com/hclimente/hclimente.github.io/tree/main/assets/python/2025-03-15-python-uv/mnist-classifier/predict.py"><code class="language-plaintext highlighter-rouge">predict.py</code></a> into the image, copying <code class="language-plaintext highlighter-rouge">uv</code> project environment files, and building the environment:</p> <div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">FROM</span><span class="s"> ghcr.io/astral-sh/uv:python3.10-bookworm-slim</span>

<span class="k">RUN </span><span class="nb">mkdir</span> <span class="nt">-p</span> /mnist_classifier/data
<span class="k">WORKDIR</span><span class="s"> /mnist_classifier</span>

<span class="c"># ensure uv.lock isn't modified</span>
<span class="k">ENV</span><span class="s"> UV_LOCKED=1</span>

<span class="c"># copy the minimum required files:</span>
<span class="c">## the uv files needed to recreate the environment</span>
<span class="k">COPY</span><span class="s"> pyproject.toml uv.lock ./</span>
<span class="c">## the prediction script</span>
<span class="k">COPY</span><span class="s"> predict.py .</span>
<span class="c">## the model weights</span>
<span class="k">COPY</span><span class="s"> data/mnist_cnn.pt data/</span>

<span class="c"># recreate the environment</span>
<span class="k">RUN </span>uv <span class="nb">sync</span> <span class="nt">--no-dev</span>

<span class="k">CMD</span><span class="s"> ["uv", "run", "predict.py"]</span>
</code></pre></div></div> <p>The key command here was <code class="language-plaintext highlighter-rouge">uv sync</code>, which will recreate the environment using the exact versions of the packages specified in <code class="language-plaintext highlighter-rouge">uv.lock</code>. This ensures that the environment used to train the model is identical to the one used to share it. Notice that the <code class="language-plaintext highlighter-rouge">--no-dev</code> flag will exclude the packages used for development, like <code class="language-plaintext highlighter-rouge">ipykernel</code>. It’s worth highlighting that the lockfile is cross-platform: I generated it on macOS, but the Docker image is based on Debian.</p> <blockquote> <p>Note: If you use GPU-specific packages, wheels may differ. See <a href="https://docs.astral.sh/uv/guides/integration/pytorch/#installing-pytorch">Astral’s docs</a>.</p> </blockquote> <p>Let’s now build and run the image:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker build <span class="nt">-t</span> mnist_classifier <span class="nb">.</span>
docker run mnist_classifier
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SimpleCNN(
  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
Downloading MNIST test set...
Accuracy of SimpleCNN on the 10,000 test images: 98 %
</code></pre></div></div> <p>Nice!</p> <h1 id="conclusions">Conclusions</h1> <p>We have seen how <code class="language-plaintext highlighter-rouge">uv</code> can be used to manage Python projects, packages and environments. It satisfies my craving for reproducibility, is snappy and has simplified repetitive workflows. I look forward to seeing how it keeps evolving.</p> <h1 id="further-reading">Further reading</h1> <ul> <li><a href="https://www.bitecode.dev/p/a-year-of-uv-pros-cons-and-should">A year of uv: pros, cons, and should you migrate</a></li> </ul>]]></content><author><name></name></author><category term="python"/><category term="coding"/><summary type="html"><![CDATA[A Swiss Army Knife for Python data science]]></summary></entry><entry><title type="html">SHAP values</title><link href="https://hclimente.github.io/blog/shapley/" rel="alternate" type="text/html" title="SHAP values"/><published>2025-04-01T11:59:00+00:00</published><updated>2025-04-01T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/shapley</id><content type="html" xml:base="https://hclimente.github.io/blog/shapley/"><![CDATA[<p>SHAP values are a model-agnostic method to quantify the contribution of any given feature to a model’s prediction. They offer both local (per prediction) and global (overall) interpretations.</p> <h1 id="shapley-values">Shapley values</h1> <p>SHAP values have their roots in game theory, specifically in <strong>Shapley</strong> values. Imagine a group of players collaborating to achieve a payout. The Shapley value is a method to find out how to fairly distribute the total earnings among the players. Or the blame, if the payout was negative!</p> <p>A core concept of Shapley values is <strong>coalitions</strong>: given \(n\) players, a coalition is a subset of the players. Another concept is the <strong>characteristic function</strong>, \(v: 2^N \rightarrow \mathbb{R}\), which returns the total payout for any given coalition (its <em>worth</em>). Here, \(N\) is the set of all players. The last concept is the Shapley value itself, the amount \(\phi_i\) that player \(i\) receives. It is computed as the average of the marginal contributions of player \(i\) to all possible coalitions that do not include it. More formally, for a game \((v, N)\):</p> \[\phi_i(v) = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!\; (n-|S|-1)!}{n!} (v(S\cup\{i\})-v(S))\] <p>These values satisfy four key properties, which collectively ensure fair attribution: efficiency, symmetry, dummy player, and additivity.</p> <h2 id="efficiency">Efficiency</h2> <p>The grand coalition is the coalition of all players, \(N\). Efficiency means that the sum of all Shapley values equals the value of the grand coalition, i.e., the entire payout is distributed among the players:</p> \[\sum_{i \in N} \phi_i(v) = v(N)\] <h2 id="symmetry">Symmetry</h2> <p>Two players \(i\) and \(j\) are symmetric if their marginal contribution to any coalition not containing either player is the same. That is, if \(v(S \cup \{i\}) = v(S \cup \{j\})\) for any coalition \(S \subseteq N \setminus \{i, j\}\), then symmetry implies that players \(i\) and \(j\) receive the same Shapley value: \(\phi_i(v) = \phi_j(v)\).</p> <h2 id="dummy-player">Dummy player</h2> <p>If a player \(i\) does not change the value of any coalition they join (i.e., \(v(S \cup \{i\}) = v(S)\) for all \(S \subseteq N \setminus \{i\}\)), they are a dummy player. The dummy player property states that such a player’s Shapley value is 0.</p> <h2 id="additivity">Additivity</h2> <p>If two games with characteristic functions \(v_1\) and \(v_2\) are combined into a new game \(v_1 + v_2\) (where \((v_1+v_2)(S) = v_1(S) + v_2(S)\) for any coalition \(S\)), the Shapley values are additive:</p> \[\phi_i(v_1+v_2) = \phi_i(v_1) + \phi_i(v_2)\] <h1 id="shap-values">SHAP values</h1> <p>Machine learning models like linear regression are <em>interpretable</em>, as the model parameters indicate how each input feature contributes to the prediction. However, many complex models like neural networks or random forests are less directly interpretable: their output is a complex, non-linear combination of the input features. SHAP values (<a href="https://arxiv.org/abs/1705.07874">Lundberg and Lee, 2017</a>) provide a framework to quantify the contribution of each feature to a specific prediction for <em>any</em> model. SHAP stands for SHapley Additive exPlanations, highlighting their connection to <em>Shapley</em> values.</p> <p>Intuitively, SHAP values quantify how much each feature’s presence changes the prediction. Some features will have a negative contribution (pushing the prediction lower) and others a positive contribution (pushing the prediction higher). The sum of a feature’s SHAP value and a baseline value (typically the average prediction) approximates the model’s output.</p> <p>To establish the connection to Shapley values, we map the game theory concepts to the machine learning context:</p> <ul> <li>The \(n\) players become \(n\) <em>predictive features</em>.</li> <li>The game is the <em>trained model</em>.</li> <li>The payout for a coalition of features is the <em>model’s prediction</em> when only those features are known.</li> </ul> <p>The Shapley value \(\phi_i\) for feature \(i\) in this context is then calculated as:</p> \[\phi_i = \sum_{S \subseteq F \setminus \{i\}} \frac{|S|!\; (n-|S|-1)!}{n!} (f(\mathbf{x}_{S\cup\{i\}})-f(\mathbf{x}_S))\] <p>where \(\mathbf{x}_S\) is the input datapoint including only the features in \(S\); \(F\) is the set of all features; \(n\) is the total number of features; and \(f_S\) is the model trained only on the features in set \(S\). However, this naïve approach is very computationally intensive, since it’d require retraining \(2^n\) models, one per possible coalition. (See a worked out example <a href="https://www.aidancooper.co.uk/how-shapley-values-work/">here</a>.) SHAP values get around re-training models by approximating the effect of feature subsets using conditional expectations: \(f(\mathbf{x}_S) = \mathbb{E}[f(X) \mid X_S = \mathbf{x}_S]\). In other words, we fix the features that are in \(S\) to the sample values, and average over the predictions when sampling the remaining features from the dataset.</p> <blockquote> <p><strong><em>Simplified</em> features:</strong> We use \(\mathbf{x}\) for the features in the original space \(\chi\), a vector of length \(n\). The SHAP theoretical framework uses a simplified feature vector \(\mathbf{x}' \in \{0,1\}^m\), where \(m\) is the number of simplified features (which can be different from \(n\)). \(x'_j = 1\) indicates that simplified feature \(j\) is “present” in a coalition, and \(x'_j = 0\) indicates it is “absent”. The simplified features are more useful for interpretation. For instance, if \(\mathbf{x}\) represented the individual pixels of an image, \(\mathbf{x}'\) could represent the presence of the “super pixels” that form a cat, grass or the sky. A mapping function \(h_\mathbf{x}: \{0,1\}^m \rightarrow \chi\) links the simplified representation back to the original feature space. For \(\mathbf{x}' = \mathbf{1}\) (all simplified features present), \(h_\mathbf{x}(\mathbf{1}) = \mathbf{x}\). For other \(\mathbf{x}'\), \(h_\mathbf{x}(\mathbf{x}')\) represents the original instance with features corresponding to \(x'_j=0\) appropriately handled (e.g., replaced by baseline values). Note that \(h_\mathbf{x}\) is specific to the instance \(\mathbf{x}\) being explained.</p> </blockquote> <p>That covers the <em>Shapley</em> part of SHAP; let’s now focus on the <em>Additive exPlanation</em> bit. The goal of SHAP is to obtain a local, additive explanation model \(g\) for each prediction \(f(\mathbf{x})\) using the simplified features \(\mathbf{x}'\):</p> \[g(\mathbf{x}') = \phi_0 + \sum_{j = 1}^m \phi_j \mathbf{x}'_j\] <p>where \(\phi_0\) is the expectation over all training examples \(\mathbb{E}[f(X)]\). \(g(\mathbf{x}')\) is a very easy to interpret function that we’ll use to explain \(f(\mathbf{x})\).</p> <p>Since SHAP values are Shapley values, they meet all the properties specified above. But they also satisfy three additional properties that are desirable for model explainers.</p> <h2 id="local-accuracy">Local accuracy</h2> <p>When all simplified features are present (\(\mathbf{x}' = \mathbf{1}\)), the explanation model \(g\) must equal the prediction \(f(\mathbf{x})\):</p> \[f(\mathbf{x}) = g(\mathbf{1}) = \phi_0 + \sum_{j = 1}^m \phi_j\] <h2 id="missingness">Missingness</h2> <p>If a feature is missing, it deserves 0 attribution:</p> \[\mathbf{x}'_j = 0 \implies \phi_j = 0.\] <p>This is a required property to ensure that local accuracy has a unique solution.</p> <h2 id="consistency">Consistency</h2> <p>The consistency ensures that if a model \(f\) changes into another model \(f'\), such that a feature’s contribution doesn’t decrease, the SHAP values do not decrease either. Formally, if</p> \[f'(S) - f'(S \setminus \{i\}) \geq f(S) - f(S \setminus \{i\})\] <p>for all \(S \in F\), then \(\phi_i(f', \mathbf{x}) \geq \phi_i(f, \mathbf{x})\).</p> <h1 id="a-visual-example">A visual example</h1> <p>Let’s understand SHAP values better by looking at an example. I trained a model that uses 10 clinical features (body mass index, cholesterol, age, and a few others) to predict a continuous measure of disease progression one year after baseline. For the purposes of this example, the model is treated as a black box whose input are the 10 features, and the output a real number.</p> <table> <thead> <tr> <th>Age</th> <th>Sex</th> <th>BMI</th> <th>Blood pressure</th> <th>…</th> <th>Target</th> </tr> </thead> <tbody> <tr> <td>0.0380759</td> <td>0.0506801</td> <td>0.0616962</td> <td>0.0218724</td> <td>…</td> <td>151</td> </tr> <tr> <td>-0.00188202</td> <td>-0.0446416</td> <td>-0.0514741</td> <td>-0.0263275</td> <td>…</td> <td>75</td> </tr> <tr> <td>0.0852989</td> <td>0.0506801</td> <td>0.0444512</td> <td>-0.00567042</td> <td>…</td> <td>141</td> </tr> <tr> <td>…</td> <td>…</td> <td>…</td> <td>…</td> <td>…</td> <td>…</td> </tr> </tbody> </table> <blockquote> <p>SHAP values can be computed on the dataset used to train the model (train set) or on a holdout set. Using a larger dataset like the train set might provide a more stable picture of overall feature contributions learned by the model. However, if the train and test data come from different distributions, computing SHAP on the respective sets will likely yield different results.</p> </blockquote> <details><summary>The <code class="language-plaintext highlighter-rouge">shap</code> package</summary> <p>SHAP values are implemented in Python via the <a href="https://shap.readthedocs.io/en/latest/index.html"><code class="language-plaintext highlighter-rouge">shap</code></a> package. While I won’t be showing any code here, you can see the code that generated the figures <a href="/assets/python/2025-04-01-shapley/main.py">here</a>.</p> </details> <p>SHAP values provide <strong>local</strong> explanations, showing the contribution of each feature to a particular prediction. I computed the SHAP values describing the importance of each of the 10 variables for each of the 442 patients. These values represent the estimated impact of each feature on a prediction, relative to the average prediction. We can start by looking at the SHAP values for one patient, using a <em>waterfall</em> plot:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-04-01-shapley/img/waterfall_diabetes.webp" sizes="95vw"/> <img src="/assets/python/2025-04-01-shapley/img/waterfall_diabetes.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The waterfall plot shows how the prediction for this patient (186.53) departs from the average prediction over the training set (152.132). The difference (34.398) is the total change attributed by the model. As per the local accuracy property, the SHAP values for this instance sum up to this difference. The features are sorted by the absolute magnitude of their SHAP value. Features colored in pink push the prediction toward higher values, and features in blue toward lower values. We can see that, for this patient, the body mass index was the most important feature, contributing positively by 22.25.</p> <p>We can visualize SHAP values for all 442 patients using a <em>swarmplot</em>:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-04-01-shapley/img/beeswarm_diabetes.webp" sizes="95vw"/> <img src="/assets/python/2025-04-01-shapley/img/beeswarm_diabetes.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the swarmplot, each point represents the SHAP value for a patient for a specific feature. Features are shown on the y-axis, and their corresponding SHAP values on the x-axis. As in the waterfall plot, features are sorted by their overall importance; and the color of each point indicates the feature value for that patient (pink for high, blue for low).</p> <p>Global explanations can be derived by aggregating the local SHAP values over a dataset. A common global measure is the average absolute SHAP value for each feature:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-04-01-shapley/img/global_diabetes.webp" sizes="95vw"/> <img src="/assets/python/2025-04-01-shapley/img/global_diabetes.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Plotting these averages shows which features have the largest impact on the model’s predictions <em>on average</em> across the dataset, providing a global measure of feature importance.</p> <p>Lastly, SHAP values can be used for clustering. While traditional clustering groups data points based on their original feature values, clustering in SHAP space groups points based on how features <em>contribute to the model’s prediction</em>. This can be seen as a form of <em>supervised</em> clustering, as it leverages the model’s output (and indirectly the outcome it was trained on). Clustering SHAP values can reveal groups of instances where different sets of features drive the prediction.</p> <style>.colored-slider{--divider-color:rgba(0,0,0,0.5);--default-handle-color:rgba(0,0,0,0.5);--default-handle-width:clamp(40px,10vw,200px)}</style> <img-comparison-slider class="colored-slider"> <figure slot="first"> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-04-01-shapley/img/supervised_pca.webp" sizes="95vw"/> <img src="/assets/python/2025-04-01-shapley/img/supervised_pca.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure slot="second"> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-04-01-shapley/img/unsupervised_pca.webp" sizes="95vw"/> <img src="/assets/python/2025-04-01-shapley/img/unsupervised_pca.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </img-comparison-slider> <p>Applying PCA to the SHAP values (“supervised PCA”) and the original features (“unsupervised PCA”) for this dataset, we can visualize how instances are grouped.</p> <h1 id="limitations">Limitations</h1> <p>One key limitation of interpreting SHAP values is their behavior with <strong>highly correlated features</strong>. When features are strongly correlated, the model might arbitrarily use one over the others, or distribute importance among them. Consequently, the SHAP values for individual correlated features can become unstable or misleading, making it hard to disentangle their individual contributions.</p> <p>Another point of consideration is <strong>feature interactions</strong>. While the fundamental Shapley value calculation inherently accounts for interactions (by averaging marginal contributions over different coalitions), the basic additive SHAP explanation model \(g(\mathbf{x}') = \phi_0 + \sum \phi_j \mathbf{x}'_j\) does not explicitly separate main effects from interaction effects. The \(\phi_j\) values represent the <em>average</em> contribution of feature \(j\), including its interactive effects, making their interpretation as pure “main effects” challenging when interactions are significant. However, SHAP <a href="https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/tree_based_models/Basic%20SHAP%20Interaction%20Value%20Example%20in%20XGBoost.html"><em>can</em> be extended</a> to compute pairwise SHAP interaction values (\(\phi_{ij}\)) which explicitly quantify the interaction between features \(i\) and \(j\).</p> <p>Finally, it’s important to remember that SHAP values explain <em>how the model makes a prediction</em>, not whether the prediction itself is correct. If the model is biased, overfit, or simply wrong for a given instance, the SHAP values will faithfully explain the mechanism behind that incorrect prediction. Measures like permutation feature importance, which rely on model performance metrics after feature perturbation, inherently account for the model’s correctness in their explanation.</p> <h1 id="flavors-of-shap-the-permutation-approximation">Flavors of SHAP: the permutation approximation</h1> <p><a href="#shap-values">Above</a> I described the general approach to compute SHAP values. Unfortunately, it is very computationally intensive: exploring all possible coalitions is equivalent to exploring all \(2^m\) subsets of features. For that reason, different flavors of SHAP values have been proposed to make computations more efficient. I describe below the <strong>permutation approximation</strong>, a model-agnostic method to compute SHAP values \(\phi_i\). However, there are others specialized in specific model types, like <a href="https://shap.readthedocs.io/en/latest/generated/shap.TreeExplainer.html">Tree SHAP</a> for tree-based models (e.g., random forests, gradient boosting) and <a href="https://shap.readthedocs.io/en/latest/generated/shap.DeepExplainer.html">Deep SHAP</a> for deep learning models.</p> <p>The permutation approximation approximates SHAP values by estimating the expected marginal contribution of each feature over many random permutations of the features. Let’s study the permutation approximation through a worked out example. We aim to explain a prediction \(f(\mathbf{x}_0)\). We have at our disposal a background dataset \(X_\text{bg}\), e.g., the whole training set, which we will use for sampling. For the sake of the example, our model only considers four (simplified) features: \(\mathbf{x}_0 = [x_{\text{age}}, x_\text{sex}, x_\text{BMI}, x_\text{BP}]\).</p> <p>For each feature \(i\) that we want to explain:</p> <ol> <li>Initializing a list to store the marginal contribution of each feature. In this example, I will focus on the contribution of the first feature, \(x_\text{age}\), so I will call this list just \(\text{list}_\text{age}\).</li> <li>For \(K\) iterations: <ol> <li>A random ordering of the features is produced, e.g., \((\text{BP}, \text{age}, \text{BMI}, \text{sex})\), and a random sample \(\mathbf{z}\) is sampled from the background dataset \(X_\text{bg}\).</li> <li>Create two synthetic examples: - \(\mathbf{x}_1 = (x_\text{BP}, x_\text{age}, z_\text{BMI}, z_\text{sex})\) - \(\mathbf{x}_2 = (x_\text{BP}, z_\text{age}, z_\text{BMI}, z_\text{sex})\) Note that the only difference between the two examples is the value of the age feature.</li> <li>Compute the marginal contribution of the age feature as \(\delta = f(\mathbf{x}_1) - f(\mathbf{x}_2)\).</li> <li>Append the marginal contribution to \(\text{list}_\text{age}\).</li> </ol> </li> <li>Approximate the SHAP value as the average marginal contribution: \(\phi_\text{age} \cong \frac{1}{K} \sum_i \delta_{i}.\)</li> </ol> <h1 id="further-reading">Further reading</h1> <ul> <li><a href="https://christophm.github.io/interpretable-ml-book/shapley.html">Interpretable Machine Learning: Shapley values</a></li> <li><a href="https://christophm.github.io/interpretable-ml-book/shap.html">Interpretable Machine Learning: SHAP</a></li> <li><a href="https://shap.readthedocs.io">Python’s <code class="language-plaintext highlighter-rouge">shap</code> documentation</a></li> <li><a href="https://www.aidancooper.co.uk/supervised-clustering-shap-values/">Supervised Clustering: How to Use SHAP Values for Better Cluster Analysis</a></li> <li><a href="https://davidrosenberg.github.io/ttml2021fall/interpretable-ml/5.Shapley-LIME-SHAP.pdf">Shapley Values, LIME, and SHAP</a></li> </ul>]]></content><author><name></name></author><category term="feature_selection"/><category term="machine_learning"/><category term="feature_importance"/><summary type="html"><![CDATA[A model-agnostic framework for explaining predictions]]></summary></entry><entry><title type="html">Knockoffs</title><link href="https://hclimente.github.io/blog/kernel-knockoffs/" rel="alternate" type="text/html" title="Knockoffs"/><published>2025-02-18T12:00:00+00:00</published><updated>2025-02-18T12:00:00+00:00</updated><id>https://hclimente.github.io/blog/kernel-knockoffs</id><content type="html" xml:base="https://hclimente.github.io/blog/kernel-knockoffs/"><![CDATA[<p>In many scientific applications, the goal is to discover which features are truly associated with an outcome. The <a href="https://en.wikipedia.org/wiki/False_discovery_rate">false discovery rate</a> (FDR) is defined as the expected proportion of false positives among the selected features. Controlling the FDR is less conservative than controlling the <a href="https://en.wikipedia.org/wiki/Family-wise_error_rate">family-wise error rate</a>, often leading to more discoveries.</p> <p>When dealing with statistical tests, Benjamini–Hochberg and Benjamini–Yekutieli are common procedures to keep the FDR below a level \(\alpha\). However, such strategies rely on certain assumptions; for instance, that P-values are well-calibrated or that tests have certain correlation structures. If these are not met, the statistical guarantees on FDR control are also out the window. Furthermore, they require having P-values to work with; in many cases we just want to control the FDR of selected features, but do not have a well-characterized null hypothesis. For instance, given a set of active features in Lasso, how can we make sure the fraction of non-explanatory features is controlled? In such cases, <em>knockoffs</em> can be helpful.</p> <h1 id="knockoffs">Knockoffs</h1> <p>The <strong>knockoff</strong> filter is a procedure to perform feature selection while keeping the FDR controlled. Given an outcome \(\mathbf{Y}\) and a feature matrix \(X\), the goal is to select a subset of features \(X_S\) such that</p> \[Y \perp X_{-S} \mid X_S\] <p>The procedure computes and leverages a new matrix \(\tilde{X}\), with the same dimensions as \(X\), containing “knockoff” copies of the original features. Each original variable \(\mathbf{X_i}\) has its own knockoff \(\mathbf{\tilde{X}_i}\). These knockoffs are engineered to mimic the correlation structure of the original features: for any \(i \neq j\), \(\rho(\mathbf{X_i}, \mathbf{X_j}) = \rho(\mathbf{X_i}, \mathbf{\tilde{X}_j}) = \rho(\mathbf{\tilde{X}_i}, \mathbf{\tilde{X}_j})\). Also, knockoffs are created without using \(\mathbf{Y}\). Hence, conditional on \(X\), \(Y\) is independent of \(\tilde{X}\).</p> <p>There are two paradigms to model knockoffs: Model-X and Fixed-X.</p> <p>The <strong>Model-X</strong> paradigm assumes that the explanatory variables are random variables with a known joint distribution. Although theoretically appealing, this assumption can be impractical for real-world data, since we do not know the data generating function \(F_X\). For that reason, I will ignore it for the remainder of this discussion.</p> <p>The <strong>Fixed-X</strong> paradigm makes no assumptions on the distribution of the explanatory variables. Instead, they can be treated as fixed quantities. This makes it more applicable in practice. However, it imposes three important restrictions:</p> <ul> <li>\(F_{Y \mid X}\) must be linear and homoscedastic</li> <li>The problem must be low dimensional (number of samples \(&gt;\) number of features)</li> <li>The statistics \(D(X_i, Y)\) and \(D(\tilde{X}_i, Y)\) must satisfy additional requirements (see references)</li> </ul> <h1 id="the-knockoff-procedure">The knockoff procedure</h1> <p>Intuitively, by comparing the association measure computed for each original feature against its knockoff, one can determine which features provide true signals. Specifically, the knockoff-based feature selection consists of four steps.</p> <h2 id="1-generate-knockoffs">1. Generate knockoffs</h2> <p>Create synthetic copies of the features that retain the original correlation structure without any outcome information. An obvious question is how to synthesize such knockoff copies.</p> <h2 id="2-compute-association-measures">2. Compute association measures</h2> <p>For each feature, calculate the association measure \(D(\mathbf{Y}, \mathbf{X_k})\) and its counterpart \(D(\mathbf{Y}, \tilde{\mathbf{X}}_k)\) on the knockoff.</p> <p>Kernel-based measures are powerful tools for detecting complex, non-linear dependencies:</p> <ul> <li><strong>HSIC (Hilbert-Schmidt Independence Criterion):</strong> Computes the covariance between kernel-transformed versions of the feature and the outcome, capturing a broad range of dependency structures.</li> <li><strong>Conditional MMD (cMMD):</strong> Assesses the difference between the conditional distribution of a feature given the outcome and its marginal distribution. This measure is particularly useful when dealing with categorical outcomes.</li> <li><strong>TR Measure:</strong> A linear combination of Kendall’s τ and Spearman’s ρ, designed to effectively capture associations in both continuous and discrete data.</li> </ul> <p>These measures satisfy the sure independence screening property under bounded kernel conditions—meaning that, with high probability, the truly active features are recovered when a proper threshold is used.</p> <blockquote> <p>A potential limitation of kernel knockoffs is its sometimes overly conservative nature. To keep the FDR low, the procedure may end up selecting very few—or even no—features. This suggests that the chosen association measure might not be sufficiently sensitive. One possible remedy is to explore alternative kernel choices or optimize feature screening steps before applying knockoff filtering.</p> </blockquote> <h2 id="3-compute-the-knockoff-statistic">3. Compute the knockoff statistic</h2> <p>Define the statistic as \(w_k = D(Y, X_k) - D(Y, \tilde{X}_k)\). A larger \(w_k\) indicates stronger evidence that the original feature is associated with the outcome.</p> <h2 id="4-select-a-threshold-and-select-features">4. Select a threshold and select features</h2> <p>Identify the smallest threshold \(t\) such that \(\frac{\#\{w_k \le -t\}}{\#\{w_k \ge t\}} \le \alpha\) where \(\alpha\) is the desired FDR level. Retain all features with \(w_k \ge t\).</p> <h1 id="screening-in-high-dimensions">Screening in High Dimensions</h1> <p>A notable challenge arises when the number of features \(p\) is large compared to the sample size \(n\) (i.e., \(2p&gt;n\)). In such high-dimensional settings, constructing knockoffs directly is infeasible. A common workaround is to:</p> <ul> <li>Pre-screen Features: Use a subset of the data to rank and reduce the feature set.</li> <li>Apply the knockoff filter: With the reduced set of features, generate knockoffs using the remaining samples (ensuring \(m &gt; 2d\), where \(d\) is the number of features after screening).</li> </ul> <p>This two-step approach helps maintain statistical power while ensuring robust FDR control.</p> <h1 id="references">References</h1> <ul> <li><a href="https://web.stanford.edu/group/candes/knockoffs/">Variable Selection with Knockoffs</a></li> <li><a href="https://proceedings.mlr.press/v151/poignard22a.html">B. Poignard, P. J. Naylor, H. Climente-González, M. Yamada, in International Conference on Artificial Intelligence and Statistics (PMLR, 2022), pp. 1935–1974.</a></li> </ul>]]></content><author><name></name></author><category term="fdr"/><category term="knockoffs"/><category term="feature_selection"/><summary type="html"><![CDATA[FDR-controlled feature selection]]></summary></entry><entry><title type="html">Random walks and Markov chains</title><link href="https://hclimente.github.io/blog/graphs-random-walks/" rel="alternate" type="text/html" title="Random walks and Markov chains"/><published>2025-01-27T11:59:00+00:00</published><updated>2025-01-27T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/graphs-random-walks</id><content type="html" xml:base="https://hclimente.github.io/blog/graphs-random-walks/"><![CDATA[<h1 id="random-walk">Random walk</h1> <p>A <strong>random walk (RW)</strong> is a <a href="https://en.wikipedia.org/wiki/Stochastic_process">stochastic</a>, discrete process. At every time step a walker, located in one of the graph’s vertices, picks one of its neighbors at random and moves to it. Often the transition probability between vertices is represented by the <strong>transition</strong> matrix \(P\), a normalized version of the <a href="/blog/graphs-linear-algebra/#adjacency-matrix">adjacency</a> in which the weights of all outbound edges add up to 1:</p> \[P = D^{-1} A\] <p>Note that \(P\) corresponds to a <a href="#markov-chains">row stochastic matrix</a>. The outcome of a single random walk is a <a href="/blog/graphs-glossary/#walk">walk</a> of length \(t\), where \(t\) is the number of steps. Let’s see how a random walk starting at vertex \(i\) plays out:</p> <ul> <li>At step 0, \(\mathbf{\pi}_0 = (0, 0, \cdots, 1, \cdots, 0)\). That is, \(\pi_0\) is an \(n\)-dimensional row vector that is \(0\) almost everywhere, with a \(1\) at component \(i\).</li> <li>At step 1, \(\mathbf{\pi}_{1} = \mathbf{\pi}_0 P\)</li> <li>At step 2, \(\mathbf{\pi}_{2} = \mathbf{\pi}_1 P = (\mathbf{\pi}_0 P) P = \mathbf{\pi}_0 P^2\)</li> <li>At step 3, \(\mathbf{\pi}_{3} = \mathbf{\pi}_2 P = (\mathbf{\pi}_0 P^2) P = \mathbf{\pi}_0 P^3\)</li> <li>…</li> <li>At step \(t\), \(\mathbf{\pi}_{t} = \mathbf{\pi}_0 P^t\)</li> </ul> <p>\(\pi_t\) is an \(n\)-dimensional row vector \(\mathbf{\pi}_t\) in which \(\pi_{tj}\) represents the probability of the walker starting at vertex \(i\) and being on vertex $j$ at time $t$.</p> <p>We might be interested in what happens if we let the random walk run indefinitely:</p> \[\lim_{t \to \infty} \mathbf{\pi}_{t} = \mathbf{\pi}_0 P^t\] <p>When taking powers of a matrix, it is useful to use its <a href="https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix">eigendecomposition</a>. After computing the eigenvectors (\(\mathbf{u}_1, \cdots, \mathbf{u}_n\)) and the eigenvalues (\(\lambda_1, \cdots, \lambda_n\)) of \(P\), we first expand \(\mathbf{\pi}_0\) in the eigenbasis:</p> \[\mathbf{\pi}_0 = c_1 \mathbf{u}_1 + c_2 \mathbf{u}_2 + \cdots + c_n \mathbf{u}_n\] <p>Then, for an arbitrary step \(t\):</p> \[\begin{multline*} \mathbf{\pi}_{t} = \mathbf{\pi}_0 P^t \\ = (c_1 \mathbf{u}_1 + \cdots + c_n \mathbf{u}_n) P^t \\ = c_1 \mathbf{u}_1 P^t + \cdots + c_n \mathbf{u}_n P^t \\ = c_1 \lambda^t_1 \mathbf{u}_1 + \cdots + c_n \lambda^t_n \mathbf{u}_n \end{multline*}\] <p>The eigenvalues of a stochastic matrix are always less than or equal to 1 in absolute value. When the random walk is <em>ergodic</em> (see below), \(P\) has an eigenvalue of 1 with an eigenvector \(\pi\) such that:</p> \[\pi_i = \frac {d_i} {\sum_j d_j}.\] <details><summary>Proof</summary> <p>The degree row-vector \(\mathbf{d} = ({d_1}, \cdots, d_n )\) is a left eigenvector of \(P\):</p> \[\mathbf{d} P = \mathbf{d} D^{-1} A = \mathbf{1} A = \mathbf{d}\] <p>where \(\mathbf{1}\) represents the row vector of all ones. That is, \(\mathbf{d}\) is an eigenvector with eigenvalue 1 and non-negative entries. In order to transform it into a valid probability distribution, we need to make sure that \(\sum_i \pi_i = 1\):</p> \[\pi = \frac 1 {\sum_i d_i} \mathbf{d}\] </details> <p>This is the stationary distribution of the random walk. It formalizes the intuitive result that high <a href="/blog/graph-properties/#degree">degree</a> vertices are more likely to be visited. If the graph is <a href="/blog/graphs-glossary/#regular">regular</a>, the stationary distribution is uniform. Note that this is a property of the matrix, and not of \(\pi_0\). This implies that the starting vertex is not important in the long run: if the random walk is allowed to run indefinitely, the probability of ending up in each vertex will converge to \(\pi\).</p> <blockquote> <p><strong>Ergodicity and <em>lazy</em> random walks:</strong> A unique stationary distribution does not always exists. A random walk is <em>ergodic</em> if a stationary distribution exists and is the same for any \(\pi_0\). For the random walk to be ergodic, the graph needs to be connected and non <a href="/blog/graphs-glossary/#bipartite-graph">bipartite</a>. If the graph has multiple components, starting in different components will produce different stationary distributions. If the graph is bipartite, at step \(t\) the walker will be on one side or another, depending on the initial vertex and the parity of \(t\). Bipartite graphs have a ergodic <a href="https://people.orie.cornell.edu/dpw/orie6334/Fall2016/lecture11.pdf"><em>lazy</em> random walk</a>, in which the walker has a probability \(\frac 1 2\) of remaining at the current vertex and a probability \(\frac 1 2\) of leaving it.</p> </blockquote> <details><summary>Connection to the Laplacian</summary> <p>The <a href="/blog/graphs-linear-algebra/#normalized-laplacian-matrices">Laplacian</a> and the transition matrices are deeply related:</p> \[L_{rw} = D^{-1}L = D^{-1}(D - A) = I - P\] <p>In fact, their eigenvectors and eigenvalues are connected. If \(\mathbf{u}\) is an eigenvector of \(P\), with eigenvalue \(\lambda\):</p> \[\mathbf{u} L_{rw} = \mathbf{u} (I - P) = \mathbf{u} - \mathbf{u} P = (1 - \lambda) \mathbf{u}\] <p>That is, \(P\) and \(L_{rw}\) have the same eigenvectors, and the eigenvalues are related as \(\lambda_i(L_{rw}) = 1 - \lambda_i(P)\). Since the <a href="/blog/graphs-linear-algebra/#connectivity-of-the-graph">smallest eigenvalue of \(L_{rw}\)</a> is 0, corresponding to the eigenvector \(\mathbf{1}\), \(P\) has an eigenvalue of \(1\) corresponding to that same eigenvector.</p> </details> <p>There are several remarks we can do:</p> <ul> <li>This result holds regardless of what the starting vertex is. In fact, \(\pi_0\) could be a probability distribution over the vertices.</li> <li>The <em>speed</em> at which the distribution converges depends on the eigenvalues of \(P\). Specifically, if \(\lambda_2\) is close to 1, the convergence will be slow.</li> </ul> <h1 id="random-walk-with-restart">Random walk with restart</h1> <p>In the <strong>random walk with restart (RWR)</strong>, the walker can return to its root vertex with a restart probability \(r \in [0, 1]\):</p> \[\mathbf{\pi}_{t+1} = r \mathbf{\pi}_0 + (1 - r) P \mathbf{\pi}_t\] <p>where \(\mathbf{\pi}_0\) represents the probability of starting at each vertex. If \(r = 0\), the walker will never be teleported back to the root, and a RW is equivalent to a RWR. If \(r = 1\), the walker will not be allowed to move out of the root, and \(\mathbf{\pi}_t = \mathbf{\pi}_0\). However, for certain values of $r$, the walker is allowed to explore the root’s neighborhood before teleporting back. If the root is part of a <a href="/blog/graphs-glossary/#module">module</a>, the walk will mostly happen within that module. If the root is very central, the walker will explore many parts of the network.</p> <p>Importantly, the RWR also has a stationary distribution \(\pi\):</p> \[\lim_{t \to \infty} \mathbf{\pi}_{t} = \pi\] <h1 id="markov-chains">Markov chains</h1> <p>A <strong>Markov chain</strong> is a sequence of events in which the probability of each event only depends on the state attained in the previous event. A random walk is a Markov chain: the probability of visiting a vertex depends only on the current vertex’s neighbors and the corresponding transition probabilities. We can describe some of the properties of a Markov chain by describing the underlying graph:</p> <ul> <li><em>Time reversibility</em></li> <li><em>Symmetry</em>: a Markov chain is symmetric when the underlying graph is <a href="/blog/graphs-glossary/#regular">regular</a>.</li> </ul> <p>In the context of Markov chains, the transition matrix \(P\) is known as the <strong>right stochastic matrix</strong>.</p> <details><summary>Types of stochastic matrices</summary> <ul> <li><strong><em>Row/right</em> stochastic matrix</strong>: square matrix with non-negative entries where each row sums to \(1\).</li> <li><strong><em>Column/left</em> stochastic matrix</strong>: square matrix with non-negative entries where each column sums to \(1\).</li> <li><strong><em>Doubly</em> stochastic matrix</strong>: square matrix with non-negative entries where each row and column sum to \(1\).</li> </ul> </details> <h1 id="further-reading">Further reading</h1> <ul> <li><a href="https://www.youtube.com/watch?v=8XJes6XFjxM">Full title: The Unreasonable Effectiveness of Spectral Graph Theory: A Confluence of Algorithms, Geometry, and Physics</a></li> </ul>]]></content><author><name></name></author><category term="graphs"/><category term="random_walks"/><category term="linear_algebra"/><summary type="html"><![CDATA[PageRank, MCMC, and others]]></summary></entry><entry><title type="html">Graphs and Linear Algebra</title><link href="https://hclimente.github.io/blog/graphs-linear-algebra/" rel="alternate" type="text/html" title="Graphs and Linear Algebra"/><published>2025-01-25T11:59:00+00:00</published><updated>2025-01-25T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/graphs-linear-algebra</id><content type="html" xml:base="https://hclimente.github.io/blog/graphs-linear-algebra/"><![CDATA[<p>In this article I discuss matrices associated to graphs. As we will see, a graph can be represented as a matrix without any information loss. Hence, the properties of these matrices describe <a href="/blog/graphs-basics/#properties-of-a-graph">properties of the underlying graph</a>.</p> <h1 id="matrices-associated-to-graphs">Matrices associated to graphs</h1> <p>A graph \(G = (V, E)\) s.t. \(V = \{v_1, \dots, v_n\}\) and \(E = \{e_1, \dots, e_m \}\) has several important associated matrices. For convenience, I often refer to vertex \(v_i\) simply by its index (\(i\)), and to an edge by the vertices it links (e.g., \(ij\)).</p> <p>I will show examples on the following graph, named \(G_1\):</p> <pre><code class="language-mermaid">---
config:
  layout: elk
  look: handDrawn
---
graph LR
    vertex_1((1))
    vertex_2((2))
    vertex_3((3))
    vertex_4((4))

    vertex_1 === vertex_2
    vertex_1 === vertex_3
    vertex_1 === vertex_4
    vertex_2 === vertex_3
</code></pre> <h2 id="degree-matrix">Degree matrix</h2> <p><a href="/blog/graphs-basics/#degree">Vertex degree</a> is ised to define the <strong>degree</strong> matrix \(D\) is a diagonal \(n \times n\) matrix such that \(D_{ii} = \deg i\), and 0 elsewhere. For instance, for \(G_1\):</p> \[\text{D}(G_1) = \begin{bmatrix} 3 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 2 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \\ \end{bmatrix}\] <h2 id="incidence-matrix">Incidence matrix</h2> <p><a href="/blog/graphs-glossary/#incidence">Incidence</a> is used to define the <strong>incidence</strong> matrix \(Q\), a \(n \times m\) matrix such that \(Q_{ij}\) equals:</p> <ul> <li>If \(G\) is <em>directed</em>: <ul> <li>\(0\) if vertex \(i\) and edge \(e_j\) are not incident</li> <li>\(1\) if edge \(e_j\) originates at vertex \(i\)</li> <li>\(-1\) if edge \(e_j\) terminates at vertex \(i\)</li> </ul> </li> <li>If \(G\) is <em>undirected</em>: <ul> <li>If \(Q\) is <em>unoriented</em>: <ul> <li>\(0\) if vertex \(i\) and edge \(e_j\) are not incident</li> <li>\(1\) otherwise</li> </ul> </li> <li>If \(Q\) is <em>oriented</em>: we pick an <a href="/blog/graphs-glossary/#orientation">orientation</a> of the graph, and use the incidence matrix of the resulting directed graph.</li> </ul> </li> </ul> <h2 id="adjacency-matrix">Adjacency matrix</h2> <p><a href="/blog/graphs-glossary/#adjacency">Adjacency</a> is used to define the <strong>adjacency</strong> matrix \(A\), a matrix \(n \times n\) such that the \(A_{ij}\) equals:</p> <ul> <li>\(0\) if vertices \(i\) and \(j\) are not adjacent (note that in simple graphs vertices are not self-adjacent)</li> <li>\(1\) otherwise</li> </ul> <p>For \(G_1\):</p> \[A = \begin{bmatrix} 0 &amp; 1 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1 &amp; 0 \\ 1 &amp; 1 &amp; 0 &amp; 0 \\ 1 &amp; 0 &amp; 0 &amp; 0 \\ \end{bmatrix}\] <p>The adjacency matrix relates to the concept of <a href="/blog/graphs-glossary/#path">paths</a> in an unweighted graph: \((A^k)_{ij}\) represents the number of paths of length \(k\) from vertex \(i\) to vertex \(j\). In a weighted graph, it represents the sum of products of weights. For instance, if edge weights represent transition probabilities, \((A^k)_{ij}\) represents the probability of starting a <a href="/blog/graphs-random-walks/">walk</a> at node \(i\) and ending at node \(j\) after \(k\) steps.</p> <h2 id="laplacian-matrix">Laplacian matrix</h2> <p>The <strong>Laplacian</strong> matrix \(L\) is a \(n \times n\) matrix such that the \(L_{ij}\) equals::</p> <ul> <li>For \(i \neq j\): <ul> <li>\(0\) if vertices \(i\) and \(j\) are not adjacent</li> <li>\(-1\) otherwise</li> </ul> </li> <li>For \(i = j\), the degree of \(i\).</li> </ul> <p>More concisely, \(L = D - A\). Or, given any oriented incidence matrix \(Q(G)\), \(L = QQ^T\).</p> <p>For \(G_1\):</p> \[L = D - A = \begin{bmatrix} 3 &amp; -1 &amp; -1 &amp; -1 \\ -1 &amp; 2 &amp; -1 &amp; 0 \\ -1 &amp; -1 &amp; 2 &amp; 0 \\ -1 &amp; 0 &amp; 0 &amp; 1 \\ \end{bmatrix}\] <p>The Laplacian relates to the connectedness of a graph, giving rise to <a href="#spectral-graph-theory">spectral graph theory</a>. It also is connected to <a href="/blog/graphs-glossary/#flow">flows</a>. The diagonal entries represent the total outflow capacity from a vertex, while off-diagonal entries encode pairwise connection strengths.</p> <h2 id="normalized-laplacian-matrices">Normalized Laplacian matrices</h2> <p>The presence of <a href="/blog/graphs-glossary/#hub">hubs</a> results in large diagonal entries in the Laplacian. There are normalized versions of the Laplacian that downweigh such vertices by dividing the entries by the vertex degree.</p> <p>The <strong>symmetrically</strong> normalized Laplacian \(L_\text{sym}\) is a symmetric matrix derived as follows:</p> \[L_\text{sym} = D^{-1/2}LD^{-1/2}\] <p>The <strong>random walk</strong> normalized Laplacian \(L_\text{rw}\) is a matrix closely related to <a href="/blog/graphs-random-walks/">random walks</a> that is derived as follows:</p> \[L_\text{rw} = D^{-1}L\] <h1 id="spectral-graph-theory">Spectral graph theory</h1> <p><strong>Spectral graph theory</strong> studies how the eigenvalues and eigenvectors of a graph’s associated matrices relate to its properties. Looking more closely at two of the matrices described above, we can see they have interesting properties:</p> <ul> <li>If \(G\) is undirected, \(A\) is both real and symmetric. Hence, it is diagonalizable and has only <em>real</em> values.</li> <li>Since for an undirected graph both \(D\) and \(A\) are symmetric, \(L\) is also real and symmetric. In fact, \(L\) is <strong>positive semi-definite</strong>. This implies that \(L\)’s eigenvalues are not only real, but also <em>non-negative</em>.</li> </ul> <p>Spectral graph theory often focuses on studying the eigenvalues of the Laplacian.</p> <h2 id="connectivity-of-the-graph">Connectivity of the graph</h2> <p>The eigenvectors of \(L\) are closely related to the connectivity of its associated graph.</p> <p>A simple, but ultimately insightful property of \(L\) is that, for an undirected graph, the sum over the rows or the columns equals 0. In other words, multiplying \(L\) by an all-ones vector \(\mathbf{1}\) results in the zero vector. This tells us that \(L\) has an eigenvalue of 0, corresponding to the eigenvector \(\mathbf{1}\). Separately, linear algebra tells us that since \(L\) is real and symmetric, it has <em>real</em> eigenvalues and <em>orthogonal</em> eigenvectors. And since \(L\) is positive semi-definite, its eigenvalues are <em>non-negative</em>. As we have just seen, the <a href="/blog/graphs-glossary/#first-k-eigenvectors">first eigenvalue</a>, \(\lambda_1\), of \(L\) is 0, corresponding to the \(\mathbf{1}\) eigenvector. If a vector has multiple <a href="/blog/graphs-glossary/#component">components</a>, \(L\) is block diagonal. This makes it easy to see that the indicator vectors, representing the membership of each vertex to one of the components, are eigenvectors with an eigenvalue of 0. This highlights another important property of the Laplacian: given an undirected graph, the multiplicity of the eigenvalue 0 of \(L\) equals the number of <a href="/blog/graphs-glossary/#component">components</a>. Conversely, for a <a href="/blog/graphs-glossary/#connected-graph">connected</a> graph, \(\lambda_2 &gt; 0\). (The second smallest eigenvalue is sometimes called the Fiedler eigenvalue.)</p> <p>More generally, less <em>smooth</em> eigenvectors (i.e., those in which consecutive elements change sharply) indicate a less connected. Equivalently, smaller eigenvalues correspond to smoother eigenvectors, and hence to better connected graphs.</p> <h2 id="spectral-clustering">Spectral clustering</h2> <p>The goal of <strong>spectral clustering</strong> is finding a partition of the graph into \(k\) groups such that the are densely/strongly connected with each other, and sparsely/weakly connected to the others. (If we consider <a href="/blog/graphs-random-walks/">random walks</a>, spectral clustering seeks a partition of the graph such that a random walker tends to stay within each partition, rarely shifting between disjoint sets.) An spectral clustering algorithm, in which seek to find <em>k</em> clusters, looks as follows:</p> <pre><code class="language-pseudocode">\begin{algorithm}
\caption{Spectral Clustering}
\begin{algorithmic}[1]
\PROCEDURE{GraphSpectralClustering}{$$A, k$$}
    \STATE $$n \gets \text{number of nodes (rows in A)}$$

    \STATE Compute degree matrix $$D$$ where $$D[i,i] = \sum_{j=1}^n A[i,j]$$
    \STATE $$D_{\text{sqrt-inv}} \gets \text{diag}(1/\sqrt{D[i,i]})$$
    \STATE $$L_{\text{sym}} \gets I - D_{\text{sqrt-inv}} A D_{\text{sqrt-inv}}$$ \COMMENT{Symmetric normalized Laplacian}

    \STATE Compute first $$k$$ eigenvectors $$u_1, \ldots, u_k$$ of $$L_{\text{sym}}$$
    \STATE Form matrix $$U \in \mathbb{R}^{n \times k}$$ with columns $$u_1, \ldots, u_k$$

    \FOR{$$i = 1$$ \TO $$n$$}
        \STATE $$U[i] \gets U[i] / \|U[i]\|$$ \COMMENT{Row normalization}
    \ENDFOR

    \STATE $$\text{labels} \gets \text{KMeans}(U, k)$$ \COMMENT{Cluster embedded nodes}
    \RETURN $$\text{labels}$$
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}
</code></pre> <blockquote> <p><strong>Note:</strong> spectral clustering is often applied as a clustering technique on datasets. The aim is to divide the observation into \(k\) groups based on their pairwise similarities. In that case, the first step consists on obtaining the graph. It will be a complete weighted graph in which the vertices are the different observations and the edges are weighted according to the similarity between each pair of vertices, as measured by an arbitrary function.</p> </blockquote> <h1 id="further-reading">Further reading</h1> <ul> <li><a href="https://people.csail.mit.edu/dsontag/courses/ml14/notes/Luxburg07_tutorial_spectral_clustering.pdf">A Tutorial on Spectral Clustering</a></li> <li><a href="https://mathweb.ucsd.edu/~fan/talks/mlg.pdf">Four graph partitioning algorithms</a></li> <li><a href="https://www.youtube.com/watch?v=uTUVhsxdGS8">Spectral Graph Theory For Dummies</a></li> <li><a href="https://www.youtube.com/watch?v=8XJes6XFjxM">Full title: The Unreasonable Effectiveness of Spectral Graph Theory: A Confluence of Algorithms, Geometry, and Physics</a></li> </ul>]]></content><author><name></name></author><category term="graphs"/><category term="linear_algebra"/><summary type="html"><![CDATA[Matrices associated to graphs and their properties]]></summary></entry><entry><title type="html">Properties of Graphs</title><link href="https://hclimente.github.io/blog/graph-properties/" rel="alternate" type="text/html" title="Properties of Graphs"/><published>2025-01-24T11:59:00+00:00</published><updated>2025-01-24T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/graph-properties</id><content type="html" xml:base="https://hclimente.github.io/blog/graph-properties/"><![CDATA[<p>At the most fundamental level, graphs are just entities and connections between them. Yet, the network topology gives rise to emergent properties. For instance, how information flows through a social network is partly a function who posts the message and how they are connected to the rest of the network, with their immediate connections being likely more important. In this section, I review three levels at which networks operate: <a href="#local-properties">local</a>, <a href="#mesoscale-properties">mesoscale</a> and <a href="#global-properties">global</a>. They refer, respectively, to properties of the nodes, properties of parts of the network and properties of the whole network.</p> <h1 id="local-properties">Local properties</h1> <h2 id="degree">Degree</h2> <p>In an undirected network, the <strong>degree</strong> of a vertex \(u\) (\(\deg u\)) refers to the number of edges that are incident on \(u\). In a directed network, this concept is split between <em>indegree</em> ([\(\deg^- u\)], the number of edges that have \(u\) as their destination) and <em>outdegree</em> ([\(\deg^+ u\)], number of edges that have \(u\) as their source). Weighted graphs extend this concept to <em>weighted</em> degree, in which \(\deg u = \sum_{i} w(e_{ui})\).</p> <h2 id="local-clustering-coefficient">Local clustering coefficient</h2> <p>The <strong>(local) clustering coefficient</strong> <em>of a vertex</em> measures the probability that its <a href="/blog/graphs-glossary/#neighborhood">neighbors</a> are connected. It is computed as the ratio between number of <a href="/blog/graphs-glossary/#triangle-graph">triangles</a> involving a vertex, and the number of <a href="/blog/graphs-glossary/#triplet">triplets</a> involving that same vertex.</p> <p><a href="https://r.igraph.org/reference/transitivity.html">Often</a>, the clustering coefficient of a directed graph is computed without considering the direction of the edges.</p> <h1 id="mesoscale-properties">Mesoscale properties</h1> <h2 id="modularity">Modularity</h2> <p>The <strong>modularity</strong> measures how well a graph can be divided into <a href="/blog/graphs-glossary/#modules">modules</a>. Given a partition of a graph into \(k\) modules, the modularity \(Q\) is computed as</p> \[Q = \sum_{i=1}^k (e_{ii} - {a_i^2})\] <p>where \(e_{ii} = \frac {\| \{\{u, v\} \mid u \in V_i, v \in V_i, \{u, v\} \in E \} \|} {\|E\|}\),\(a*i = \frac {\| \{\{u, v\} \mid u \in V_i, \{u, v\} \in E \} \|} {\|E\|}\) and \(V_i\) is the set of vertices in module \(i\). \(e*{ii}\) is the fraction of edges within module \(i\) and \(a_i\) is the fraction of edges incident with one vertex in module \(i\). \(Q\) will be large when the fraction of edges within the module is much larger than expected by chance.</p> <h2 id="within-module-degree">Within-module degree</h2> <p>The <strong>within-module degree</strong> of a vertex is the module version of the <a href="#degree">degree</a>. It is often normalized as a z-score; the z-score for node \(i\), mapped to module \(k\):</p> \[Z_i = \frac {\kappa_i - \bar \kappa_k} {\sigma_{\kappa_k}}\] <p>where \(\kappa_i\) is within-module degree (the number of edges between \(i\) and other vertices in module \(k\)); \(\bar \kappa_k\) is the average within-module degree; and \(\sigma_{\kappa_k}\) is the standard deviation of the within module degrees.</p> <h1 id="global-properties">Global properties</h1> <h2 id="radius-and-diameter">Radius and diameter</h2> <p>The radius and the diameter measure how easy it is to traverse a graph. They both are quantities based on the maximum <a href="/blog/graphs-glossary/#distance">distance</a> between any two vertices found in the graph. Specifically, the <strong>radius</strong> is the minimum maximum distance; the <strong>diameter</strong> is the maximum distance.</p> <h2 id="global-clustering-coefficient">Global clustering coefficient</h2> <p>The <strong>global clustering coefficient</strong> <em>of a graph</em> is the ratio between closed and open <a href="/blog/graphs-glossary/#triplet">triplets</a> in that graph. Or, equivalently:</p> \[C = \frac {3 \times \text{triangles}} {\text{triplets}}\] <p><a href="https://r.igraph.org/reference/transitivity.html">Often</a>, the clustering coefficient of a directed graph is computed without considering the direction of the edges.</p> <h2 id="centrality">Centrality</h2> <p><strong>Centrality</strong> assigns a score or a ranking to every vertex in the graph, which represents its importance in the network according to some metric. <a href="#degree">Degree</a> and <a href="#participation">participation</a> are examples of such metrics, but there are others.</p> <h1 id="types-of-graphs">Types of graphs</h1> <p>We can clasify graphs into different types by using the <a href="#global-properties">global properties</a> of their nodes.</p> <h2 id="regular-graphs">Regular graphs</h2> <p><strong>Regular</strong> graphs are those in which every node has the same degree. They have a high average <a href="#local-clustering-coefficient">clustering coefficient</a> and a large <a href="#radius-and-diameter">diameter</a>.</p> <h2 id="small-world-graphs">Small world graphs</h2> <p>Small world graphs have a high average <a href="#local-clustering-coefficient">clustering coefficient</a> and a small <a href="#radius-and-diameter">diameter</a>. They are called small world because, despite their size, the average distance between any two nodes is small. This is often summarized as <a href="https://en.wikipedia.org/wiki/Six_degrees_of_separation">“six degrees of separation”</a>, the idea that any two people on Earth are connected by at most six social connections. This is because many real-world networks, like social networks, protein interaction networks, and neural networks, exhibit small-world properties.</p> <details><summary>Milgram’s small-world experiment</summary> <p><a href="https://en.wikipedia.org/wiki/Stanley_Milgram">Milgram</a> <em>et al.</em> conducted experiments that were key to understand the topology of social graphs.</p> <p>They gave letters to randomly chosen people from Nebraska and Kansas, each of which was to reach a target random person from Massachusetts. To that end, they could only give it to their friend or relative they thought was most likely to know the target. These, in turn, were meant to do the same; and so on, until eventually the letter would reach the target. The majority of letters never reached their target; but those who did, made it in 5 to 6 hops.</p> <p>This ultimately lead to the postulation of the six degrees of separation, and the realization that social graphs are small world graphs.</p> </details> <h1 id="further-reading">Further reading</h1> <ul> <li><a href="https://chih-ling-hsu.github.io/tags/#Graph">Chihling’s series on graphs</a></li> </ul>]]></content><author><name></name></author><category term="graphs"/><summary type="html"><![CDATA[Multiscale ways to talk about graphs]]></summary></entry></feed>