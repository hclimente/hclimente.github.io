<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://hclimente.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://hclimente.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-07-16T20:48:20+00:00</updated><id>https://hclimente.github.io/feed.xml</id><title type="html">blank</title><subtitle>Data Scientist. Machine learning + Genetics. </subtitle><entry><title type="html">Covariance and precision</title><link href="https://hclimente.github.io/blog/precision-matrix/" rel="alternate" type="text/html" title="Covariance and precision"/><published>2025-07-16T11:59:00+00:00</published><updated>2025-07-16T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/precision-matrix</id><content type="html" xml:base="https://hclimente.github.io/blog/precision-matrix/"><![CDATA[<p>Imagine we have a set of 3 variables (\(U\), \(X\), and \(Y\)), with one of them being upstream of the other two (\(X \leftarrow U \rightarrow Y\)):</p> \[U \sim N(0, 1)\] \[X = U + \varepsilon_X\] \[Y = U + \varepsilon_Y\] \[\varepsilon_X, \varepsilon_Y \sim N(0, 0.25)\] <p>We want to discover this structure from observational data. Since both \(X\) and \(Y\) are caused by \(U\), a correlation is not very enlightening and will just return the fully connected graph:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-05-29-precision-matrix/img/correlations.webp" sizes="95vw"/> <img src="/assets/python/2025-05-29-precision-matrix/img/correlations.webp" class="img-fluid" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Scatter plots of each pair of variables on 200 observations, each with the correlation between the variables and the associated P-value indicated above. </div> <p>A sensible way of going about it is to study the correlation between each pair of variables after adjusting for the remaining variable. If we assume all relationships are linear, these are called <strong>partial correlations</strong>. Partial correlations are designed to reveal direct relationships by removing the influence of confounding variables. Here is a naive implementation:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">pcorr_residuals</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">
    Compute the matrix of partial correlations from the residuals of linear regression models.

    Parameters
    ----------
    X : np.ndarray
        The input data matrix.

    Returns
    -------
    np.ndarray
        The matrix of partial correlations.
    </span><span class="sh">"""</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>

    <span class="n">residuals</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">empty</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">object</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
            <span class="n">covariates_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">if</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">i</span> <span class="ow">and</span> <span class="n">k</span> <span class="o">!=</span> <span class="n">j</span><span class="p">]</span>
            <span class="n">X_covars</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">covariates_indices</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">target</span><span class="p">,</span> <span class="n">excluded</span> <span class="ow">in</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">)]:</span>

                <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">target</span><span class="p">]</span>

                <span class="c1"># fit a linear model
</span>                <span class="n">beta</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">lstsq</span><span class="p">(</span><span class="n">X_covars</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">rcond</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">X_covars</span> <span class="o">@</span> <span class="n">beta</span>

                <span class="c1"># compute and center the residuals
</span>                <span class="n">r</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_pred</span>
                <span class="n">residuals</span><span class="p">[(</span><span class="n">target</span><span class="p">,</span> <span class="n">excluded</span><span class="p">)]</span> <span class="o">=</span> <span class="n">r</span> <span class="o">-</span> <span class="n">r</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>

    <span class="n">pcorr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">eye</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>

            <span class="n">res_1</span> <span class="o">=</span> <span class="n">residuals</span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">)]</span>
            <span class="n">res_2</span> <span class="o">=</span> <span class="n">residuals</span><span class="p">[(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">)]</span>
            <span class="n">corr</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">res_1</span><span class="p">,</span> <span class="n">res_2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">res_1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">res_2</span><span class="p">))</span>

            <span class="n">pcorr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">pcorr</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">corr</span>

    <span class="k">return</span> <span class="n">pcorr</span>
</code></pre></div></div> <p>Partial correlations correctly identify that \(U\) is correlated with both \(X\) and \(Y\), and in turn that those are not correlated once we account for the effect of \(U\):</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-05-29-precision-matrix/img/partial_correlations.webp" sizes="95vw"/> <img src="/assets/python/2025-05-29-precision-matrix/img/partial_correlations.webp" class="img-fluid" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Scatter plots of the residuals of each pair of variables on 200 observations, each with the <em>partial correlation</em> between the variables and its associated P-value indicated above. </div> <p>Note that while \(\hat{\rho}_{X, U} \approx \rho_{X, U} = 0.8944\), \(\hat{\rho}_{X, U \mid Y} \neq \rho_{X, U}\). This is because \(Y\) contains an additional noise term that makes the adjustment imperfect. Also note that we have identified the <strong>structure</strong> of the data (\(X - U - Y\)), but not its <strong>causal</strong> structure (\(X \rightarrow U \rightarrow Y\), \(X \leftarrow U \leftarrow Y\) or \(X \rightarrow U \rightarrow Y\)).</p> <p>A downside of this approach is its computational complexity. For an \(n \times p\) input matrix:</p> <ul> <li>Memory complexity: \(\mathcal{O}(np^2)\), dominated by storing \({p \choose 2} = \mathcal{O}(p^2)\) residuals, each of length \(n\).</li> <li>Time complexity: \(\mathcal{O}(np^4)\), dominated by computing \({p \choose 2} = \mathcal{O}(p^2)\) least squares problems, each of complexity \(\mathcal{O}(np^2)\).</li> </ul> <p>This is quite computational intensive, which will become a problem in real-world problems. Can we do better? Enter the <strong>precision matrix</strong>, a nice mathematical object to do this at scale.</p> <h1 id="the-precision-matrix">The precision matrix</h1> <details><summary>Need to dust off the basics? Variance, covariance and correlation</summary> <p>The <strong>variance</strong> of a random variable \(X\) is defined as</p> \[\sigma_X^2 = \mathbf{E}(X - \mathbf{E}(X))^2\] <p>The variance takes values in \([0, \infty)\), and measures how disperse the outcomes of the RV are from its mean. Notably, the <strong>(scalar) precision</strong> is defined as \(\frac 1 \sigma_X^2\), so high variance equals low precision and vice versa.</p> <p>The <strong>covariance</strong> between two random variables, \(X_1\) and \(X_2\), is defined as:</p> \[\text{Cov}(X_1, X_2) = \mathbf{E}((X_1 - \mathbf{E}(X_1))(X_2 - \mathbf{E}(X_2))).\] <p>Observe that if \(X_1 = X_2\), \(\sigma_{X_1}^2 = \sigma_{X_2}^2 = \text{Cov}(X_1, X_2)\).</p> <p>The covariance takes values in \((-\sigma_{X_1} \sigma_{X_2}, \sigma_{X_1} \sigma_{X_2})\), and measures the degree to which two random variables are linearly related. The <strong>correlation</strong> \(\rho\) normalizes the covariance, rescaling it to the \([-1, 1]\) range:</p> \[\rho_{X_1, X_2} = \frac {\text{Cov}(X_1, X_2)} {\sigma_{X_1} \sigma_{X_2}}\] </details> <p>The <strong>covariance matrix</strong> of a set of random variables ties the variance and the covariance together. If \(\mathbf{X}\) is a column vector such that</p> \[\mathbf{X} = \begin{pmatrix} X_1 \\ X_2 \\ \vdots \\ X_n \end{pmatrix}\] <p>then its associated covariance matrix \(\mathbf{\Sigma}\) is</p> \[\mathbf{\Sigma} = \begin{pmatrix} \sigma_{X_1}^2 &amp; \text{Cov}(X_1, X_2) &amp; \cdots &amp; \text{Cov}(X_1, X_n) \\ \text{Cov}(X_2, X_1) &amp; \sigma_{X_2}^2 &amp; \cdots &amp; \text{Cov}(X_2, X_n) \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \text{Cov}(X_n, X_1) &amp; \text{Cov}(X_n, X_2) &amp; \cdots &amp; \sigma_{X_n}^2 \end{pmatrix}\] <p>Since always \(\text{Cov}(X_i, X_j) = \text{Cov}(X_j, X_i)\), \(\mathbf{\Sigma}\) is <em>symmetric</em>. It is, in fact, <em>positive semi-definite</em> (<a href="https://statproofbook.github.io/P/covmat-psd.html">proof</a>).</p> <p>By normalizing the covariance matrix by dividing each item \(\mathbf{\Sigma}_{ij}\) by \(\sigma_{X_i} \sigma_{X_j}\), we obtain the <strong>correlation matrix</strong>:</p> \[P = \begin{pmatrix} 1 &amp; \rho_{X_1, X_2} &amp; \cdots &amp; \rho_{X_1, X_n} \\ \rho_{X_2, X_1} &amp; 1 &amp; \cdots &amp; \rho_{X_1, X_n} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \rho_{X_n, X_1} &amp; \rho_{X_n, X_2} &amp; \cdots &amp; 1 \end{pmatrix}\] <p>Finally, the <strong>precision matrix</strong> \(\mathbf{\Sigma}^{-1}\) is the inverse of the covariance matrix, i.e., \(\mathbf{\Sigma} \mathbf{\Sigma}^{-1} = \mathbf{I}\). \(\mathbf{\Sigma}\) is not guaranteed to be invertible, and hence \(\mathbf{\Sigma}^{-1}\) may not exist. Let’s ignore this case for now, and jump to where things start getting interesting. \(\mathbf{\Sigma}^{-1}\) can be decomposed as follows:</p> \[\mathbf{\Sigma}^{-1} = D \begin{pmatrix} 1 &amp; -\rho_{X_1, X_2 \mid X_3, \dots, X_n} &amp; \cdots &amp; -\rho_{X_1, X_n \mid X_2, \cdots, X_{n-1}} \\ -\rho_{X_2, X_1 \mid X_3, \cdots, X_n} &amp; 1 &amp; \cdots &amp; -\rho_{X_2, X_n \mid X_1, X_3, \cdots, X_{n-1}} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ -\rho_{X_n, X_1 \mid X_2, \cdots, X_{n-1}} &amp; -\rho_{X_n, X_2 \mid X_1, X_3 \cdots, X_{n-1}} &amp; \cdots &amp; 1 \end{pmatrix} D\] <p>where \(D\) is a normalization matrix:</p> \[D = \begin{pmatrix} \frac 1 {\sigma_{X_1 \mid X_2, \cdots, X_n}} &amp; &amp; &amp; 0 \\ &amp; \frac 1 {\sigma_{X_2 \mid X_1, X_3, \cdots, X_n}} &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ 0 &amp; &amp; &amp; \frac 1 {\sigma_{X_n \mid X_1, \cdots, X_{n-1}}} \end{pmatrix}\] <p>The entries \(\rho_{X_., X_. \mid \dots}\) in the middle matrix are our precious <strong>partial correlations</strong>.</p> <h1 id="estimating-the-precision-matrix">Estimating the precision matrix</h1> <p>Let’s revisit our motivating example equipped with our newfound knowledge: instead of fitting \(\mathcal{O}(p^2)\) linear models, let’s reach the same result using linear algebra. First, we will estimate the covariance matrix using the maximum likelihood approach. Then, we will invert it to obtain the precision matrix.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">pcorr_linalg</span><span class="p">(</span><span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">:</span> <span class="c1"># (n, p) -&gt; (p, p)
</span>    <span class="sh">"""</span><span class="s">
    Compute the matrix of partial correlations from the covariance matrix.

    Parameters
    ----------
    X : np.ndarray
        The input data matrix.

    Returns
    -------
    np.ndarray
        The matrix of partial correlations.
    </span><span class="sh">"""</span>

    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">shape</span>

    <span class="c1"># showing how the sausage is made
</span>    <span class="c1"># but could be replaced by covariance = np.cov(X, rowvar=False)
</span>    <span class="n">centered_X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">covariance</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">centered_X</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">centered_X</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">precision</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">inv</span><span class="p">(</span><span class="n">covariance</span><span class="p">)</span>

    <span class="n">normalization_factors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">outer</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">precision</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">diag</span><span class="p">(</span><span class="n">precision</span><span class="p">)))</span>
    <span class="n">partial_correlations</span> <span class="o">=</span> <span class="o">-</span> <span class="n">precision</span> <span class="o">/</span> <span class="n">normalization_factors</span>

    <span class="k">return</span> <span class="n">partial_correlations</span>
</code></pre></div></div> <p>This implementation is not only more compact, but has a more favorable computational complexity:</p> <ul> <li>Memory complexity: \(\mathcal{O}(p^2)\), dominated by the intermediate matrices.</li> <li>Time complexity: \(\mathcal{O}(np^2 + p^3)\), dominated by the computation of the covariance matrix and by the matrix inversion.</li> </ul> <p>Furthermore, this implementation is <a href="/blog/python-vectors/">vectorized</a> which further boosts performance. As a quick benchmark, on a random \(1000 \times 100\) matrix, the original <code class="language-plaintext highlighter-rouge">pcorr_residuals</code> took 40.85 seconds; the updated <code class="language-plaintext highlighter-rouge">pcorr_linalg</code> took only 0.0007 seconds.</p> <p>As with many elegant results in linear algebra, things start breaking down when our covariance matrix is <a href="https://en.wikipedia.org/wiki/Condition_number">ill-conditioned</a> or outright <a href="https://en.wikipedia.org/wiki/Singular_matrix">non-invertible</a>. In <a href="https://en.wikipedia.org/wiki/High-dimensional_statistics">high-dimensional problems</a>, \(\Sigma\) is non-invertible (and hard to estimate in the first place). In such cases, we could use <a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">the pseudoinverse matrix</a> instead of the inverse. But that’s just a patch: we will get results, but we are outside of the theory and interpreting the results is not as straightforward. However, when the matrix is ill-conditioned, there is a potential path to salvation: <a href="https://scikit-learn.org/stable/modules/covariance.html">regularization</a>.</p> <h1 id="regularized-estimation">Regularized estimation</h1> <p>Adding a regularization step to the covariance matrix estimation will result in a better conditioned matrix. A common approach is <em>shrinking</em> our empirical covariance towards another matrix, the <em>target</em>:</p> \[\hat{\mathbf{\Sigma}} = (1 - \alpha) \hat{\mathbf{\Sigma}}_\text{MLE} + \alpha T\] <p>where \(\alpha \in [0, 1]\) is a parameter and \(T\) is the target matrix, a highly structured matrix that encodes our assumption about what a <em>true</em> covariance matrix should look like. A possible and aggressive target matrix is a diagonal matrix, which encodes the assumption of zero covariance between variables. By upweighting the diagonal elements and downweighting the off-diagonal elements, this matrix will have a better condition than \(\Sigma_\text{MLE}\).</p> <p>The problem becomes then tuning \(\alpha\). A common way to compute the \(\alpha\) is the <a href="https://web.archive.org/web/20141205061842/http://www.econ.uzh.ch/faculty/ledoit/publications/honey.pdf">Ledoit-Wolf shrinkage method</a>, which finds the \(\alpha\) that minimizes the mean squared error between the real and the estimated matrix. Its <a href="https://github.com/scikit-learn/scikit-learn/blob/68483539614102ba8e083277ed7123e6a9fece53/sklearn/covariance/_shrunk_covariance.py#L25">scikit-learn implementation</a> assumes that the target matrix is \(T = \mu I\), where \(\mu\) is the average variance.</p> <p>Alternatively, we can use graphical lasso to estimate a sparse precision matrix. Conceptually, this is a bit easier to swallow: in many situations, most variables being conditionally uncorrelated is a valid assumption. The <a href="https://en.wikipedia.org/wiki/Graphical_lasso">graphical lasso</a> does just that; it is a penalized estimator of the precision matrix.</p> \[\hat{\mathbf{\Sigma}}^{-1} = \operatorname{argmin}_{\mathbf{\Sigma}^{-1} \succ 0} \left(\operatorname{tr}(\mathbf{\Sigma} \mathbf{\Sigma}^{-1}) - \log \det \mathbf{\Sigma}^{-1} - \lambda \|\mathbf{\Sigma}^{-1}\|_1 \right).\] <p>The \(- \lambda \|\mathbf{\Sigma}^{-1}\|_1\) term will favor sparse matrices, with a strength proportional to the magnitude of \(\lambda\). While tuning \(\lambda\) is in itself a challenge, a common approach is using <a href="https://scikit-learn.org/stable/modules/generated/sklearn.covariance.GraphicalLassoCV.html">cross-validation</a>.</p> <p>Let’s bring this point home by looking at a high-dimensional example (20 samples, 20 features).</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-05-29-precision-matrix/img/high_dimensional_experiments.webp" sizes="95vw"/> <img src="/assets/python/2025-05-29-precision-matrix/img/high_dimensional_experiments.webp" class="img-fluid" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Ground truth and estimated covariance matrix, precision matrix and structure of a high-dimensional example. The data generation process involved 20 samples, with 20 features each, sampled from a 0-mean multivariate Normal distribution. The estimated structure using the Ledoit-Wolf used a soft threshold (abs(correlation) &gt; 0.1); otherwise, the fully connected graph would be shown. </div> <p>As we can see, <strong>maximum likelihood estimation</strong> absolutely fails. Due to the extremely ill-conditioned covariance matrix, the precision matrix is completely off scale, with values ranging from -1.8e+15 to 1.0e+15. <strong>Ledoit-Wolf</strong> succeeds at computing a sensible-looking precision matrix. But recovering a structure, e.g., by thresholding it, is quite a hard task. Last, <strong>graphical lasso</strong> is able to find a relatively sparse structure. While it is still far from the ground truth, it prunes away most of the spurious correlations and keeps most of the true links. <a href="https://scikit-learn.org/stable/modules/covariance.html#sparse-inverse-covariance">As expected</a>, most of the true links are larger in absolute value, and further pruning it would return something close to the true structure.</p> <p>More than anything, this little exercise shows how hard this endeavour is, and serves as a good caution to high-dimensional statistics. Beware!</p> <h2 id="conclusions">Conclusions</h2> <p>Under certain assumptions, the precision matrix helps us discover the internal structure of the data. When should we use what to estimate it?</p> <ol> <li><strong>Empirical inverse (MLE):</strong> fast and exact, but blows up if \(p\) approaches \(n\) or \(\hat Σ\) is singular. Use it when \(n \gg p\) and \(\hat Σ\) is well‑conditioned.</li> <li><strong>Shrinkage (Ledoit-Wolf):</strong> automatically picks \(\alpha\) to stabilize \(\hat Σ\), yielding a dense but well‑behaved precision. Use it when \(\frac p n\) is moderate.</li> <li><strong>Graphical Lasso (cross‑validated \(\lambda\)):</strong> trades off likelihood vs. sparsity to prune weak edges and reveal a parsimonious conditional‑independence network. Use it in high‑dimensional settings.</li> </ol>]]></content><author><name></name></author><category term="linear_algebra"/><category term="graphs"/><category term="statistics"/><summary type="html"><![CDATA[Learning the hidden structure of data]]></summary></entry><entry><title type="html">DNA language model fine-tuning and inference</title><link href="https://hclimente.github.io/blog/hf-transformers/" rel="alternate" type="text/html" title="DNA language model fine-tuning and inference"/><published>2025-05-29T11:59:00+00:00</published><updated>2025-05-29T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/hf-transformers</id><content type="html" xml:base="https://hclimente.github.io/blog/hf-transformers/"><![CDATA[<p>Picture this. A relevant model was just published. The results look compelling. You want to give it a try on your own data. If you have ever been there, the next steps will be painfully familiar: search for code in the paper; find a Zenodo hyperlink; download a tarball, extract it; look for a README, find none; cry; crawl through Jupyter notebooks to understand how the code is meant to be run; et cetera. After a couple of hours, maybe you can get the code working with a nagging discomfort that you might have missed something.</p> <p>This is the workflow that Hugging Face 🤗 and its <a href="https://huggingface.co/docs/transformers/index"><code class="language-plaintext highlighter-rouge">transformers</code></a> Python library aim to eradicate. <code class="language-plaintext highlighter-rouge">transformers</code> provides a unified API to fetch, use and fine-tune many models, making it easy to switch between them without having to learn a new API each time, which has turned it into a staple of LLM work.</p> <p>Let’s dive into the <code class="language-plaintext highlighter-rouge">transformers</code> library. Although big tech is going crazy over LLMs, DNA language models are where the money is.<d-footnote>Citation required</d-footnote> In that spirit, in this post I use <code class="language-plaintext highlighter-rouge">transformers</code> to showcase an application of the <a href="https://www.nature.com/articles/s41592-024-02523-z">Nucleotide Transformer</a> (NT), a DNA language model. And I use the NT to showcase <code class="language-plaintext highlighter-rouge">transformers</code>.</p> <p>I will be providing snippets of code along with the text. If you are still curious about the nitty-gritty, all the code is available <a href="https://github.com/hclimente/hclimente.github.io/blob/main/assets/python/2025-05-02-hf-transformers/">on Github</a>.</p> <h1 id="a-worked-out-training-example">A worked-out training example</h1> <p>The <a href="https://www.nature.com/articles/s41592-024-02523-z">Nucleotide Transformer</a> (NT) is an encoder-only transformer, essentially a <a href="https://en.wikipedia.org/wiki/BERT_(language_model)">BERT model</a> trained on the genomes of 850 species via masked language modelling (MLM).</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/2025-05-02-hf-transformers/nucleotide_transformer-480.webp 480w,/assets/img/posts/2025-05-02-hf-transformers/nucleotide_transformer-800.webp 800w,/assets/img/posts/2025-05-02-hf-transformers/nucleotide_transformer-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/posts/2025-05-02-hf-transformers/nucleotide_transformer.jpg" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> Training of the NT using masked language modelling (MLM). Adapted from Figure 1 in the <a href="https://www.nature.com/articles/s41592-024-02523-z">NT article</a>. </div> <p>In MLM a random bit of the input DNA sequence will be hidden from the model. The task of the model is to retrieve the masked subsequences using the rest of the sequence. Let’s say that the input sequence is <code class="language-plaintext highlighter-rouge">ATGGTAGCTACATCATCT</code>. The model will receive as input <code class="language-plaintext highlighter-rouge">ATGGTAGCTACA&lt;MASK&gt;</code> and we expect it to correctly guess that <code class="language-plaintext highlighter-rouge">&lt;MASK&gt;</code> equals <code class="language-plaintext highlighter-rouge">TCATCT</code>. The figure below gives the basic idea. Let’s break MLM down into its four steps:</p> <ol> <li> <p><strong>Tokenizer:</strong> First, we convert the input DNA sequence into a sequence of integers (<em>tokens</em>), each representing a subsequence of length 6 nucleotides (“6-mers”). The total number of tokens is 4,107: one for each of the \(4^6 = 4096\) possible 6-mers and 11 special tokens (<a href="https://en.wikipedia.org/wiki/Sentence_embedding">CLS</a>, MASK, PAD and a few others).<d-footnote>You can learn more about the tokenizer in the <a href="https://github.com/hclimente/hclimente.github.io/blob/main/assets/python/2025-05-02-hf-transformers/supplementary.ipynb">supplementary notes</a>.</d-footnote></p> <p>In the case of our 18-nucleotide sequence <code class="language-plaintext highlighter-rouge">ATGGTAGCTACATCATCT</code>, the tokenizer transforms it into a tokenized sequence of length 4: <code class="language-plaintext highlighter-rouge">[3, 506, 3662, 1567]</code>. This includes the CLS token (<code class="language-plaintext highlighter-rouge">3</code>) and three tokens representing three 6-mers. During training, a random subset of 15% of the tokens are replaced by the MASK token (<code class="language-plaintext highlighter-rouge">2</code>). These are the parts of the sequence that the model will try to recover. Let’s mask the last token in our example: <code class="language-plaintext highlighter-rouge">[3, 506, 3662, 2]</code>.</p> </li> <li> <p><strong>Embedding layer:</strong> An embedding layer transforms the tokenized sequence of integers into an fixed-length vector of real values (<em>embedding</em>). On this embedding, a positional encoding is added to preserve information about the position of each token.</p> </li> <li> <p><strong>Transformer encoder:</strong> Here comes the main event: the stacked Transformer encoder blocks (since the NT is an encoder-only model, remember?). These blocks are where the magic actually happens, processing the initial embeddings to create context-aware representations. Each block uses self-attention mechanisms to let tokens interact across the sequence and feed-forward networks for position-specific processing.</p> </li> <li> <p><strong>Token probabilities:</strong> Finally the last layer’s embedding is transformed into a probability of each token in each of the input positions. Since there were 3 input positions and 4,107 possible tokens, the output for our sequence will be a matrix of size 3 × 4,107. The rows will sum to 1.</p> <p>In our example, the masked token was <code class="language-plaintext highlighter-rouge">1567</code> and was in the last position. If our model has done a good job, the matrix entry (3, 1567) will be close to 1, and the rest of the entries in that row will be close to 0. During training, the trainer evaluates the model’s output using the <a href="https://en.wikipedia.org/wiki/Cross-entropy">cross-entropy</a> loss, and adjusts the parameters of the model by <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a>.</p> </li> </ol> <p>By repeating this process over and over, on DNA sequences obtained from very different species, the model learns to guess the hidden sequence from it’s genomic context. But, <strong>what is it <em>really</em> learning?</strong> My intuition is that it’s picking up general patterns across genomes. For instance, after looking at many protein-coding sequences it might learn the pattern that we would adscribe to an alpha helix. By putting together some of such patterns, it might learn that protein-coding sequences are related. Then, it could leverage this knowledge in the MLM task to predict a sequence that preserves the alpha helix with the observed codon usage. Similarly, it might learn that another mask is around the right genomic distance from an ORF, and deduce it should predict what we recognize as a promoter. In all this proess the NT has no access to phenotypic information or explicit knowledge about promoters, genes or alpha helices. It is flying blind regarding how this DNA sequence plays out in the real world. Although it is getting a glimpse of evolutionary constraints by being exposed to different genomes, it won’t be able to learn sophisticated genomic regulation patterns.</p> <h1 id="loading-a-pre-trained-model">Loading a pre-trained model</h1> <p>Now that the theory is out of the way, let’s start exploring the Hugging Face ecosystem. There are two elements of it that vastly facilitate sharing and leveraging pre-trained models.</p> <p>One is the <a href="https://huggingface.co/docs/hub/en/index">Model Hub</a>, a repository for the community to share and discover pre-trained models. In this post I use the smallest NT, <a href="https://huggingface.co/InstaDeepAI/nucleotide-transformer-v2-50m-multi-species">a 50 million parameter model</a>, available from <a href="https://huggingface.co/InstaDeepAI">InstaDeep’s hub organization</a>.</p> <p>The other one is the many <a href="https://huggingface.co/docs/transformers/model_doc/auto"><code class="language-plaintext highlighter-rouge">transformers</code> AutoClasses</a>. They abstract away the specific model architecture, and the changes that would be needed to make it fit our use-case. For instance, fetching the NT adapted for masked language modeling is as easy as running:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForMaskedLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
  <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
  <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
    (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
    (decoder): Linear(in_features=512, out_features=4107, bias=False)
  )
)
</code></pre></div></div> <p>As expected, the output is a vector of length 4,107, one for each possible token.</p> <p>By using the <code class="language-plaintext highlighter-rouge">from_pretrained</code> method, we are loading both the architecture and the weights of the model. By default, the model is in evaluation mode; if we were to further fine-tune it, we would need to set it to training mode using <code class="language-plaintext highlighter-rouge">model.train()</code>. In contrast, we could use <code class="language-plaintext highlighter-rouge">from_config</code> to load the model architecture only. This would be appropriate to train the model from scratch.</p> <p>If instead we wanted to leverage the pre-trained model for binary classification, we would run:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
    (dropout): Dropout(p=0.0, inplace=False)
    (out_proj): Linear(in_features=512, out_features=2, bias=True)
  )
)
</code></pre></div></div> <p>As we can see, this added a (disabled) dropout layer, and a linear layer with two outputs, as requested.</p> <p>The model cannot be applied directly to a DNA sequence, which needs to be <a href="#a-worked-out-training-example">tokenized first</a>. Another AutoClasses, the <a href="https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoTokenizer">AutoTokenizer</a>, has got our back:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
  <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
  <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</code></pre></div></div> <h1 id="building-an-inference-pipeline">Building an inference pipeline</h1> <p>The NT’s <a href="https://huggingface.co/InstaDeepAI/nucleotide-transformer-v2-50m-multi-species">Model Card</a> shows how to embed DNA sequences. I copied that code below for your convenience:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForMaskedLM</span>
<span class="kn">import</span> <span class="n">torch</span>

<span class="c1"># Import the tokenizer and the model
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForMaskedLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span>
    <span class="p">)</span>

<span class="c1"># Choose the length to which the input sequences are padded. By default, the
# model max length is chosen, but feel free to decrease it as the time taken to
# obtain the embeddings increases significantly with it.
</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">model_max_length</span>

<span class="c1"># Create a dummy dna sequence and tokenize it
</span><span class="n">sequences</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">ATGGTAGCTACATCATCT</span><span class="sh">"</span><span class="p">]</span>
<span class="n">tokens_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="nf">batch_encode_plus</span><span class="p">(</span>
    <span class="n">sequences</span><span class="p">,</span>
    <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">max_length</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span><span class="p">)[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span>

<span class="c1"># Compute the embeddings
</span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">tokens_ids</span> <span class="o">!=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span>
<span class="n">torch_outs</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span>
    <span class="n">tokens_ids</span><span class="p">,</span>
    <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
    <span class="n">encoder_attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
    <span class="n">output_hidden_states</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>

<span class="c1"># Compute sequences embeddings
</span><span class="n">embeddings</span> <span class="o">=</span> <span class="n">torch_outs</span><span class="p">[</span><span class="sh">'</span><span class="s">hidden_states</span><span class="sh">'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Embeddings shape: </span><span class="si">{</span><span class="n">embeddings</span><span class="p">.</span><span class="n">shape</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Embeddings per token: </span><span class="si">{</span><span class="n">embeddings</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Add embed dimension axis
</span><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Compute mean embeddings per sequence
</span><span class="n">mean_sequence_embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">attention_mask</span><span class="o">*</span><span class="n">embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">torch</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Mean sequence embeddings: </span><span class="si">{</span><span class="n">mean_sequence_embeddings</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

</code></pre></div></div> <p>This is a representation of a common workflow in inference, which looks like this:</p> <pre><code class="language-mermaid">---
config:
  layout: elk
  look: handDrawn
---
flowchart LR
    %% Style definitions
    classDef process fill:#a8dadc,stroke:#2f4f4f,stroke-width:2px,rx:8,ry:8,color:#000
    classDef data fill:#f9c74f,stroke:#2f4f4f,stroke-width:2px,rx:8,ry:8,color:#000

    %% Process nodes
    P2[Tokenizer]:::process
    P3[Model Inference]:::process
    P5[Postprocessing]:::process

    %% Data nodes
    D1[DNA Sequence]:::data
    D21[Tokens]:::data
    D22[Attention Mask]:::data
    D3[Embeddings]:::data
    D5[Masked Embeddings]:::data

    %% Connections
    D1 --&gt; P2
    P2 --&gt; D21
    P2 --&gt; D22
    D21 --&gt; P3
    D22 --&gt; P3
    P3 --&gt; D3
    D22 --&gt; P5
    D3  --&gt; P5
    P5 --&gt; D5
</code></pre> <details><summary>Wondering what is the attention mask?</summary> <p>The attention mask is a binary mask that, for a given input sequence, identifies the padding tokens that are there just to make the sequence fit the desired shape. They help the model avoid wasting (C/G/T)PU cycles on processing useless information. Or even worse, learning the wrong information, when we are not in inference mode. This mask is passed along through the model, and forces the attention scores for these padding tokens to effectively become zero.</p> </details> <p><a href="https://huggingface.co/docs/transformers/pipeline_tutorial">Hugging Face’s <code class="language-plaintext highlighter-rouge">pipelines</code></a> exist to encapsulate these inference steps while cutting the boilerplate code. In particular, every pipeline requires defining four steps:</p> <ul> <li>A function to sanitize the pipeline user-provided arguments</li> <li>A preprocessing function that converts inputs (DNA sequences) into tokenized sequences</li> <li>A forward function that passes the tokenized sequence through the model</li> <li>A postprocessing function that postprocess the model’s outputs</li> </ul> <p>I implemented a small pipeline to embed DNA sequences. Its inputs are Python strings and the output are numpy arrays.</p> <details><summary><code class="language-plaintext highlighter-rouge">DNAEmbeddingPipeline</code> class implementation</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">transformers</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="k">class</span> <span class="nc">DNAEmbeddingPipeline</span><span class="p">(</span><span class="n">Pipeline</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">_sanitize_parameters</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sh">"""</span><span class="s">
        Sanitize the parameters for the pipeline.

        Args:
            **kwargs: The parameters to be sanitized.

        Returns:
            Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]: A tuple containing
                the sanitized parameters for preprocessing, model forward pass, and
                postprocessing, respectively.
        </span><span class="sh">"""</span>
        <span class="n">preprocess_params</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">recognized_params</span> <span class="o">=</span> <span class="nf">set</span><span class="p">([</span><span class="sh">"</span><span class="s">max_length</span><span class="sh">"</span><span class="p">])</span>

        <span class="k">if</span> <span class="sh">"</span><span class="s">max_length</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">preprocess_params</span><span class="p">[</span><span class="sh">"</span><span class="s">max_length</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="sh">"</span><span class="s">max_length</span><span class="sh">"</span><span class="p">]</span>

        <span class="n">unrecognized_params</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">kwargs</span><span class="p">.</span><span class="nf">keys</span><span class="p">())</span> <span class="o">-</span> <span class="n">recognized_params</span>
        <span class="k">if</span> <span class="n">unrecognized_params</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nc">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Unrecognized pipeline parameters: </span><span class="si">{</span><span class="n">unrecognized_params</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">preprocess_params</span><span class="p">,</span> <span class="p">{},</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">model_inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">max_length</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">pt</span><span class="p">.</span><span class="n">Tensor</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Preprocess the input sequences before passing them to the model.

        Args:
            model_inputs (Union[str, List[str]]): The input sequence(s) to be tokenized.
            max_length (Optional[int]): The maximum length of the tokenized sequences.
                If None, the maximum length of the tokenizer is used.

        Returns:
            List[pt.Tensor]: The tokenized input sequences.
        </span><span class="sh">"""</span>
        <span class="k">if</span> <span class="n">max_length</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">max_length</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">model_max_length</span>

        <span class="k">if</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">model_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">model_inputs</span><span class="p">]</span>

        <span class="n">tokens_ids</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="nf">batch_encode_plus</span><span class="p">(</span>
            <span class="n">model_inputs</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="sh">"</span><span class="s">pt</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="sh">"</span><span class="s">longest</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="p">)[</span><span class="sh">"</span><span class="s">input_ids</span><span class="sh">"</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">tokens_ids</span>

    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">model_inputs</span><span class="p">:</span> <span class="n">pt</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Forward pass through the model.

        Args:
            model_inputs (pt.Tensor): The tokenized input sequence(s).

        Returns:
            Dict[str, Any]: The model outputs.
        </span><span class="sh">"""</span>
        <span class="c1"># find out which of the tokens are padding tokens
</span>        <span class="c1"># these tokens will be ignored by the model
</span>        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">model_inputs</span> <span class="o">!=</span> <span class="n">self</span><span class="p">.</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">pad_token_id</span>

        <span class="n">out</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span>
            <span class="n">model_inputs</span><span class="p">,</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">encoder_attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="n">output_hidden_states</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">out</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">attention_mask</span>

        <span class="k">return</span> <span class="n">out</span>

    <span class="k">def</span> <span class="nf">postprocess</span><span class="p">(</span>
        <span class="n">self</span><span class="p">,</span>
        <span class="n">model_outputs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="sh">"""</span><span class="s">
        Compute the mean sequence embedding from the last hidden layer (size 512).

        Args:
            model_outputs (Dict[str, Any]): The model outputs.

        Returns:
            dict[str, np.ndarray]: The mean sequence embeddings for each input sequence.
        </span><span class="sh">"""</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">model_outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">hidden_states</span><span class="sh">"</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">detach</span><span class="p">()</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">model_outputs</span><span class="p">[</span><span class="sh">"</span><span class="s">attention_mask</span><span class="sh">"</span><span class="p">].</span><span class="nf">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nf">cpu</span><span class="p">()</span>
        <span class="n">masked_embeddings</span> <span class="o">=</span> <span class="n">attention_mask</span> <span class="o">*</span> <span class="n">embeddings</span>

        <span class="n">mean_sequence_embeddings</span> <span class="o">=</span> <span class="n">masked_embeddings</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">attention_mask</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">mean_sequence_embeddings</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
</code></pre></div></div> </details> <p>Once the pipeline is in place, embedding a sequence is as easy as:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForMaskedLM</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="nc">DNAEmbeddingPipeline</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="n">embedding</span> <span class="o">=</span> <span class="nf">pipeline</span><span class="p">(</span><span class="sh">"</span><span class="s">ATGGTAGCTACATCATCTG</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>Encapsulating the model into its own inference pipeline has a few advantages. Beyond the obvious benefit of cleaner code by separating inference steps into logical abstractions, it makes swapping models a breeze, as you’ll see when we <a href="#fine-tuning-the-model">fine-tune the model</a>.</p> <h1 id="embedding-dna-sequences">Embedding DNA sequences</h1> <p>I will be using the NT to embed protein-coding DNA sequences from six species: three animals (human, mouse and fruit fly); one plant (arabidopsis); one bacteria (<em>E. coli</em>); and one yeast (<em>S. cerevisiae</em>). I aim to obtain embeddings such that the sequences from each species are on aggregate closer to each other than to the sequences from other species. Note that this is not something the model was trained to do. But I hope that the model picked up that a piece of bacterial DNA is very different from a chunk of human DNA.</p> <p>To this end, I <a href="https://github.com/hclimente/hclimente.github.io/blob/main/assets/python/2025-05-02-hf-transformers/prepare_data.sh">downloaded the DNA sequences</a> of all protein coding genes for the selected species. For each species I randomly subsampled 2,000 sequences of 60 nucleotides each. I chose the length of the sequence because of convenience: they are a common sequence length for FASTA files, and short enough for my modest home computer to handle. Half of them were the train set, used for model building; the other half constituted the test set, used exclusively for performance evaluation. All the results shown below are computed on the latter.</p> <p>I <a href="https://github.com/hclimente/hclimente.github.io/blob/main/assets/python/2025-05-02-hf-transformers/main.ipynb">embedded the sequences</a> and used a UMAP to visualize the embeddings:</p> <div class="l-page"> <iframe src="/assets/python/2025-05-02-hf-transformers/plotly/umap_embeddings.html" frameborder="0" scrolling="no" height="500px" width="100%"></iframe> </div> <div class="caption"> Scatter plot of the two UMAP dimensions from the embeddings computed by applying the <em>pre-trained</em> NT to the 6,000 DNA sequences test dataset, containing 1,000 sequences from each species. </div> <p>Some disclaimers need to be made. First, I took a minuscule sample of all protein coding sequences, which my sampling process slightly biases towards the beginning of the protein. Second, I am using the smallest NT, and its likely that larger models can represent these sequences more richly.</p> <p>Even with these limitations, sequences from the same species tend to inhabit similar regions of the underlying manifold. If you are unconvinced, just squint your eyes or toggle some species on and off. Since this is probably not too reassuring, maybe I can do better: I trained a multiclass logistic regression tasked with predicting the species from the sequence embeddings. This classifier achieved an accuracy of \(0.47\), convincingly above the accuracy of a random classifier (\(\frac 1 6 = 0.16\)). Furthermore, some of the errors are clearly between the two closest species from an evolutionary standpoint: human and mouse.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-05-02-hf-transformers/img/confusion_matrix_test.webp" sizes="95vw"/> <img src="/assets/python/2025-05-02-hf-transformers/img/confusion_matrix_test.webp" class="img-fluid" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="fine-tuning-the-model">Fine-tuning the model</h1> <p>The NT was trained via MLM, and it never got any explicit information about which species it was looking at. Hence, it’s not too surprising that it can’t separate different species right off the bat. Fine-tuning it to this task should provide more relevant representations. <code class="language-plaintext highlighter-rouge">transformers</code> also provides an easy way of doing that using <code class="language-plaintext highlighter-rouge">transformers.Trainer</code>. (For the record, I am unconvinced Hugging Face provides a better solution than <a href="https://lightning.ai">Lightning</a> and others; however, it can be convenient if you are already in teh Hugging Face ecosystem.)</p> <p>We will start by importing the model using a the right AutoClass for the task:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">classif_nt</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="p">.</span><span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">InstaDeepAI/nucleotide-transformer-v2-50m-multi-species</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
    <span class="n">trust_remote_code</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</code></pre></div></div> <p>The <code class="language-plaintext highlighter-rouge">Trainer</code> makes fine-tuning the model quite easy. The task is to predict the species from the sequence. I froze the first few layers from the NT, which should capture low level features of the sequences, and will only train the last layers. Then, I specify the trainer configuration:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">training_args</span> <span class="o">=</span> <span class="nc">TrainingArguments</span><span class="p">(</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">eval_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">epoch</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">save_strategy</span><span class="o">=</span><span class="sh">"</span><span class="s">epoch</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">metric_for_best_model</span><span class="o">=</span><span class="sh">"</span><span class="s">accuracy</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>  <span class="c1"># not supported by mps
</span><span class="p">)</span>
<span class="n">data_collator</span> <span class="o">=</span> <span class="nc">DataCollatorWithPadding</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer_nt</span><span class="p">)</span>

<span class="n">trainer</span> <span class="o">=</span> <span class="nc">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">classif_nt</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">tr_train_ds</span><span class="p">,</span>    <span class="c1"># train on 90% of the train set
</span>    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">tr_val_ds</span><span class="p">,</span>       <span class="c1"># evaluate on 10% of the train set
</span>    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_trainer_metrics</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div> <p>Last, I just begin training with:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trainer</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
</code></pre></div></div> <p>After the model is trained, as specified in the trainer arguments, the model with the best performance on the validation dataset will be the loaded.</p> <p>We can create a new inference pipeline focus around classification. The pipeline will output both the probability of each class, as well as the embeddings, obtained from the last layer. Since this model is tasked explicitly with telling apart sequences coming from different species, the embedding should provides a much better separation:</p> <div class="l-page"> <iframe src="/assets/python/2025-05-02-hf-transformers/plotly/umap_embeddings_ft-model.html" frameborder="0" scrolling="no" height="500px" width="100%"></iframe> </div> <div class="caption"> Scatter plot of the two UMAP dimensions from the embeddings computed by applying the <em>fine-tuned</em> NT to the 6,000 DNA sequences test dataset, containing 1,000 sequences from each species. </div> <p>Maybe this time you won’t even need to squint your eyes to agree.</p> <h1 id="conclusions">Conclusions</h1> <p>In this post, I have given a primer on how to use Hugging Face’s libraries for a particular flavor of BioML work. Yet, in my opinion, Hugging Face’s greatest strength lies just in the boundaries of this post’s focus: on its community. With its <a href="https://huggingface.co/docs/hub/en/models-the-hub">Model Hub</a> they have made it easy for researchers to quickly prototype and share models, and to build on top of existing ones.</p>]]></content><author><name></name></author><category term="python"/><category term="machine_learning"/><category term="huggingface"/><summary type="html"><![CDATA[Using Hugging Face transformers]]></summary></entry><entry><title type="html">An intro to uv</title><link href="https://hclimente.github.io/blog/python-uv/" rel="alternate" type="text/html" title="An intro to uv"/><published>2025-04-25T11:59:00+00:00</published><updated>2025-04-25T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/python-uv</id><content type="html" xml:base="https://hclimente.github.io/blog/python-uv/"><![CDATA[<p>Python veterans will be familiar with <code class="language-plaintext highlighter-rouge">pip</code>, <code class="language-plaintext highlighter-rouge">poetry</code>, <code class="language-plaintext highlighter-rouge">pyenv</code>, <code class="language-plaintext highlighter-rouge">conda</code> and a few other tools for managing projects, packages and environments. <a href="https://github.com/astral-sh/uv"><code class="language-plaintext highlighter-rouge">uv</code></a>’s goal is to replace them all while being blazingly fast.</p> <p>We will use <code class="language-plaintext highlighter-rouge">uv</code> for a prototypical machine learning project: train a neural network to classify images of handwritten digits from the <a href="https://en.wikipedia.org/wiki/MNIST_database">MNIST dataset</a> using a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a>. The input of the model will be a 28x28 pixel image, and the output will be a vector of 10 probabilities, one for each digit. If you are interested in the details of the model, you can check out the <a href="https://github.com/hclimente/hclimente.github.io/tree/main/assets/python/2025-03-15-python-uv/mnist-classifier">code</a>.</p> <div style="width:50%; margin:0 auto;"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-03-15-python-uv/mnist-classifier/img/mnist_examples.webp" sizes="95vw"/> <img src="/assets/python/2025-03-15-python-uv/mnist-classifier/img/mnist_examples.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" alt="Sample MNIST digits" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="caption"> A few examples from MNIST </div> <p>My previous workflow relied on <code class="language-plaintext highlighter-rouge">conda</code> to handle the project environment. I’d start by creating a new conda environment and installing several packages via slow <code class="language-plaintext highlighter-rouge">conda install</code> commands before getting to work. If during model development I needed additional packages, I’d run another <code class="language-plaintext highlighter-rouge">conda install</code> hoping to avoid the dreaded <code class="language-plaintext highlighter-rouge">Solving environment: failed with initial frozen solve. Retrying with flexible solve.</code> error. Once I’d finish, I’d dump my environment into an <code class="language-plaintext highlighter-rouge">environment.yaml</code>, strip-out dev-only dependencies, and hope that the final environment sufficiently resembles the one I worked on. Finally, I’d package the model into a Docker image to get it ready for production.</p> <p>Clearly, I wasn’t thrilled with my old workflow. Let’s see how <code class="language-plaintext highlighter-rouge">uv</code> made it a more pleasant experience.</p> <h1 id="why-uv">Why <code class="language-plaintext highlighter-rouge">uv</code>?</h1> <p>Before diving into the details, it’s worth justifying why we need <em>yet another tool</em> for managing Python-centric data science projects.</p> <p>First, <code class="language-plaintext highlighter-rouge">uv</code> is <strong>fast</strong>. As is common in new high-performance tools, it’s written in Rust, a compiled language known for its performance. It also uses different strategies to speed up package installation, like caching and parallelization. Anyone who has installed a package with <code class="language-plaintext highlighter-rouge">conda</code> knows that package resolution can be a pretty painful experience.</p> <p>Second, <code class="language-plaintext highlighter-rouge">uv</code> boosts <strong>reproducibility</strong>. As we will see below, it makes it easy to create and share virtual environments. This is key to ensure that multiple developers can work on a consistent environment. Furthermore, it facilitates moving projects from development to production.</p> <p>Third, <code class="language-plaintext highlighter-rouge">uv</code> leverages <strong>common standards</strong> within the Python ecosystem. This reduces the risk of being locked into its ecosystem, and makes it easy to collaborate with other developers that use different tools.</p> <p>Last, <code class="language-plaintext highlighter-rouge">uv</code> is <strong>one</strong> tool, which means that I don’t need to remember the syntax of multiple tools, or how to use them together.</p> <details><summary>Why <em>not</em> <code class="language-plaintext highlighter-rouge">uv</code>?</summary> <p>I’m always quite enthusiastic about the new, shinier tool. But before jumping straight into <code class="language-plaintext highlighter-rouge">uv</code>, it’s worth considering the downsides of adopting it.</p> <p>First, <code class="language-plaintext highlighter-rouge">uv</code> is <strong>young</strong>. In contrast, tools like <code class="language-plaintext highlighter-rouge">pip</code>, <code class="language-plaintext highlighter-rouge">conda</code> or <code class="language-plaintext highlighter-rouge">venv</code> have been around for more than a decade. I have no doubt they will be around for at least another decade and are unlikely to pull the rug from under me with breaking changes.</p> <p>Second, and on a related note, <code class="language-plaintext highlighter-rouge">uv</code> is <strong>not widely adopted</strong>. This means that I have had a hard time troubleshooting some errors. It has also meant that it’s not a standard, and you might need to be prepared to advocate for it in your team.</p> <p>Last, <code class="language-plaintext highlighter-rouge">uv</code> is mainly developed by <a href="https://astral.sh">Astral</a>, a VC-backed startup that hasn’t started monetizing their products yet. It remains to be seen how their future business model will impact their tools. I should highlight that <code class="language-plaintext highlighter-rouge">uv</code> is open-source and licensed under MIT, which is somewhat reassuring.</p> <p>I believe that it’s a worthwhile trade-off. But, you know, <em>caveat emptor</em>.</p> </details> <h1 id="starting-a-new-project">Starting a new project</h1> <p>After <a href="https://docs.astral.sh/uv/getting-started/installation/">installing <code class="language-plaintext highlighter-rouge">uv</code></a>, we simply need to run <code class="language-plaintext highlighter-rouge">uv init</code> to start a new project:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>uv init mnist-classifier
</code></pre></div></div> <p>This creates a directory <code class="language-plaintext highlighter-rouge">mnist-classifier</code> in the current directory containing a few files we’ll soon dig into. One of them is a <a href="https://packaging.python.org/en/latest/guides/writing-pyproject-toml/"><code class="language-plaintext highlighter-rouge">pyproject.toml</code></a> file that stores the project’s metadata and configuration. This is a standard file used by <a href="https://python-poetry.org/docs/pyproject/">many</a> <a href="https://pip.pypa.io/en/stable/reference/build-system/pyproject-toml/">tools</a> <a href="https://docs.astral.sh/ruff/configuration/">in</a> <a href="https://black.readthedocs.io/en/stable/usage_and_configuration/the_basics.html#command-line-options">the</a> <a href="https://docs.pytest.org/en/stable/reference/customize.html#pyproject-toml">Python</a> <a href="https://setuptools.pypa.io/en/latest/userguide/pyproject_config.html">ecosystem</a>. For instance, <code class="language-plaintext highlighter-rouge">pip install .</code> would install all the packages listed under the <code class="language-plaintext highlighter-rouge">dependencies</code> field. The <code class="language-plaintext highlighter-rouge">pyproject.toml</code> file created by <code class="language-plaintext highlighter-rouge">uv</code> looks like this:</p> <div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[project]</span>
<span class="py">name</span> <span class="p">=</span> <span class="s">"mnist-classifier"</span>
<span class="py">version</span> <span class="p">=</span> <span class="s">"0.1.0"</span>
<span class="py">description</span> <span class="p">=</span> <span class="s">"Add your description here"</span>
<span class="py">readme</span> <span class="p">=</span> <span class="s">"README.md"</span>
<span class="py">requires-python</span> <span class="p">=</span> <span class="py">"&gt;</span><span class="p">=</span><span class="mf">3.10</span><span class="s">"</span><span class="err">
</span><span class="py">dependencies</span> <span class="p">=</span> <span class="p">[]</span>
</code></pre></div></div> <p>Furthermore, it will start a git repository with a sensible <code class="language-plaintext highlighter-rouge">.gitignore</code>.</p> <details><summary>What about <em>package</em> projects?</summary> <p>By default, <code class="language-plaintext highlighter-rouge">uv init</code> creates an <em>application</em> project. This is appropriate for scripts, like simple tools. This is why the command above created a <code class="language-plaintext highlighter-rouge">main.py</code> file, meant to be the entry point of our application. Alternatively, we could create a <em>library</em> project with <code class="language-plaintext highlighter-rouge">uv init --package mnist-classifier-pkg</code>. This would create a new directory <code class="language-plaintext highlighter-rouge">mnist-classifier-pkg</code> and populate it with a standard structure and configuration suitable for a Python library.</p> </details> <h1 id="creating-the-project-environment">Creating the project environment</h1> <p>Multiple Python projects can co-exist on the same machine, each requiring different packages and versions of the same packages. This is facilitated by <em>virtual environments</em>, self-contained directories with their own Python interpreter and installed Python packages. There are multiple solutions to create and manage virtual environments, like <a href="https://docs.python.org/3/library/venv.html"><code class="language-plaintext highlighter-rouge">venv</code></a>, <a href="https://anaconda.org/anaconda/conda"><code class="language-plaintext highlighter-rouge">conda</code></a> or <a href="https://python-poetry.org/"><code class="language-plaintext highlighter-rouge">poetry</code></a>.</p> <p><code class="language-plaintext highlighter-rouge">uv</code> leverages Python’s built-in package to handle virtual environments: <code class="language-plaintext highlighter-rouge">venv</code>. The virtual environment contains its own installation of Python, whose version is specified in <code class="language-plaintext highlighter-rouge">.python-version</code>. <code class="language-plaintext highlighter-rouge">uv init</code> created this file:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>3.10
</code></pre></div></div> <p>The virtual environment itself lives in the <code class="language-plaintext highlighter-rouge">.venv</code> directory. When Python runs from within an environment, it uses the packages installed in that environment, and only those packages. Typically we would activate this virtual environment from the terminal with <code class="language-plaintext highlighter-rouge">source .venv/bin/activate</code>. This will append <code class="language-plaintext highlighter-rouge">.venv/bin/</code> to our <code class="language-plaintext highlighter-rouge">PATH</code>, loading the <code class="language-plaintext highlighter-rouge">python</code> located there into our environment. However, this comes with an overhead: we need to remember to activate the environment before running any Python script, and we need to deactivate (<code class="language-plaintext highlighter-rouge">deactivate</code>) it when we are done. This is a source of errors, as we may forget to activate the environment or, worse, forget to deactivate it.</p> <p>That’s why <code class="language-plaintext highlighter-rouge">uv</code> does not require explicitly activating the environment. Instead, we can use <code class="language-plaintext highlighter-rouge">uv run &lt;script&gt;.py</code> to run any Python script or command using the environment’s Python. For instance, <code class="language-plaintext highlighter-rouge">uv init</code> created a short, example script, <code class="language-plaintext highlighter-rouge">main.py</code>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Hello from mnist-classifier!</span><span class="sh">"</span><span class="p">)</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="sh">"</span><span class="s">__main__</span><span class="sh">"</span><span class="p">:</span>
    <span class="nf">main</span><span class="p">()</span>
</code></pre></div></div> <p>As stated, we can run it using our default Python, as we are used to (<code class="language-plaintext highlighter-rouge">python main.py</code>), maybe after <code class="language-plaintext highlighter-rouge">source .venv/bin/activate</code>. But we can also run it using <code class="language-plaintext highlighter-rouge">uv run main.py</code>, which will run the script using the environment’s Python interpreter. Besides avoiding loading/unloading virtual environments, <code class="language-plaintext highlighter-rouge">uv run</code> will automatically create the project environment if it does not exist. Similarly, we can run an interactive Python session via <code class="language-plaintext highlighter-rouge">uv run python</code>.</p> <h2 id="installing-the-required-packages">Installing the required packages</h2> <p>Upon its first invocation, <code class="language-plaintext highlighter-rouge">uv run main.py</code> creates a virtual environment. To do this, it examines the (empty) <code class="language-plaintext highlighter-rouge">dependencies</code> list in <code class="language-plaintext highlighter-rouge">pyproject.toml</code> and resolves an (empty) set of packages.</p> <p>To start our little data science project, we’ll need to install the <a href="https://pytorch.org/">PyTorch</a> library. Typically I would have run <code class="language-plaintext highlighter-rouge">conda install conda-forge::pytorch</code>; in <code class="language-plaintext highlighter-rouge">uv</code> we use <code class="language-plaintext highlighter-rouge">uv add torch</code> instead. This installs the most recent version of the package that is compatible with our environment (2.7.0). The whole thing took 9 seconds. For comparison, installing <code class="language-plaintext highlighter-rouge">torch</code> with <code class="language-plaintext highlighter-rouge">conda</code> took 48 seconds. Upon installation, <code class="language-plaintext highlighter-rouge">pyproject.toml</code> gets automatically updated to:</p> <div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="py">dependencies</span> <span class="p">=</span> <span class="p">[</span>
    <span class="py">"torch&gt;</span><span class="p">=</span><span class="mf">2.7</span><span class="err">.</span><span class="mi">0</span><span class="s">",</span><span class="err">
</span><span class="p">]</span>
</code></pre></div></div> <p>This is great, as it allows us to keep track of the packages that we needed for our project, reducing our overhead down the road as the project matures.</p> <p>However, <code class="language-plaintext highlighter-rouge">torch</code> depends, in turn, on other packages, like <code class="language-plaintext highlighter-rouge">numpy</code>. Note that this is not reflected in <code class="language-plaintext highlighter-rouge">pyproject.toml</code>, which lists only our direct dependencies, not every transitive package. Furthermore, as we install additional packages like <code class="language-plaintext highlighter-rouge">torchvision</code> or <code class="language-plaintext highlighter-rouge">matplotlib</code>, <code class="language-plaintext highlighter-rouge">uv</code> will need to resolve all the dependencies and potential conflicts between the packages. <code class="language-plaintext highlighter-rouge">uv</code> keeps an additional file, the lockfile (<code class="language-plaintext highlighter-rouge">uv.lock</code>) that records the exact state of the environment with all the specific package resolutions. The lockfile is thus considerably more thorough than <code class="language-plaintext highlighter-rouge">pyproject.toml</code>. For instance, after <code class="language-plaintext highlighter-rouge">uv add torch</code> it expanded to 353 lines describing all the specific packages, their versions and the metadata that were installed in the environment. This is a small excerpt of the lockfile:</p> <div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[[package]]</span>
<span class="py">name</span> <span class="p">=</span> <span class="s">"filelock"</span>
<span class="py">version</span> <span class="p">=</span> <span class="s">"3.18.0"</span>
<span class="py">source</span> <span class="o">=</span> <span class="p">{</span> <span class="py">registry</span> <span class="p">=</span> <span class="s">"https://pypi.org/simple"</span> <span class="p">}</span>
<span class="py">sdist</span> <span class="o">=</span> <span class="p">{</span> <span class="py">url</span> <span class="p">=</span> <span class="s">"https://files.pythonhosted.org/packages/0a/10/c23352565a6544bdc5353e0b15fc1c563352101f30e24bf500207a54df9a/filelock-3.18.0.tar.gz"</span><span class="p">,</span> <span class="py">hash</span> <span class="p">=</span> <span class="s">"sha256:adbc88eabb99d2fec8c9c1b229b171f18afa655400173ddc653d5d01501fb9f2"</span><span class="p">,</span> <span class="py">size</span> <span class="p">=</span> <span class="mi">18075</span> <span class="p">}</span>
<span class="py">wheels</span> <span class="p">=</span> <span class="p">[</span>
    <span class="err">{</span> <span class="py">url</span> <span class="p">=</span> <span class="s">"https://files.pythonhosted.org/packages/4d/36/2a115987e2d8c300a974597416d9de88f2444426de9571f4b59b2cca3acc/filelock-3.18.0-py3-none-any.whl"</span><span class="p">,</span> <span class="py">hash</span> <span class="p">=</span> <span class="s">"sha256:c401f4f8377c4464e6db25fff06205fd89bdd83b65eb0488ed1b160f780e21de"</span><span class="p">,</span> <span class="py">size</span> <span class="p">=</span> <span class="mi">16215</span> <span class="err">}</span><span class="p">,</span>
<span class="p">]</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">uv.lock</code> should be under git control, providing the exact recipe to replicate an environment. This is key, for instance, to ensure that all developers work on a consistent environment. It can also facilitate moving our code to production, as we’ll see <a href="#training--shipping-the-model">below</a>.</p> <blockquote> <p>If needed, <code class="language-plaintext highlighter-rouge">uv.lock</code> can be exported into a <a href="https://pip.pypa.io/en/stable/reference/requirements-file-format/"><code class="language-plaintext highlighter-rouge">requirements.txt</code></a> file for legacy tools, via <code class="language-plaintext highlighter-rouge">uv export --format=requirements-txt &gt;requirements.txt</code>.</p> </blockquote> <details><summary>Other package management commands</summary> <p>Besides <code class="language-plaintext highlighter-rouge">uv add</code>, there are other commands that can be used to manage packages. For starters, its counterpart <code class="language-plaintext highlighter-rouge">uv remove &lt;package_name&gt;</code> will uninstall <code class="language-plaintext highlighter-rouge">&lt;package_name&gt;</code>. Another command that can trigger package management is <code class="language-plaintext highlighter-rouge">uv run &lt;script&gt;.py</code>. Before running the script, it will ensure that the lockfile is in sync with <code class="language-plaintext highlighter-rouge">pyproject.toml</code> and then ensure that the project environment is in sync with the lockfile.</p> <p>Syncing refers to (un)installing packages in the project environment to match the lockfile. <code class="language-plaintext highlighter-rouge">uv run</code> will do this automatically, as we just saw. But it can also be forced manually with <code class="language-plaintext highlighter-rouge">uv sync</code>.</p> <p>Last, when adding new packages, <code class="language-plaintext highlighter-rouge">uv</code> will tend to be conservative. It will install the most recent version of the package that is compatible with the current environment. To force a specific version, we can use <code class="language-plaintext highlighter-rouge">uv add &lt;package_name&gt;==&lt;version&gt;</code>. For instance, <code class="language-plaintext highlighter-rouge">uv add torch==2.0.1</code> will install version 2.0.1 of <code class="language-plaintext highlighter-rouge">torch</code>, even if a newer version is available. We can request <code class="language-plaintext highlighter-rouge">uv</code> to upgrade all packages if possible with <code class="language-plaintext highlighter-rouge">uv lock --upgrade</code>; or a specific package with <code class="language-plaintext highlighter-rouge">uv lock --upgrade-package &lt;package_name&gt;</code>.</p> <blockquote> <p>To keep compatibility with <code class="language-plaintext highlighter-rouge">pip</code> workflows, <code class="language-plaintext highlighter-rouge">uv</code> also supports <code class="language-plaintext highlighter-rouge">uv pip install &lt;package_name&gt;</code> and <code class="language-plaintext highlighter-rouge">uv pip uninstall &lt;package_name&gt;</code>. These will (un)install the package in the current environment, but it will not update <code class="language-plaintext highlighter-rouge">pyproject.toml</code> or <code class="language-plaintext highlighter-rouge">uv.lock</code>. For this reason, they should be avoided in favor of <code class="language-plaintext highlighter-rouge">uv add</code> and <code class="language-plaintext highlighter-rouge">uv remove</code>.</p> </blockquote> </details> <h2 id="installing-development-only-dependencies">Installing development-only dependencies</h2> <p>As a data scientist, Jupyter notebooks are my bread and butter. In order to run Jupyter notebooks on our <code class="language-plaintext highlighter-rouge">uv</code> environment, we need to install the <a href="https://pypi.org/project/ipykernel/">IPython kernel <code class="language-plaintext highlighter-rouge">ipykernel</code></a>. However, <code class="language-plaintext highlighter-rouge">ipykernel</code>’s role is different from other packages: it is not a dependency of our code, but a tool needed for development. Once my code is ready, I will distribute it as a standalone Python script that has no dependencies on <code class="language-plaintext highlighter-rouge">ipykernel</code>. The same principle applies to tools like <code class="language-plaintext highlighter-rouge">pytest</code>, used to test your code, but which the end-user shouldn’t require unless they intend to contribute to the project.</p> <p><code class="language-plaintext highlighter-rouge">uv</code> allows you to add development dependencies with <code class="language-plaintext highlighter-rouge">uv add --dev ipykernel</code>, which will add the following to <code class="language-plaintext highlighter-rouge">pyproject.toml</code>:</p> <div class="language-toml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">[dependency-groups]</span>
<span class="py">dev</span> <span class="p">=</span> <span class="p">[</span>
    <span class="py">"ipykernel&gt;</span><span class="p">=</span><span class="mf">6.29</span><span class="err">.</span><span class="mi">5</span><span class="s">",</span><span class="err">
</span><span class="p">]</span>
</code></pre></div></div> <p>This should allow my tool of choice, Visual Studio Code, to find this virtual environment and run Jupyter notebooks on it. However, in my experience, it has been somewhat unreliable: Visual Studio Code only finds the kernel half of the time. A workaround is launching a JupyterLab server instance with <code class="language-plaintext highlighter-rouge">uv run --with jupyter jupyter lab</code> and connecting to it from the editor.</p> <h1 id="training--shipping-the-model">(Training &amp;) Shipping the model</h1> <p>Here comes the actual data science, which I will just skim over. I wrote a simple script to train a convolutional neural network on the MNIST dataset. The script is located in <a href="https://github.com/hclimente/hclimente.github.io/tree/main/assets/python/2025-03-15-python-uv/mnist-classifier/train.py"><code class="language-plaintext highlighter-rouge">train.py</code></a>, and can be run with <code class="language-plaintext highlighter-rouge">uv run train.py</code>. It achieves a 98% classification accuracy on the held-out samples. Neat!</p> <p>Now that we have a working model, let’s see how <code class="language-plaintext highlighter-rouge">uv</code> helps us package the model into a Docker image.</p> <p>First, we need to pick our base image. Astral provides <a href="https://docs.astral.sh/uv/guides/integration/docker/#available-images">multiple pre-built images</a> that include <code class="language-plaintext highlighter-rouge">uv</code> and different versions of Python. Then, deploying the model is as easy as copying the model weights and the prediction script <a href="https://github.com/hclimente/hclimente.github.io/tree/main/assets/python/2025-03-15-python-uv/mnist-classifier/predict.py"><code class="language-plaintext highlighter-rouge">predict.py</code></a> into the image, copying <code class="language-plaintext highlighter-rouge">uv</code> project environment files, and building the environment:</p> <div class="language-Dockerfile highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">FROM</span><span class="s"> ghcr.io/astral-sh/uv:python3.10-bookworm-slim</span>

<span class="k">RUN </span><span class="nb">mkdir</span> <span class="nt">-p</span> /mnist_classifier/data
<span class="k">WORKDIR</span><span class="s"> /mnist_classifier</span>

<span class="c"># ensure uv.lock isn't modified</span>
<span class="k">ENV</span><span class="s"> UV_LOCKED=1</span>

<span class="c"># copy the minimum required files:</span>
<span class="c">## the uv files needed to recreate the environment</span>
<span class="k">COPY</span><span class="s"> pyproject.toml uv.lock ./</span>
<span class="c">## the prediction script</span>
<span class="k">COPY</span><span class="s"> predict.py .</span>
<span class="c">## the model weights</span>
<span class="k">COPY</span><span class="s"> data/mnist_cnn.pt data/</span>

<span class="c"># recreate the environment</span>
<span class="k">RUN </span>uv <span class="nb">sync</span> <span class="nt">--no-dev</span>

<span class="k">CMD</span><span class="s"> ["uv", "run", "predict.py"]</span>
</code></pre></div></div> <p>The key command here was <code class="language-plaintext highlighter-rouge">uv sync</code>, which will recreate the environment using the exact versions of the packages specified in <code class="language-plaintext highlighter-rouge">uv.lock</code>. This ensures that the environment used to train the model is identical to the one used to share it. Notice that the <code class="language-plaintext highlighter-rouge">--no-dev</code> flag will exclude the packages used for development, like <code class="language-plaintext highlighter-rouge">ipykernel</code>. It’s worth highlighting that the lockfile is cross-platform: I generated it on macOS, but the Docker image is based on Debian.</p> <blockquote> <p>Note: If you use GPU-specific packages, wheels may differ. See <a href="https://docs.astral.sh/uv/guides/integration/pytorch/#installing-pytorch">Astral’s docs</a>.</p> </blockquote> <p>Let’s now build and run the image:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker build <span class="nt">-t</span> mnist_classifier <span class="nb">.</span>
docker run mnist_classifier
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>SimpleCNN(
  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
Downloading MNIST test set...
Accuracy of SimpleCNN on the 10,000 test images: 98 %
</code></pre></div></div> <p>Nice!</p> <h1 id="conclusions">Conclusions</h1> <p>We have seen how <code class="language-plaintext highlighter-rouge">uv</code> can be used to manage Python projects, packages and environments. It satisfies my craving for reproducibility, is snappy and has simplified repetitive workflows. I look forward to seeing how it keeps evolving.</p> <h1 id="further-reading">Further reading</h1> <ul> <li><a href="https://www.bitecode.dev/p/a-year-of-uv-pros-cons-and-should">A year of uv: pros, cons, and should you migrate</a></li> </ul>]]></content><author><name></name></author><category term="python"/><category term="coding"/><summary type="html"><![CDATA[A Swiss Army Knife for Python data science]]></summary></entry><entry><title type="html">SHAP values</title><link href="https://hclimente.github.io/blog/shapley/" rel="alternate" type="text/html" title="SHAP values"/><published>2025-04-01T11:59:00+00:00</published><updated>2025-04-01T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/shapley</id><content type="html" xml:base="https://hclimente.github.io/blog/shapley/"><![CDATA[<p>SHAP values are a model-agnostic method to quantify the contribution of any given feature to a model’s prediction. They offer both local (per prediction) and global (overall) interpretations.</p> <h1 id="shapley-values">Shapley values</h1> <p>SHAP values have their roots in game theory, specifically in <strong>Shapley</strong> values. Imagine a group of players collaborating to achieve a payout. The Shapley value is a method to find out how to fairly distribute the total earnings among the players. Or the blame, if the payout was negative!</p> <p>A core concept of Shapley values is <strong>coalitions</strong>: given \(n\) players, a coalition is a subset of the players. Another concept is the <strong>characteristic function</strong>, \(v: 2^N \rightarrow \mathbb{R}\), which returns the total payout for any given coalition (its <em>worth</em>). Here, \(N\) is the set of all players. The last concept is the Shapley value itself, the amount \(\phi_i\) that player \(i\) receives. It is computed as the average of the marginal contributions of player \(i\) to all possible coalitions that do not include it. More formally, for a game \((v, N)\):</p> \[\phi_i(v) = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!\; (n-|S|-1)!}{n!} (v(S\cup\{i\})-v(S))\] <p>These values satisfy four key properties, which collectively ensure fair attribution: efficiency, symmetry, dummy player, and additivity.</p> <h2 id="efficiency">Efficiency</h2> <p>The grand coalition is the coalition of all players, \(N\). Efficiency means that the sum of all Shapley values equals the value of the grand coalition, i.e., the entire payout is distributed among the players:</p> \[\sum_{i \in N} \phi_i(v) = v(N)\] <h2 id="symmetry">Symmetry</h2> <p>Two players \(i\) and \(j\) are symmetric if their marginal contribution to any coalition not containing either player is the same. That is, if \(v(S \cup \{i\}) = v(S \cup \{j\})\) for any coalition \(S \subseteq N \setminus \{i, j\}\), then symmetry implies that players \(i\) and \(j\) receive the same Shapley value: \(\phi_i(v) = \phi_j(v)\).</p> <h2 id="dummy-player">Dummy player</h2> <p>If a player \(i\) does not change the value of any coalition they join (i.e., \(v(S \cup \{i\}) = v(S)\) for all \(S \subseteq N \setminus \{i\}\)), they are a dummy player. The dummy player property states that such a player’s Shapley value is 0.</p> <h2 id="additivity">Additivity</h2> <p>If two games with characteristic functions \(v_1\) and \(v_2\) are combined into a new game \(v_1 + v_2\) (where \((v_1+v_2)(S) = v_1(S) + v_2(S)\) for any coalition \(S\)), the Shapley values are additive:</p> \[\phi_i(v_1+v_2) = \phi_i(v_1) + \phi_i(v_2)\] <h1 id="shap-values">SHAP values</h1> <p>Machine learning models like linear regression are <em>interpretable</em>, as the model parameters indicate how each input feature contributes to the prediction. However, many complex models like neural networks or random forests are less directly interpretable: their output is a complex, non-linear combination of the input features. SHAP values (<a href="https://arxiv.org/abs/1705.07874">Lundberg and Lee, 2017</a>) provide a framework to quantify the contribution of each feature to a specific prediction for <em>any</em> model. SHAP stands for SHapley Additive exPlanations, highlighting their connection to <em>Shapley</em> values.</p> <p>Intuitively, SHAP values quantify how much each feature’s presence changes the prediction. Some features will have a negative contribution (pushing the prediction lower) and others a positive contribution (pushing the prediction higher). The sum of a feature’s SHAP value and a baseline value (typically the average prediction) approximates the model’s output.</p> <p>To establish the connection to Shapley values, we map the game theory concepts to the machine learning context:</p> <ul> <li>The \(n\) players become \(n\) <em>predictive features</em>.</li> <li>The game is the <em>trained model</em>.</li> <li>The payout for a coalition of features is the <em>model’s prediction</em> when only those features are known.</li> </ul> <p>The Shapley value \(\phi_i\) for feature \(i\) in this context is then calculated as:</p> \[\phi_i = \sum_{S \subseteq F \setminus \{i\}} \frac{|S|!\; (n-|S|-1)!}{n!} (f(\mathbf{x}_{S\cup\{i\}})-f(\mathbf{x}_S))\] <p>where \(\mathbf{x}_S\) is the input datapoint including only the features in \(S\); \(F\) is the set of all features; \(n\) is the total number of features; and \(f_S\) is the model trained only on the features in set \(S\). However, this naïve approach is very computationally intensive, since it’d require retraining \(2^n\) models, one per possible coalition. (See a worked out example <a href="https://www.aidancooper.co.uk/how-shapley-values-work/">here</a>.) SHAP values get around re-training models by approximating the effect of feature subsets using conditional expectations: \(f(\mathbf{x}_S) = \mathbb{E}[f(X) \mid X_S = \mathbf{x}_S]\). In other words, we fix the features that are in \(S\) to the sample values, and average over the predictions when sampling the remaining features from the dataset.</p> <blockquote> <p><strong><em>Simplified</em> features:</strong> We use \(\mathbf{x}\) for the features in the original space \(\chi\), a vector of length \(n\). The SHAP theoretical framework uses a simplified feature vector \(\mathbf{x}' \in \{0,1\}^m\), where \(m\) is the number of simplified features (which can be different from \(n\)). \(x'_j = 1\) indicates that simplified feature \(j\) is “present” in a coalition, and \(x'_j = 0\) indicates it is “absent”. The simplified features are more useful for interpretation. For instance, if \(\mathbf{x}\) represented the individual pixels of an image, \(\mathbf{x}'\) could represent the presence of the “super pixels” that form a cat, grass or the sky. A mapping function \(h_\mathbf{x}: \{0,1\}^m \rightarrow \chi\) links the simplified representation back to the original feature space. For \(\mathbf{x}' = \mathbf{1}\) (all simplified features present), \(h_\mathbf{x}(\mathbf{1}) = \mathbf{x}\). For other \(\mathbf{x}'\), \(h_\mathbf{x}(\mathbf{x}')\) represents the original instance with features corresponding to \(x'_j=0\) appropriately handled (e.g., replaced by baseline values). Note that \(h_\mathbf{x}\) is specific to the instance \(\mathbf{x}\) being explained.</p> </blockquote> <p>That covers the <em>Shapley</em> part of SHAP; let’s now focus on the <em>Additive exPlanation</em> bit. The goal of SHAP is to obtain a local, additive explanation model \(g\) for each prediction \(f(\mathbf{x})\) using the simplified features \(\mathbf{x}'\):</p> \[g(\mathbf{x}') = \phi_0 + \sum_{j = 1}^m \phi_j \mathbf{x}'_j\] <p>where \(\phi_0\) is the expectation over all training examples \(\mathbb{E}[f(X)]\). \(g(\mathbf{x}')\) is a very easy to interpret function that we’ll use to explain \(f(\mathbf{x})\).</p> <p>Since SHAP values are Shapley values, they meet all the properties specified above. But they also satisfy three additional properties that are desirable for model explainers.</p> <h2 id="local-accuracy">Local accuracy</h2> <p>When all simplified features are present (\(\mathbf{x}' = \mathbf{1}\)), the explanation model \(g\) must equal the prediction \(f(\mathbf{x})\):</p> \[f(\mathbf{x}) = g(\mathbf{1}) = \phi_0 + \sum_{j = 1}^m \phi_j\] <h2 id="missingness">Missingness</h2> <p>If a feature is missing, it deserves 0 attribution:</p> \[\mathbf{x}'_j = 0 \implies \phi_j = 0.\] <p>This is a required property to ensure that local accuracy has a unique solution.</p> <h2 id="consistency">Consistency</h2> <p>The consistency ensures that if a model \(f\) changes into another model \(f'\), such that a feature’s contribution doesn’t decrease, the SHAP values do not decrease either. Formally, if</p> \[f'(S) - f'(S \setminus \{i\}) \geq f(S) - f(S \setminus \{i\})\] <p>for all \(S \in F\), then \(\phi_i(f', \mathbf{x}) \geq \phi_i(f, \mathbf{x})\).</p> <h1 id="a-visual-example">A visual example</h1> <p>Let’s understand SHAP values better by looking at an example. I trained a model that uses 10 clinical features (body mass index, cholesterol, age, and a few others) to predict a continuous measure of disease progression one year after baseline. For the purposes of this example, the model is treated as a black box whose input are the 10 features, and the output a real number.</p> <table> <thead> <tr> <th>Age</th> <th>Sex</th> <th>BMI</th> <th>Blood pressure</th> <th>…</th> <th>Target</th> </tr> </thead> <tbody> <tr> <td>0.0380759</td> <td>0.0506801</td> <td>0.0616962</td> <td>0.0218724</td> <td>…</td> <td>151</td> </tr> <tr> <td>-0.00188202</td> <td>-0.0446416</td> <td>-0.0514741</td> <td>-0.0263275</td> <td>…</td> <td>75</td> </tr> <tr> <td>0.0852989</td> <td>0.0506801</td> <td>0.0444512</td> <td>-0.00567042</td> <td>…</td> <td>141</td> </tr> <tr> <td>…</td> <td>…</td> <td>…</td> <td>…</td> <td>…</td> <td>…</td> </tr> </tbody> </table> <blockquote> <p>SHAP values can be computed on the dataset used to train the model (train set) or on a holdout set. Using a larger dataset like the train set might provide a more stable picture of overall feature contributions learned by the model. However, if the train and test data come from different distributions, computing SHAP on the respective sets will likely yield different results.</p> </blockquote> <details><summary>The <code class="language-plaintext highlighter-rouge">shap</code> package</summary> <p>SHAP values are implemented in Python via the <a href="https://shap.readthedocs.io/en/latest/index.html"><code class="language-plaintext highlighter-rouge">shap</code></a> package. While I won’t be showing any code here, you can see the code that generated the figures <a href="/assets/python/2025-04-01-shapley/main.py">here</a>.</p> </details> <p>SHAP values provide <strong>local</strong> explanations, showing the contribution of each feature to a particular prediction. I computed the SHAP values describing the importance of each of the 10 variables for each of the 442 patients. These values represent the estimated impact of each feature on a prediction, relative to the average prediction. We can start by looking at the SHAP values for one patient, using a <em>waterfall</em> plot:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-04-01-shapley/img/waterfall_diabetes.webp" sizes="95vw"/> <img src="/assets/python/2025-04-01-shapley/img/waterfall_diabetes.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The waterfall plot shows how the prediction for this patient (186.53) departs from the average prediction over the training set (152.132). The difference (34.398) is the total change attributed by the model. As per the local accuracy property, the SHAP values for this instance sum up to this difference. The features are sorted by the absolute magnitude of their SHAP value. Features colored in pink push the prediction toward higher values, and features in blue toward lower values. We can see that, for this patient, the body mass index was the most important feature, contributing positively by 22.25.</p> <p>We can visualize SHAP values for all 442 patients using a <em>swarmplot</em>:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-04-01-shapley/img/beeswarm_diabetes.webp" sizes="95vw"/> <img src="/assets/python/2025-04-01-shapley/img/beeswarm_diabetes.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In the swarmplot, each point represents the SHAP value for a patient for a specific feature. Features are shown on the y-axis, and their corresponding SHAP values on the x-axis. As in the waterfall plot, features are sorted by their overall importance; and the color of each point indicates the feature value for that patient (pink for high, blue for low).</p> <p>Global explanations can be derived by aggregating the local SHAP values over a dataset. A common global measure is the average absolute SHAP value for each feature:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-04-01-shapley/img/global_diabetes.webp" sizes="95vw"/> <img src="/assets/python/2025-04-01-shapley/img/global_diabetes.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Plotting these averages shows which features have the largest impact on the model’s predictions <em>on average</em> across the dataset, providing a global measure of feature importance.</p> <p>Lastly, SHAP values can be used for clustering. While traditional clustering groups data points based on their original feature values, clustering in SHAP space groups points based on how features <em>contribute to the model’s prediction</em>. This can be seen as a form of <em>supervised</em> clustering, as it leverages the model’s output (and indirectly the outcome it was trained on). Clustering SHAP values can reveal groups of instances where different sets of features drive the prediction.</p> <style>.colored-slider{--divider-color:rgba(0,0,0,0.5);--default-handle-color:rgba(0,0,0,0.5);--default-handle-width:clamp(40px,10vw,200px)}</style> <img-comparison-slider class="colored-slider"> <figure slot="first"> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-04-01-shapley/img/supervised_pca.webp" sizes="95vw"/> <img src="/assets/python/2025-04-01-shapley/img/supervised_pca.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure slot="second"> <picture> <source class="responsive-img-srcset" srcset="/assets/python/2025-04-01-shapley/img/unsupervised_pca.webp" sizes="95vw"/> <img src="/assets/python/2025-04-01-shapley/img/unsupervised_pca.webp" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </img-comparison-slider> <p>Applying PCA to the SHAP values (“supervised PCA”) and the original features (“unsupervised PCA”) for this dataset, we can visualize how instances are grouped.</p> <h1 id="limitations">Limitations</h1> <p>One key limitation of interpreting SHAP values is their behavior with <strong>highly correlated features</strong>. When features are strongly correlated, the model might arbitrarily use one over the others, or distribute importance among them. Consequently, the SHAP values for individual correlated features can become unstable or misleading, making it hard to disentangle their individual contributions.</p> <p>Another point of consideration is <strong>feature interactions</strong>. While the fundamental Shapley value calculation inherently accounts for interactions (by averaging marginal contributions over different coalitions), the basic additive SHAP explanation model \(g(\mathbf{x}') = \phi_0 + \sum \phi_j \mathbf{x}'_j\) does not explicitly separate main effects from interaction effects. The \(\phi_j\) values represent the <em>average</em> contribution of feature \(j\), including its interactive effects, making their interpretation as pure “main effects” challenging when interactions are significant. However, SHAP <a href="https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/tree_based_models/Basic%20SHAP%20Interaction%20Value%20Example%20in%20XGBoost.html"><em>can</em> be extended</a> to compute pairwise SHAP interaction values (\(\phi_{ij}\)) which explicitly quantify the interaction between features \(i\) and \(j\).</p> <p>Finally, it’s important to remember that SHAP values explain <em>how the model makes a prediction</em>, not whether the prediction itself is correct. If the model is biased, overfit, or simply wrong for a given instance, the SHAP values will faithfully explain the mechanism behind that incorrect prediction. Measures like permutation feature importance, which rely on model performance metrics after feature perturbation, inherently account for the model’s correctness in their explanation.</p> <h1 id="flavors-of-shap-the-permutation-approximation">Flavors of SHAP: the permutation approximation</h1> <p><a href="#shap-values">Above</a> I described the general approach to compute SHAP values. Unfortunately, it is very computationally intensive: exploring all possible coalitions is equivalent to exploring all \(2^m\) subsets of features. For that reason, different flavors of SHAP values have been proposed to make computations more efficient. I describe below the <strong>permutation approximation</strong>, a model-agnostic method to compute SHAP values \(\phi_i\). However, there are others specialized in specific model types, like <a href="https://shap.readthedocs.io/en/latest/generated/shap.TreeExplainer.html">Tree SHAP</a> for tree-based models (e.g., random forests, gradient boosting) and <a href="https://shap.readthedocs.io/en/latest/generated/shap.DeepExplainer.html">Deep SHAP</a> for deep learning models.</p> <p>The permutation approximation approximates SHAP values by estimating the expected marginal contribution of each feature over many random permutations of the features. Let’s study the permutation approximation through a worked out example. We aim to explain a prediction \(f(\mathbf{x}_0)\). We have at our disposal a background dataset \(X_\text{bg}\), e.g., the whole training set, which we will use for sampling. For the sake of the example, our model only considers four (simplified) features: \(\mathbf{x}_0 = [x_{\text{age}}, x_\text{sex}, x_\text{BMI}, x_\text{BP}]\).</p> <p>For each feature \(i\) that we want to explain:</p> <ol> <li>Initializing a list to store the marginal contribution of each feature. In this example, I will focus on the contribution of the first feature, \(x_\text{age}\), so I will call this list just \(\text{list}_\text{age}\).</li> <li>For \(K\) iterations: <ol> <li>A random ordering of the features is produced, e.g., \((\text{BP}, \text{age}, \text{BMI}, \text{sex})\), and a random sample \(\mathbf{z}\) is sampled from the background dataset \(X_\text{bg}\).</li> <li>Create two synthetic examples: - \(\mathbf{x}_1 = (x_\text{BP}, x_\text{age}, z_\text{BMI}, z_\text{sex})\) - \(\mathbf{x}_2 = (x_\text{BP}, z_\text{age}, z_\text{BMI}, z_\text{sex})\) Note that the only difference between the two examples is the value of the age feature.</li> <li>Compute the marginal contribution of the age feature as \(\delta = f(\mathbf{x}_1) - f(\mathbf{x}_2)\).</li> <li>Append the marginal contribution to \(\text{list}_\text{age}\).</li> </ol> </li> <li>Approximate the SHAP value as the average marginal contribution: \(\phi_\text{age} \cong \frac{1}{K} \sum_i \delta_{i}.\)</li> </ol> <h1 id="further-reading">Further reading</h1> <ul> <li><a href="https://christophm.github.io/interpretable-ml-book/shapley.html">Interpretable Machine Learning: Shapley values</a></li> <li><a href="https://christophm.github.io/interpretable-ml-book/shap.html">Interpretable Machine Learning: SHAP</a></li> <li><a href="https://shap.readthedocs.io">Python’s <code class="language-plaintext highlighter-rouge">shap</code> documentation</a></li> <li><a href="https://www.aidancooper.co.uk/supervised-clustering-shap-values/">Supervised Clustering: How to Use SHAP Values for Better Cluster Analysis</a></li> <li><a href="https://davidrosenberg.github.io/ttml2021fall/interpretable-ml/5.Shapley-LIME-SHAP.pdf">Shapley Values, LIME, and SHAP</a></li> </ul>]]></content><author><name></name></author><category term="feature_selection"/><category term="machine_learning"/><category term="feature_importance"/><summary type="html"><![CDATA[A model-agnostic framework for explaining predictions]]></summary></entry><entry><title type="html">Knockoffs</title><link href="https://hclimente.github.io/blog/kernel-knockoffs/" rel="alternate" type="text/html" title="Knockoffs"/><published>2025-02-18T12:00:00+00:00</published><updated>2025-02-18T12:00:00+00:00</updated><id>https://hclimente.github.io/blog/kernel-knockoffs</id><content type="html" xml:base="https://hclimente.github.io/blog/kernel-knockoffs/"><![CDATA[<p>In many scientific applications, the goal is to discover which features are truly associated with an outcome. The <a href="https://en.wikipedia.org/wiki/False_discovery_rate">false discovery rate</a> (FDR) is defined as the expected proportion of false positives among the selected features. Controlling the FDR is less conservative than controlling the <a href="https://en.wikipedia.org/wiki/Family-wise_error_rate">family-wise error rate</a>, often leading to more discoveries.</p> <p>When dealing with statistical tests, Benjamini–Hochberg and Benjamini–Yekutieli are common procedures to keep the FDR below a level \(\alpha\). However, such strategies rely on certain assumptions; for instance, that P-values are well-calibrated or that tests have certain correlation structures. If these are not met, the statistical guarantees on FDR control are also out the window. Furthermore, they require having P-values to work with; in many cases we just want to control the FDR of selected features, but do not have a well-characterized null hypothesis. For instance, given a set of active features in Lasso, how can we make sure the fraction of non-explanatory features is controlled? In such cases, <em>knockoffs</em> can be helpful.</p> <h1 id="knockoffs">Knockoffs</h1> <p>The <strong>knockoff</strong> filter is a procedure to perform feature selection while keeping the FDR controlled. Given an outcome \(\mathbf{Y}\) and a feature matrix \(X\), the goal is to select a subset of features \(X_S\) such that</p> \[Y \perp X_{-S} \mid X_S\] <p>The procedure computes and leverages a new matrix \(\tilde{X}\), with the same dimensions as \(X\), containing “knockoff” copies of the original features. Each original variable \(\mathbf{X_i}\) has its own knockoff \(\mathbf{\tilde{X}_i}\). These knockoffs are engineered to mimic the correlation structure of the original features: for any \(i \neq j\), \(\rho(\mathbf{X_i}, \mathbf{X_j}) = \rho(\mathbf{X_i}, \mathbf{\tilde{X}_j}) = \rho(\mathbf{\tilde{X}_i}, \mathbf{\tilde{X}_j})\). Also, knockoffs are created without using \(\mathbf{Y}\). Hence, conditional on \(X\), \(Y\) is independent of \(\tilde{X}\).</p> <p>There are two paradigms to model knockoffs: Model-X and Fixed-X.</p> <p>The <strong>Model-X</strong> paradigm assumes that the explanatory variables are random variables with a known joint distribution. Although theoretically appealing, this assumption can be impractical for real-world data, since we do not know the data generating function \(F_X\). For that reason, I will ignore it for the remainder of this discussion.</p> <p>The <strong>Fixed-X</strong> paradigm makes no assumptions on the distribution of the explanatory variables. Instead, they can be treated as fixed quantities. This makes it more applicable in practice. However, it imposes three important restrictions:</p> <ul> <li>\(F_{Y \mid X}\) must be linear and homoscedastic</li> <li>The problem must be low dimensional (number of samples \(&gt;\) number of features)</li> <li>The statistics \(D(X_i, Y)\) and \(D(\tilde{X}_i, Y)\) must satisfy additional requirements (see references)</li> </ul> <h1 id="the-knockoff-procedure">The knockoff procedure</h1> <p>Intuitively, by comparing the association measure computed for each original feature against its knockoff, one can determine which features provide true signals. Specifically, the knockoff-based feature selection consists of four steps.</p> <h2 id="1-generate-knockoffs">1. Generate knockoffs</h2> <p>Create synthetic copies of the features that retain the original correlation structure without any outcome information. An obvious question is how to synthesize such knockoff copies.</p> <h2 id="2-compute-association-measures">2. Compute association measures</h2> <p>For each feature, calculate the association measure \(D(\mathbf{Y}, \mathbf{X_k})\) and its counterpart \(D(\mathbf{Y}, \tilde{\mathbf{X}}_k)\) on the knockoff.</p> <p>Kernel-based measures are powerful tools for detecting complex, non-linear dependencies:</p> <ul> <li><strong>HSIC (Hilbert-Schmidt Independence Criterion):</strong> Computes the covariance between kernel-transformed versions of the feature and the outcome, capturing a broad range of dependency structures.</li> <li><strong>Conditional MMD (cMMD):</strong> Assesses the difference between the conditional distribution of a feature given the outcome and its marginal distribution. This measure is particularly useful when dealing with categorical outcomes.</li> <li><strong>TR Measure:</strong> A linear combination of Kendall’s τ and Spearman’s ρ, designed to effectively capture associations in both continuous and discrete data.</li> </ul> <p>These measures satisfy the sure independence screening property under bounded kernel conditions—meaning that, with high probability, the truly active features are recovered when a proper threshold is used.</p> <blockquote> <p>A potential limitation of kernel knockoffs is its sometimes overly conservative nature. To keep the FDR low, the procedure may end up selecting very few—or even no—features. This suggests that the chosen association measure might not be sufficiently sensitive. One possible remedy is to explore alternative kernel choices or optimize feature screening steps before applying knockoff filtering.</p> </blockquote> <h2 id="3-compute-the-knockoff-statistic">3. Compute the knockoff statistic</h2> <p>Define the statistic as \(w_k = D(Y, X_k) - D(Y, \tilde{X}_k)\). A larger \(w_k\) indicates stronger evidence that the original feature is associated with the outcome.</p> <h2 id="4-select-a-threshold-and-select-features">4. Select a threshold and select features</h2> <p>Identify the smallest threshold \(t\) such that \(\frac{\#\{w_k \le -t\}}{\#\{w_k \ge t\}} \le \alpha\) where \(\alpha\) is the desired FDR level. Retain all features with \(w_k \ge t\).</p> <h1 id="screening-in-high-dimensions">Screening in High Dimensions</h1> <p>A notable challenge arises when the number of features \(p\) is large compared to the sample size \(n\) (i.e., \(2p&gt;n\)). In such high-dimensional settings, constructing knockoffs directly is infeasible. A common workaround is to:</p> <ul> <li>Pre-screen Features: Use a subset of the data to rank and reduce the feature set.</li> <li>Apply the knockoff filter: With the reduced set of features, generate knockoffs using the remaining samples (ensuring \(m &gt; 2d\), where \(d\) is the number of features after screening).</li> </ul> <p>This two-step approach helps maintain statistical power while ensuring robust FDR control.</p> <h1 id="references">References</h1> <ul> <li><a href="https://web.stanford.edu/group/candes/knockoffs/">Variable Selection with Knockoffs</a></li> <li><a href="https://proceedings.mlr.press/v151/poignard22a.html">B. Poignard, P. J. Naylor, H. Climente-González, M. Yamada, in International Conference on Artificial Intelligence and Statistics (PMLR, 2022), pp. 1935–1974.</a></li> </ul>]]></content><author><name></name></author><category term="fdr"/><category term="knockoffs"/><category term="feature_selection"/><summary type="html"><![CDATA[FDR-controlled feature selection]]></summary></entry><entry><title type="html">Random walks and Markov chains</title><link href="https://hclimente.github.io/blog/graphs-random-walks/" rel="alternate" type="text/html" title="Random walks and Markov chains"/><published>2025-01-27T11:59:00+00:00</published><updated>2025-01-27T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/graphs-random-walks</id><content type="html" xml:base="https://hclimente.github.io/blog/graphs-random-walks/"><![CDATA[<h1 id="random-walk">Random walk</h1> <p>A <strong>random walk (RW)</strong> is a <a href="https://en.wikipedia.org/wiki/Stochastic_process">stochastic</a>, discrete process. At every time step a walker, located in one of the graph’s vertices, picks one of its neighbors at random and moves to it. Often the transition probability between vertices is represented by the <strong>transition</strong> matrix \(P\), a normalized version of the <a href="/blog/graphs-linear-algebra/#adjacency-matrix">adjacency</a> in which the weights of all outbound edges add up to 1:</p> \[P = D^{-1} A\] <p>Note that \(P\) corresponds to a <a href="#markov-chains">row stochastic matrix</a>. The outcome of a single random walk is a <a href="/blog/graphs-glossary/#walk">walk</a> of length \(t\), where \(t\) is the number of steps. Let’s see how a random walk starting at vertex \(i\) plays out:</p> <ul> <li>At step 0, \(\mathbf{\pi}_0 = (0, 0, \cdots, 1, \cdots, 0)\). That is, \(\pi_0\) is an \(n\)-dimensional row vector that is \(0\) almost everywhere, with a \(1\) at component \(i\).</li> <li>At step 1, \(\mathbf{\pi}_{1} = \mathbf{\pi}_0 P\)</li> <li>At step 2, \(\mathbf{\pi}_{2} = \mathbf{\pi}_1 P = (\mathbf{\pi}_0 P) P = \mathbf{\pi}_0 P^2\)</li> <li>At step 3, \(\mathbf{\pi}_{3} = \mathbf{\pi}_2 P = (\mathbf{\pi}_0 P^2) P = \mathbf{\pi}_0 P^3\)</li> <li>…</li> <li>At step \(t\), \(\mathbf{\pi}_{t} = \mathbf{\pi}_0 P^t\)</li> </ul> <p>\(\pi_t\) is an \(n\)-dimensional row vector \(\mathbf{\pi}_t\) in which \(\pi_{tj}\) represents the probability of the walker starting at vertex \(i\) and being on vertex $j$ at time $t$.</p> <p>We might be interested in what happens if we let the random walk run indefinitely:</p> \[\lim_{t \to \infty} \mathbf{\pi}_{t} = \mathbf{\pi}_0 P^t\] <p>When taking powers of a matrix, it is useful to use its <a href="https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix">eigendecomposition</a>. After computing the eigenvectors (\(\mathbf{u}_1, \cdots, \mathbf{u}_n\)) and the eigenvalues (\(\lambda_1, \cdots, \lambda_n\)) of \(P\), we first expand \(\mathbf{\pi}_0\) in the eigenbasis:</p> \[\mathbf{\pi}_0 = c_1 \mathbf{u}_1 + c_2 \mathbf{u}_2 + \cdots + c_n \mathbf{u}_n\] <p>Then, for an arbitrary step \(t\):</p> \[\begin{multline*} \mathbf{\pi}_{t} = \mathbf{\pi}_0 P^t \\ = (c_1 \mathbf{u}_1 + \cdots + c_n \mathbf{u}_n) P^t \\ = c_1 \mathbf{u}_1 P^t + \cdots + c_n \mathbf{u}_n P^t \\ = c_1 \lambda^t_1 \mathbf{u}_1 + \cdots + c_n \lambda^t_n \mathbf{u}_n \end{multline*}\] <p>The eigenvalues of a stochastic matrix are always less than or equal to 1 in absolute value. When the random walk is <em>ergodic</em> (see below), \(P\) has an eigenvalue of 1 with an eigenvector \(\pi\) such that:</p> \[\pi_i = \frac {d_i} {\sum_j d_j}.\] <details><summary>Proof</summary> <p>The degree row-vector \(\mathbf{d} = ({d_1}, \cdots, d_n )\) is a left eigenvector of \(P\):</p> \[\mathbf{d} P = \mathbf{d} D^{-1} A = \mathbf{1} A = \mathbf{d}\] <p>where \(\mathbf{1}\) represents the row vector of all ones. That is, \(\mathbf{d}\) is an eigenvector with eigenvalue 1 and non-negative entries. In order to transform it into a valid probability distribution, we need to make sure that \(\sum_i \pi_i = 1\):</p> \[\pi = \frac 1 {\sum_i d_i} \mathbf{d}\] </details> <p>This is the stationary distribution of the random walk. It formalizes the intuitive result that high <a href="/blog/graph-properties/#degree">degree</a> vertices are more likely to be visited. If the graph is <a href="/blog/graphs-glossary/#regular">regular</a>, the stationary distribution is uniform. Note that this is a property of the matrix, and not of \(\pi_0\). This implies that the starting vertex is not important in the long run: if the random walk is allowed to run indefinitely, the probability of ending up in each vertex will converge to \(\pi\).</p> <blockquote> <p><strong>Ergodicity and <em>lazy</em> random walks:</strong> A unique stationary distribution does not always exists. A random walk is <em>ergodic</em> if a stationary distribution exists and is the same for any \(\pi_0\). For the random walk to be ergodic, the graph needs to be connected and non <a href="/blog/graphs-glossary/#bipartite-graph">bipartite</a>. If the graph has multiple components, starting in different components will produce different stationary distributions. If the graph is bipartite, at step \(t\) the walker will be on one side or another, depending on the initial vertex and the parity of \(t\). Bipartite graphs have a ergodic <a href="https://people.orie.cornell.edu/dpw/orie6334/Fall2016/lecture11.pdf"><em>lazy</em> random walk</a>, in which the walker has a probability \(\frac 1 2\) of remaining at the current vertex and a probability \(\frac 1 2\) of leaving it.</p> </blockquote> <details><summary>Connection to the Laplacian</summary> <p>The <a href="/blog/graphs-linear-algebra/#normalized-laplacian-matrices">Laplacian</a> and the transition matrices are deeply related:</p> \[L_{rw} = D^{-1}L = D^{-1}(D - A) = I - P\] <p>In fact, their eigenvectors and eigenvalues are connected. If \(\mathbf{u}\) is an eigenvector of \(P\), with eigenvalue \(\lambda\):</p> \[\mathbf{u} L_{rw} = \mathbf{u} (I - P) = \mathbf{u} - \mathbf{u} P = (1 - \lambda) \mathbf{u}\] <p>That is, \(P\) and \(L_{rw}\) have the same eigenvectors, and the eigenvalues are related as \(\lambda_i(L_{rw}) = 1 - \lambda_i(P)\). Since the <a href="/blog/graphs-linear-algebra/#connectivity-of-the-graph">smallest eigenvalue of \(L_{rw}\)</a> is 0, corresponding to the eigenvector \(\mathbf{1}\), \(P\) has an eigenvalue of \(1\) corresponding to that same eigenvector.</p> </details> <p>There are several remarks we can do:</p> <ul> <li>This result holds regardless of what the starting vertex is. In fact, \(\pi_0\) could be a probability distribution over the vertices.</li> <li>The <em>speed</em> at which the distribution converges depends on the eigenvalues of \(P\). Specifically, if \(\lambda_2\) is close to 1, the convergence will be slow.</li> </ul> <h1 id="random-walk-with-restart">Random walk with restart</h1> <p>In the <strong>random walk with restart (RWR)</strong>, the walker can return to its root vertex with a restart probability \(r \in [0, 1]\):</p> \[\mathbf{\pi}_{t+1} = r \mathbf{\pi}_0 + (1 - r) P \mathbf{\pi}_t\] <p>where \(\mathbf{\pi}_0\) represents the probability of starting at each vertex. If \(r = 0\), the walker will never be teleported back to the root, and a RW is equivalent to a RWR. If \(r = 1\), the walker will not be allowed to move out of the root, and \(\mathbf{\pi}_t = \mathbf{\pi}_0\). However, for certain values of $r$, the walker is allowed to explore the root’s neighborhood before teleporting back. If the root is part of a <a href="/blog/graphs-glossary/#module">module</a>, the walk will mostly happen within that module. If the root is very central, the walker will explore many parts of the network.</p> <p>Importantly, the RWR also has a stationary distribution \(\pi\):</p> \[\lim_{t \to \infty} \mathbf{\pi}_{t} = \pi\] <h1 id="markov-chains">Markov chains</h1> <p>A <strong>Markov chain</strong> is a sequence of events in which the probability of each event only depends on the state attained in the previous event. A random walk is a Markov chain: the probability of visiting a vertex depends only on the current vertex’s neighbors and the corresponding transition probabilities. We can describe some of the properties of a Markov chain by describing the underlying graph:</p> <ul> <li><em>Time reversibility</em></li> <li><em>Symmetry</em>: a Markov chain is symmetric when the underlying graph is <a href="/blog/graphs-glossary/#regular">regular</a>.</li> </ul> <p>In the context of Markov chains, the transition matrix \(P\) is known as the <strong>right stochastic matrix</strong>.</p> <details><summary>Types of stochastic matrices</summary> <ul> <li><strong><em>Row/right</em> stochastic matrix</strong>: square matrix with non-negative entries where each row sums to \(1\).</li> <li><strong><em>Column/left</em> stochastic matrix</strong>: square matrix with non-negative entries where each column sums to \(1\).</li> <li><strong><em>Doubly</em> stochastic matrix</strong>: square matrix with non-negative entries where each row and column sum to \(1\).</li> </ul> </details> <h1 id="further-reading">Further reading</h1> <ul> <li><a href="https://www.youtube.com/watch?v=8XJes6XFjxM">Full title: The Unreasonable Effectiveness of Spectral Graph Theory: A Confluence of Algorithms, Geometry, and Physics</a></li> </ul>]]></content><author><name></name></author><category term="graphs"/><category term="random_walks"/><category term="linear_algebra"/><summary type="html"><![CDATA[PageRank, MCMC, and others]]></summary></entry><entry><title type="html">Graphs and Linear Algebra</title><link href="https://hclimente.github.io/blog/graphs-linear-algebra/" rel="alternate" type="text/html" title="Graphs and Linear Algebra"/><published>2025-01-25T11:59:00+00:00</published><updated>2025-01-25T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/graphs-linear-algebra</id><content type="html" xml:base="https://hclimente.github.io/blog/graphs-linear-algebra/"><![CDATA[<p>In this article I discuss matrices associated to graphs. As we will see, a graph can be represented as a matrix without any information loss. Hence, the properties of these matrices describe <a href="/blog/graphs-basics/#properties-of-a-graph">properties of the underlying graph</a>.</p> <h1 id="matrices-associated-to-graphs">Matrices associated to graphs</h1> <p>A graph \(G = (V, E)\) s.t. \(V = \{v_1, \dots, v_n\}\) and \(E = \{e_1, \dots, e_m \}\) has several important associated matrices. For convenience, I often refer to vertex \(v_i\) simply by its index (\(i\)), and to an edge by the vertices it links (e.g., \(ij\)).</p> <p>I will show examples on the following graph, named \(G_1\):</p> <pre><code class="language-mermaid">---
config:
  layout: elk
  look: handDrawn
---
graph LR
    vertex_1((1))
    vertex_2((2))
    vertex_3((3))
    vertex_4((4))

    vertex_1 === vertex_2
    vertex_1 === vertex_3
    vertex_1 === vertex_4
    vertex_2 === vertex_3
</code></pre> <h2 id="degree-matrix">Degree matrix</h2> <p><a href="/blog/graphs-basics/#degree">Vertex degree</a> is ised to define the <strong>degree</strong> matrix \(D\) is a diagonal \(n \times n\) matrix such that \(D_{ii} = \deg i\), and 0 elsewhere. For instance, for \(G_1\):</p> \[\text{D}(G_1) = \begin{bmatrix} 3 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 2 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \\ \end{bmatrix}\] <h2 id="incidence-matrix">Incidence matrix</h2> <p><a href="/blog/graphs-glossary/#incidence">Incidence</a> is used to define the <strong>incidence</strong> matrix \(Q\), a \(n \times m\) matrix such that \(Q_{ij}\) equals:</p> <ul> <li>If \(G\) is <em>directed</em>: <ul> <li>\(0\) if vertex \(i\) and edge \(e_j\) are not incident</li> <li>\(1\) if edge \(e_j\) originates at vertex \(i\)</li> <li>\(-1\) if edge \(e_j\) terminates at vertex \(i\)</li> </ul> </li> <li>If \(G\) is <em>undirected</em>: <ul> <li>If \(Q\) is <em>unoriented</em>: <ul> <li>\(0\) if vertex \(i\) and edge \(e_j\) are not incident</li> <li>\(1\) otherwise</li> </ul> </li> <li>If \(Q\) is <em>oriented</em>: we pick an <a href="/blog/graphs-glossary/#orientation">orientation</a> of the graph, and use the incidence matrix of the resulting directed graph.</li> </ul> </li> </ul> <h2 id="adjacency-matrix">Adjacency matrix</h2> <p><a href="/blog/graphs-glossary/#adjacency">Adjacency</a> is used to define the <strong>adjacency</strong> matrix \(A\), a matrix \(n \times n\) such that the \(A_{ij}\) equals:</p> <ul> <li>\(0\) if vertices \(i\) and \(j\) are not adjacent (note that in simple graphs vertices are not self-adjacent)</li> <li>\(1\) otherwise</li> </ul> <p>For \(G_1\):</p> \[A = \begin{bmatrix} 0 &amp; 1 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1 &amp; 0 \\ 1 &amp; 1 &amp; 0 &amp; 0 \\ 1 &amp; 0 &amp; 0 &amp; 0 \\ \end{bmatrix}\] <p>The adjacency matrix relates to the concept of <a href="/blog/graphs-glossary/#path">paths</a> in an unweighted graph: \((A^k)_{ij}\) represents the number of paths of length \(k\) from vertex \(i\) to vertex \(j\). In a weighted graph, it represents the sum of products of weights. For instance, if edge weights represent transition probabilities, \((A^k)_{ij}\) represents the probability of starting a <a href="/blog/graphs-random-walks/">walk</a> at node \(i\) and ending at node \(j\) after \(k\) steps.</p> <h2 id="laplacian-matrix">Laplacian matrix</h2> <p>The <strong>Laplacian</strong> matrix \(L\) is a \(n \times n\) matrix such that the \(L_{ij}\) equals::</p> <ul> <li>For \(i \neq j\): <ul> <li>\(0\) if vertices \(i\) and \(j\) are not adjacent</li> <li>\(-1\) otherwise</li> </ul> </li> <li>For \(i = j\), the degree of \(i\).</li> </ul> <p>More concisely, \(L = D - A\). Or, given any oriented incidence matrix \(Q(G)\), \(L = QQ^T\).</p> <p>For \(G_1\):</p> \[L = D - A = \begin{bmatrix} 3 &amp; -1 &amp; -1 &amp; -1 \\ -1 &amp; 2 &amp; -1 &amp; 0 \\ -1 &amp; -1 &amp; 2 &amp; 0 \\ -1 &amp; 0 &amp; 0 &amp; 1 \\ \end{bmatrix}\] <p>The Laplacian relates to the connectedness of a graph, giving rise to <a href="#spectral-graph-theory">spectral graph theory</a>. It also is connected to <a href="/blog/graphs-glossary/#flow">flows</a>. The diagonal entries represent the total outflow capacity from a vertex, while off-diagonal entries encode pairwise connection strengths.</p> <h2 id="normalized-laplacian-matrices">Normalized Laplacian matrices</h2> <p>The presence of <a href="/blog/graphs-glossary/#hub">hubs</a> results in large diagonal entries in the Laplacian. There are normalized versions of the Laplacian that downweigh such vertices by dividing the entries by the vertex degree.</p> <p>The <strong>symmetrically</strong> normalized Laplacian \(L_\text{sym}\) is a symmetric matrix derived as follows:</p> \[L_\text{sym} = D^{-1/2}LD^{-1/2}\] <p>The <strong>random walk</strong> normalized Laplacian \(L_\text{rw}\) is a matrix closely related to <a href="/blog/graphs-random-walks/">random walks</a> that is derived as follows:</p> \[L_\text{rw} = D^{-1}L\] <h1 id="spectral-graph-theory">Spectral graph theory</h1> <p><strong>Spectral graph theory</strong> studies how the eigenvalues and eigenvectors of a graph’s associated matrices relate to its properties. Looking more closely at two of the matrices described above, we can see they have interesting properties:</p> <ul> <li>If \(G\) is undirected, \(A\) is both real and symmetric. Hence, it is diagonalizable and has only <em>real</em> values.</li> <li>Since for an undirected graph both \(D\) and \(A\) are symmetric, \(L\) is also real and symmetric. In fact, \(L\) is <strong>positive semi-definite</strong>. This implies that \(L\)’s eigenvalues are not only real, but also <em>non-negative</em>.</li> </ul> <p>Spectral graph theory often focuses on studying the eigenvalues of the Laplacian.</p> <h2 id="connectivity-of-the-graph">Connectivity of the graph</h2> <p>The eigenvectors of \(L\) are closely related to the connectivity of its associated graph.</p> <p>A simple, but ultimately insightful property of \(L\) is that, for an undirected graph, the sum over the rows or the columns equals 0. In other words, multiplying \(L\) by an all-ones vector \(\mathbf{1}\) results in the zero vector. This tells us that \(L\) has an eigenvalue of 0, corresponding to the eigenvector \(\mathbf{1}\). Separately, linear algebra tells us that since \(L\) is real and symmetric, it has <em>real</em> eigenvalues and <em>orthogonal</em> eigenvectors. And since \(L\) is positive semi-definite, its eigenvalues are <em>non-negative</em>. As we have just seen, the <a href="/blog/graphs-glossary/#first-k-eigenvectors">first eigenvalue</a>, \(\lambda_1\), of \(L\) is 0, corresponding to the \(\mathbf{1}\) eigenvector. If a vector has multiple <a href="/blog/graphs-glossary/#component">components</a>, \(L\) is block diagonal. This makes it easy to see that the indicator vectors, representing the membership of each vertex to one of the components, are eigenvectors with an eigenvalue of 0. This highlights another important property of the Laplacian: given an undirected graph, the multiplicity of the eigenvalue 0 of \(L\) equals the number of <a href="/blog/graphs-glossary/#component">components</a>. Conversely, for a <a href="/blog/graphs-glossary/#connected-graph">connected</a> graph, \(\lambda_2 &gt; 0\). (The second smallest eigenvalue is sometimes called the Fiedler eigenvalue.)</p> <p>More generally, less <em>smooth</em> eigenvectors (i.e., those in which consecutive elements change sharply) indicate a less connected. Equivalently, smaller eigenvalues correspond to smoother eigenvectors, and hence to better connected graphs.</p> <h2 id="spectral-clustering">Spectral clustering</h2> <p>The goal of <strong>spectral clustering</strong> is finding a partition of the graph into \(k\) groups such that the are densely/strongly connected with each other, and sparsely/weakly connected to the others. (If we consider <a href="/blog/graphs-random-walks/">random walks</a>, spectral clustering seeks a partition of the graph such that a random walker tends to stay within each partition, rarely shifting between disjoint sets.) An spectral clustering algorithm, in which seek to find <em>k</em> clusters, looks as follows:</p> <pre><code class="language-pseudocode">\begin{algorithm}
\caption{Spectral Clustering}
\begin{algorithmic}[1]
\PROCEDURE{GraphSpectralClustering}{$$A, k$$}
    \STATE $$n \gets \text{number of nodes (rows in A)}$$

    \STATE Compute degree matrix $$D$$ where $$D[i,i] = \sum_{j=1}^n A[i,j]$$
    \STATE $$D_{\text{sqrt-inv}} \gets \text{diag}(1/\sqrt{D[i,i]})$$
    \STATE $$L_{\text{sym}} \gets I - D_{\text{sqrt-inv}} A D_{\text{sqrt-inv}}$$ \COMMENT{Symmetric normalized Laplacian}

    \STATE Compute first $$k$$ eigenvectors $$u_1, \ldots, u_k$$ of $$L_{\text{sym}}$$
    \STATE Form matrix $$U \in \mathbb{R}^{n \times k}$$ with columns $$u_1, \ldots, u_k$$

    \FOR{$$i = 1$$ \TO $$n$$}
        \STATE $$U[i] \gets U[i] / \|U[i]\|$$ \COMMENT{Row normalization}
    \ENDFOR

    \STATE $$\text{labels} \gets \text{KMeans}(U, k)$$ \COMMENT{Cluster embedded nodes}
    \RETURN $$\text{labels}$$
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}
</code></pre> <blockquote> <p><strong>Note:</strong> spectral clustering is often applied as a clustering technique on datasets. The aim is to divide the observation into \(k\) groups based on their pairwise similarities. In that case, the first step consists on obtaining the graph. It will be a complete weighted graph in which the vertices are the different observations and the edges are weighted according to the similarity between each pair of vertices, as measured by an arbitrary function.</p> </blockquote> <h1 id="further-reading">Further reading</h1> <ul> <li><a href="https://people.csail.mit.edu/dsontag/courses/ml14/notes/Luxburg07_tutorial_spectral_clustering.pdf">A Tutorial on Spectral Clustering</a></li> <li><a href="https://mathweb.ucsd.edu/~fan/talks/mlg.pdf">Four graph partitioning algorithms</a></li> <li><a href="https://www.youtube.com/watch?v=uTUVhsxdGS8">Spectral Graph Theory For Dummies</a></li> <li><a href="https://www.youtube.com/watch?v=8XJes6XFjxM">Full title: The Unreasonable Effectiveness of Spectral Graph Theory: A Confluence of Algorithms, Geometry, and Physics</a></li> </ul>]]></content><author><name></name></author><category term="graphs"/><category term="linear_algebra"/><summary type="html"><![CDATA[Matrices associated to graphs and their properties]]></summary></entry><entry><title type="html">Properties of Graphs</title><link href="https://hclimente.github.io/blog/graph-properties/" rel="alternate" type="text/html" title="Properties of Graphs"/><published>2025-01-24T11:59:00+00:00</published><updated>2025-01-24T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/graph-properties</id><content type="html" xml:base="https://hclimente.github.io/blog/graph-properties/"><![CDATA[<p>At the most fundamental level, graphs are just entities and connections between them. Yet, the network topology gives rise to emergent properties. For instance, how information flows through a social network is partly a function who posts the message and how they are connected to the rest of the network, with their immediate connections being likely more important. In this section, I review three levels at which networks operate: <a href="#local-properties">local</a>, <a href="#mesoscale-properties">mesoscale</a> and <a href="#global-properties">global</a>. They refer, respectively, to properties of the nodes, properties of parts of the network and properties of the whole network.</p> <h1 id="local-properties">Local properties</h1> <h2 id="degree">Degree</h2> <p>In an undirected network, the <strong>degree</strong> of a vertex \(u\) (\(\deg u\)) refers to the number of edges that are incident on \(u\). In a directed network, this concept is split between <em>indegree</em> ([\(\deg^- u\)], the number of edges that have \(u\) as their destination) and <em>outdegree</em> ([\(\deg^+ u\)], number of edges that have \(u\) as their source). Weighted graphs extend this concept to <em>weighted</em> degree, in which \(\deg u = \sum_{i} w(e_{ui})\).</p> <h2 id="local-clustering-coefficient">Local clustering coefficient</h2> <p>The <strong>(local) clustering coefficient</strong> <em>of a vertex</em> measures the probability that its <a href="/blog/graphs-glossary/#neighborhood">neighbors</a> are connected. It is computed as the ratio between number of <a href="/blog/graphs-glossary/#triangle-graph">triangles</a> involving a vertex, and the number of <a href="/blog/graphs-glossary/#triplet">triplets</a> involving that same vertex.</p> <p><a href="https://r.igraph.org/reference/transitivity.html">Often</a>, the clustering coefficient of a directed graph is computed without considering the direction of the edges.</p> <h1 id="mesoscale-properties">Mesoscale properties</h1> <h2 id="modularity">Modularity</h2> <p>The <strong>modularity</strong> measures how well a graph can be divided into <a href="/blog/graphs-glossary/#modules">modules</a>. Given a partition of a graph into \(k\) modules, the modularity \(Q\) is computed as</p> \[Q = \sum_{i=1}^k (e_{ii} - {a_i^2})\] <p>where \(e_{ii} = \frac {\| \{\{u, v\} \mid u \in V_i, v \in V_i, \{u, v\} \in E \} \|} {\|E\|}\),\(a*i = \frac {\| \{\{u, v\} \mid u \in V_i, \{u, v\} \in E \} \|} {\|E\|}\) and \(V_i\) is the set of vertices in module \(i\). \(e*{ii}\) is the fraction of edges within module \(i\) and \(a_i\) is the fraction of edges incident with one vertex in module \(i\). \(Q\) will be large when the fraction of edges within the module is much larger than expected by chance.</p> <h2 id="within-module-degree">Within-module degree</h2> <p>The <strong>within-module degree</strong> of a vertex is the module version of the <a href="#degree">degree</a>. It is often normalized as a z-score; the z-score for node \(i\), mapped to module \(k\):</p> \[Z_i = \frac {\kappa_i - \bar \kappa_k} {\sigma_{\kappa_k}}\] <p>where \(\kappa_i\) is within-module degree (the number of edges between \(i\) and other vertices in module \(k\)); \(\bar \kappa_k\) is the average within-module degree; and \(\sigma_{\kappa_k}\) is the standard deviation of the within module degrees.</p> <h1 id="global-properties">Global properties</h1> <h2 id="radius-and-diameter">Radius and diameter</h2> <p>The radius and the diameter measure how easy it is to traverse a graph. They both are quantities based on the maximum <a href="/blog/graphs-glossary/#distance">distance</a> between any two vertices found in the graph. Specifically, the <strong>radius</strong> is the minimum maximum distance; the <strong>diameter</strong> is the maximum distance.</p> <h2 id="global-clustering-coefficient">Global clustering coefficient</h2> <p>The <strong>global clustering coefficient</strong> <em>of a graph</em> is the ratio between closed and open <a href="/blog/graphs-glossary/#triplet">triplets</a> in that graph. Or, equivalently:</p> \[C = \frac {3 \times \text{triangles}} {\text{triplets}}\] <p><a href="https://r.igraph.org/reference/transitivity.html">Often</a>, the clustering coefficient of a directed graph is computed without considering the direction of the edges.</p> <h2 id="centrality">Centrality</h2> <p><strong>Centrality</strong> assigns a score or a ranking to every vertex in the graph, which represents its importance in the network according to some metric. <a href="#degree">Degree</a> and <a href="#participation">participation</a> are examples of such metrics, but there are others.</p> <p>WIP</p>]]></content><author><name></name></author><category term="graphs"/><summary type="html"><![CDATA[Multiscale ways to talk about graphs]]></summary></entry><entry><title type="html">Introduction to Graphs</title><link href="https://hclimente.github.io/blog/graphs-basics/" rel="alternate" type="text/html" title="Introduction to Graphs"/><published>2025-01-23T11:59:00+00:00</published><updated>2025-01-23T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/graphs-basics</id><content type="html" xml:base="https://hclimente.github.io/blog/graphs-basics/"><![CDATA[<p>Graph theory was founded in the 18th century, with <a href="https://en.wikipedia.org/wiki/Leonhard_Euler">Euler’s</a> article on the <a href="https://en.wikipedia.org/wiki/Seven_Bridges_of_K%C3%B6nigsberg">Seven Bridges of Königsberg problem</a>. The city of Königsberg had seven bridges, connecting the north and south banks of the river, and two fluvial islands (Kneiphof and Lomse). Back then, Königsberg looked roughly like this:</p> <pre><code class="language-mermaid">---
config:
  layout: elk
  look: handDrawn
---
graph LR
    N[North Bank]
    K[Kneiphof Island]
    L[Lomse Island]
    S[South Bank]

    N === K
    N === K
    N === L
    S === L
    S === K
    S === K
    K === L
</code></pre> <p>The problem was to find a path such that a walker would cross each bridge exactly once. To solve this problem (by proving it had no solution), Euler found two useful abstractions: vertices representing land masses, and edges representing bridges. A key insight of framing the problem like this was that a graph can be represented in many ways (e.g., where to position the vertices), and all of them are equivalent. Euler’s theorem (yes, one of them) is the first theorem in graph theory, and proves that a graph with a number of vertices with an odd <a href="/blog/graph-properties/#degree">degree</a> other than 0 or 2 will have no <a href="/blog/graphs-glossary/#euler-circuit">Euler circuits</a> and no <a href="/blog/graphs-glossary/#euler-trail">Euler trails</a>.</p> <p>In the 21st century, we define graphs as sets of objects (vertices) and pairwise relations between them (edges). Graphs are also known as networks; vertices as nodes; and edges as links. Königsberg is a graph with 4 vertices and 6 edges. Importantly, graphs represent similarities between objects. In maths, <strong><a href="https://en.wikipedia.org/wiki/Equivalence_relation">equivalence</a></strong> formalize the notion than objects can have a relationship of “sameness”. An equivalence relation is a binary relation that is reflexive, transitive and symmetric. It is noted like \(\sim\). The epitome of equivalence relation is “is equal to”. For instance, \(2 = \frac 4 2 = \frac {2\pi} {\pi}\). “Is greater than” is an example of non-equivalence, since it does not meet the symmetric property (e.g., \(2 &gt; 1\) does not imply that \(1 &gt; 2\)). Since edges in a graph also capture this notion of “sameness” in some sense, they are tighly connected to equivalences: \(u \sim v\) implies that there is a <a href="/blog/graphs-glossary/#path">path</a> between vertices \(u\) and \(v\). Equivalently, \(u\) and \(v\) are in the same <a href="/blog/graphs-glossary/#component">component</a>.</p> <p>Importantly, graphs are mathematical objects. A graph \(G\) can be defined as</p> \[G = (V, E)\] <p>Where \(V\) denotes the set of vertices and \(E\) the set of edges (pairs of vertices).</p> <blockquote> <p><strong><em>Notation note:</em></strong> \(V\) and \(E\) above refer sets, specifically to the vertex and edge set of a specific graph (\(G\)). Note that they are in italics. In contrast, the \(\text{V}\) in \(\text{V}(H)\) and \(\text{V}(I)\) refer to the vertex sets of graphs \(H\) and \(I\) respectively. Note that they are not in italics. I will follow the same convention elsewhere, e.g. when writing about <a href="/blog/graphs-linear-algebra/">graph’s matrices</a>.</p> </blockquote> <p>This notation allows to concisely define multiple types of graph:</p> <ul> <li> <p>Undirected graph: \(E \subseteq \{ \{u, v\} \mid u, v \in V \}\), i.e., the edges do not have directions.</p> <pre><code class="language-mermaid">---
config:
layout: elk
look: handDrawn
---
graph LR

    vertex_a((a))
    vertex_b((b))
    vertex_c((c))

    vertex_a === vertex_b
    vertex_a === vertex_c
    vertex_b === vertex_c
</code></pre> </li> <li> <p>Directed graphs: \(E \subseteq \{ (u, v) \mid u, v \in V \}\), i.e., the edges have directions.</p> <pre><code class="language-mermaid">---
config:
layout: elk
look: handDrawn
---
graph LR

    vertex_a((a))
    vertex_b((b))
    vertex_c((c))

    vertex_a --&gt; vertex_b
    vertex_a --&gt; vertex_c
    vertex_b --&gt; vertex_c
</code></pre> </li> </ul> <p>Sometimes, graphs are defined as triples. An example are <a href="/blog/graphs-glossary/#multigraph"><strong>multigraphs</strong></a>, graphs in which multiple edges between the same pair of vertices are allowed. They are triples \(G = (V, E, \phi)\) in which the incidence function \(\phi\) represents the mapping from edges to pairs of vertices. Königsberg is an example of multigraph, since it has multiple bridges connecting the same landmasses (e.g., the North Bank and the Kneiphof Island). For instance, the Königsberg graph is an undirected multigraph with:</p> \[V = \{N, K, L, S \}\] \[E = \{ e_1, e_2, e_3, e_4, e_5, e_6, e_7 \}\] \[\phi(x) = \begin{cases} \{ N, K \} &amp; \text{if $x = e_1$} \\ \{ N, K \} &amp; \text{if $x = e_2$} \\ \{ N, L \} &amp; \text{if $x = e_3$} \\ \{ S, L \} &amp; \text{if $x = e_4$} \\ \{ S, K \} &amp; \text{if $x = e_5$} \\ \{ S, K \} &amp; \text{if $x = e_6$} \\ \{ K, L \} &amp; \text{if $x = e_7$} \\ \end{cases}\] <p>Another type of graph that requires a triple are <strong>weighted</strong> graphs, in which each edge has a weight. They are triples \(G = (V, E, w)\) in which \(w\) is a function that maps edges to their weights. Note that weighted multigraph would be a quadruple, since it would require both an incidence and a weight functions.</p> <blockquote> <p><strong>Note:</strong> unless specified otherwise, in this series I will focus on <a href="/blog/graphs-glossary/#simple-graph"><em>simple</em></a> graphs, which have at most one edge between any pair of vertices and no loops.</p> </blockquote> <h1 id="further-reading">Further reading</h1> <ul> <li><a href="https://arxiv.org/abs/2308.04512">An introduction to graph theory</a></li> </ul>]]></content><author><name></name></author><category term="graphs"/><summary type="html"><![CDATA[Basic definitions]]></summary></entry><entry><title type="html">Graph Glossary</title><link href="https://hclimente.github.io/blog/graphs-glossary/" rel="alternate" type="text/html" title="Graph Glossary"/><published>2025-01-23T11:59:00+00:00</published><updated>2025-01-23T11:59:00+00:00</updated><id>https://hclimente.github.io/blog/graphs-glossary</id><content type="html" xml:base="https://hclimente.github.io/blog/graphs-glossary/"><![CDATA[<h1 id="parts-of-a-graph">Parts of a graph</h1> <h2 id="component">Component</h2> <p>In an <a href="#undirected-graph">undirected</a> graph, a <a href="#connected-graph">connected</a> <a href="#subgraph">subgraph</a> that is not part of a larger connected subgraph.</p> <h2 id="circuit">Circuit</h2> <p>A <a href="#trail">trail</a> in which the first and last vertices are equal. In contrast to the <a href="#cycle">cycle</a>, any vertex can be repeated.</p> <h2 id="cycle">Cycle</h2> <p>A <a href="#trail">trail</a> in which <em>only</em> the first and last vertices are equal. Except for the tails and in contrast to the <a href="#circuit">circuit</a>, vertices cannot be repeated.</p> <h2 id="euler-circuit">Euler circuit</h2> <p>A <a href="#circuit">circuit</a> that visits every edge of the graph.</p> <h2 id="euler-trail">Euler trail</h2> <p>A <a href="#trail">trail</a> that visits every edge of the graph.</p> <h2 id="flow">Flow</h2> <p>An example of a flow is a heat diffusion process across a graph. In such processes, each vertex starts with a certain amount of heat and, at each time point, exchanges heat with its <a href="#neighborhood">neighbors</a> (gains heat from its hotter neighbors; loses it to its colder neighbors).</p> <h2 id="module">Module</h2> <p>A <a href="#subgraph">subgraph</a> whose vertices are densely connected to each other, and loosely to the rest of the graph.</p> <h2 id="orientation">Orientation</h2> <p>An orientation of an <a href="#undirected-graph">undirected</a> graph is the <a href="#directed-graph">directed</a> graph resulting of assigning a direction to each of its vertices. A <a href="#directed-graph">directed</a> graph is oriented if no two vertices form a 2-cycle.</p> <h2 id="path">Path</h2> <p>A <a href="#walk">walk</a> with no repeated <em>vertices</em>.</p> <h2 id="spanning-graph">Spanning graph</h2> <p>A subgraph \(G' = (V', E')\) of \(G = (V, E)\) is spanning if \(V' = V\).</p> <h2 id="subgraph">Subgraph</h2> <p>A graph resulting from subsetting vertices from a larger graph, as well as a subset of the edges connecting them.</p> <h3 id="induced-subgraph">Induced subgraph</h3> <p>A <a href="#subgraph">subgraph</a> containing <em>all</em> the edges connecting the vertices in the original graph.</p> <h2 id="trail">Trail</h2> <p>A <a href="#walk">walk</a> with no repeated <em>edges</em>.</p> <h2 id="triplet">Triplet</h2> <p>A set of 3 vertices and at least 2 edges between them, none of which are redundant or loops. <em>Open</em> triplets have exactly 2 edges; <em>closed</em> triplets have exactly 3.</p> <h2 id="walk">Walk</h2> <p>A walk <em>on a graph</em> is an alternating sequence of vertices and edges, such that every vertex is <a href="#incidence">incident</a> with the previous and the following edge (if any).</p> <h1 id="properties-of-vertices">Properties of vertices</h1> <h2 id="adjacency">Adjacency</h2> <p>A vertex is adjacent with <em>another vertex</em> if they are connected by an edge. \(u \sim v\) denote that \(u\) and \(v\) are adjacent.</p> <h2 id="degree">Degree</h2> <p>The degree of a vertex in a (simple) <a href="#undirected-graph">undirected</a> graph is the number of edges <a href="#incidence">incident</a> with that vertex. In a (simple) <a href="#directed-graph">directed</a> graph we distinguish the indegree (number of edges with the vertex as their <a href="#destination">destination</a>) and the outdegree (number of edges with the vertex as their <a href="#source">source</a>).</p> <h2 id="destination">Destination</h2> <p>In a <a href="#directed-graph">directed</a> graph, the destination <em>of an edge</em> is the vertex at the head of the edge.</p> <h2 id="distance">Distance</h2> <p>The distance <em>between two vertices</em> is the shortest <a href="#path">path</a> between them.</p> <h2 id="hub">Hub</h2> <p>A vertex with a high <a href="#degree">degree</a>.</p> <h2 id="neighborhood">Neighborhood</h2> <p>The neighborhood of vertex \(v\) is the <a href="#induced-subgraph">induced subgraph</a> containing all the vertices <a href="#adjacency">adjacent</a> to \(v\).</p> <h2 id="incidence">Incidence</h2> <p>A vertex is incident <em>with an edge</em> if the vertex is one of the two vertices the edge connects.</p> <h2 id="source">Source</h2> <p>In a <a href="#directed-graph">directed</a> graph, the source <em>of an edge</em> is the vertex at the tail of the edge.</p> <h1 id="types-of-graphs">Types of graphs</h1> <h2 id="acyclical-graph">Acyclical graph</h2> <p>A graph without <a href="#cycle">cycles</a>.</p> <h2 id="bipartite-graph">Bipartite graph</h2> <p>A <a href="#acyclical-graph">acyclical</a> graph whose vertices can be divided into two sets such that no pair of vertices in the same set are <a href="#adjacency">adjacent</a>. Often, each of these sets are referred to as colors, and so we say that “there is no edge between two vertices of the same color.”</p> <h2 id="complete-graph">Complete graph</h2> <p>A simple, <a href="#undirected-graph">undirected</a> graph in which every pair of vertices are connected by an edge. Complete graph are usually denoted by letter \(K\) with a subindex that indicates the total number of vertices. For instance, \(K_6\) represents the complete graph with 6 vertices.</p> <h2 id="connected-graph">Connected graph</h2> <p>A graph in which a <a href="#path">path</a> exists between every pair of vertices.</p> <h2 id="digraph">Digraph</h2> <p>A <a href="#directed-graph">directed</a> graph.</p> <h2 id="directed-graph">Directed graph</h2> <p>See <a href="/blog/graphs-basics/">Introduction to Graphs</a>.</p> <h2 id="forest">Forest</h2> <p>An <a href="#undirected-graph">undirected</a> graph in which any two vertices are connected by at most one path. That is, a disjoint union of <a href="#tree">trees</a>.</p> <h2 id="multigraph">Multigraph</h2> <p>A graph which can have multiple edges between the same pair of vertices.</p> <h2 id="regular">Regular</h2> <p>A graph in which every vertex has the same degree.</p> <h2 id="simple-graph">Simple graph</h2> <p>A graph with at most one edge between any pair of vertices and no loops.</p> <h2 id="tree">Tree</h2> <p>An <a href="#undirected-graph">undirected</a> graph in which there is only one <a href="#path">path</a> between every pair of nodes.</p> <h2 id="triangle-graph">Triangle graph</h2> <p>A <a href="#triplet">triplet</a> with 3 edges. It consists of <em>three</em> closed triplets, each centered around each of the vertices.</p> <h2 id="undirected-graph">Undirected graph</h2> <p>See <a href="/blog/graphs-basics/">Introduction to Graphs</a>.</p> <h1 id="spectral-graph-theory">Spectral graph theory</h1> <h2 id="first-k-eigenvectors">First <em>k</em> eigenvectors</h2> <p>Eigenvectors associated with the <em>k</em> smallest eigenvalues.</p>]]></content><author><name></name></author><category term="graphs"/><summary type="html"><![CDATA[Definitions of frequent graph terms]]></summary></entry></feed>