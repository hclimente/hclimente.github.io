<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Graphs and Linear Algebra | Héctor Climente-González </title> <meta name="author" content="Héctor Climente-González"> <meta name="description" content="Matrices associated to graphs and their properties"> <meta name="keywords" content="machine-learning, genetics, pharma, drug-discovery, climente, climente-gonzalez"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@2.4.1/build/pseudocode.min.css" integrity="sha256-VwMV//xgBPDyRFVSOshhRhzJRDyBmIACniLPpeXNUdc=" crossorigin="anonymous"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%AA%A2&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hclimente.github.io/blog/graphs-linear-algebra/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Héctor</span> Climente-González </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">Graphs and Linear Algebra</h1> <p class="post-meta"> Created in January 25, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/graphs"> <i class="fa-solid fa-hashtag fa-sm"></i> graphs</a>   <a href="/blog/tag/linear-algebra"> <i class="fa-solid fa-hashtag fa-sm"></i> linear_algebra</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>In this article I discuss matrices associated to graphs. As we will see, a graph can be represented as a matrix without any information loss. Hence, the properties of these matrices describe <a href="../graphs-basics#properties-of-a-graph">properties of the underlying graph</a>.</p> <h1 id="matrices-associated-to-graphs">Matrices associated to graphs</h1> <p>A graph \(G = (V, E)\) s.t. \(V = \{v_1, \dots, v_n\}\) and \(E = \{e_1, \dots, e_m \}\) has several important associated matrices. For convenience, I often refer to vertex \(v_i\) simply by its index (\(i\)), and to an edge by the vertices it links (e.g., \(ij\)).</p> <p>I will show examples on the following graph, named \(G_1\):</p> <pre><code class="language-mermaid">---
config:
  layout: elk
  look: handDrawn
---
graph LR
    vertex_1((1))
    vertex_2((2))
    vertex_3((3))
    vertex_4((4))

    vertex_1 === vertex_2
    vertex_1 === vertex_3
    vertex_1 === vertex_4
    vertex_2 === vertex_3
</code></pre> <h2 id="degree-matrix">Degree matrix</h2> <p><a href="../graphs-basics#degree">Vertex degree</a> is ised to define the <strong>degree</strong> matrix \(D\) is a diagonal \(n \times n\) matrix such that \(D_{ii} = \deg i\), and 0 elsewhere. For instance, for \(G_1\):</p> \[\text{D}(G_1) = \begin{bmatrix} 3 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 2 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \\ \end{bmatrix}\] <h2 id="incidence-matrix">Incidence matrix</h2> <p><a href="../graphs-glossary#incidence">Incidence</a> is used to define the <strong>incidence</strong> matrix \(Q\), a \(n \times m\) matrix such that \(Q_{ij}\) equals:</p> <ul> <li>If \(G\) is <em>directed</em>: <ul> <li>\(0\) if vertex \(i\) and edge \(e_j\) are not incident</li> <li>\(1\) if edge \(e_j\) originates at vertex \(i\)</li> <li>\(-1\) if edge \(e_j\) terminates at vertex \(i\)</li> </ul> </li> <li>If \(G\) is <em>undirected</em>: <ul> <li>If \(Q\) is <em>unoriented</em>: <ul> <li>\(0\) if vertex \(i\) and edge \(e_j\) are not incident</li> <li>\(1\) otherwise</li> </ul> </li> <li>If \(Q\) is <em>oriented</em>: we pick an <a href="../graphs-glossary#orientation">orientation</a> of the graph, and use the incidence matrix of the resulting directed graph.</li> </ul> </li> </ul> <h2 id="adjacency-matrix">Adjacency matrix</h2> <p><a href="../graphs-glossary#adjacency">Adjacency</a> is used to define the <strong>adjacency</strong> matrix \(A\), a matrix \(n \times n\) such that the \(A_{ij}\) equals:</p> <ul> <li>\(0\) if vertices \(i\) and \(j\) are not adjacent (note that in simple graphs vertices are not self-adjacent)</li> <li>\(1\) otherwise</li> </ul> <p>For \(G_1\):</p> \[A = \begin{bmatrix} 0 &amp; 1 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1 &amp; 0 \\ 1 &amp; 1 &amp; 0 &amp; 0 \\ 1 &amp; 0 &amp; 0 &amp; 0 \\ \end{bmatrix}\] <p>The adjacency matrix relates to the concept of <a href="../graphs-glossary#path"><strong>paths</strong></a> in an unweighted graph: \((A^k)_{ij}\) represents the number of paths of length \(k\) from vertex \(i\) to vertex \(j\). In a weighted graph, it represents the sum of products of weights. For instance, if edge weights represent transition probabilities, \((A^k)_{ij}\) represents the probability of starting a walk at node \(i\) and ending at node \(j\) after \(k\) steps.</p> <p>The adjacency matrix has some important properties:</p> <ul> <li>If \(G\) is undirected, \(A\) is symmetric</li> </ul> <h2 id="laplacian-matrix">Laplacian matrix</h2> <p>The <strong>Laplacian</strong> matrix \(L\) is a \(n \times n\) matrix such that the \(L_{ij}\) equals::</p> <ul> <li>For \(i \neq j\): <ul> <li>\(0\) if vertex \(i\) and edge \(j\) are not adjacent</li> <li>\(-1\) otherwise</li> </ul> </li> <li>For \(i = j\), the degree of \(i\).</li> </ul> <p>More concisely, \(L = D - A\). Or, given any oriented incidence matrix \(Q(G)\), \(L = QQ^T\).</p> <p>For \(G_1\):</p> \[L = D - A = \begin{bmatrix} 3 &amp; -1 &amp; -1 &amp; -1 \\ -1 &amp; 2 &amp; -1 &amp; 0 \\ -1 &amp; -1 &amp; 2 &amp; 0 \\ -1 &amp; 0 &amp; 0 &amp; 1 \\ \end{bmatrix}\] <p>The Laplacian relates to the connectedness of a graph, giving rise to <a href="#spectral-graph-theory">spectral graph theory</a>. It also is connected to <a href="../graphs-glossary#flow"><em>flows</em></a>. The diagonal entries represent the total outflow capacity from a vertex, while off-diagonal entries encode pairwise connection strengths.</p> <p>The Laplacian matrix has some important properties:</p> <ul> <li>If \(G\) is undirected, \(L\) is symmetric and positive semi-definite.</li> <li>\(L\) has \(n\) non-negative, real-valued eigenvalues.</li> </ul> <h2 id="normalized-laplacian-matrices">Normalized Laplacian matrices</h2> <p>\(L_\text{sym}\) is a symmetric matrix derived from \(L\) as follows:</p> \[L_\text{sym} = D^{-1/2}LD^{-1/2}\] <p>\(L_\text{rw}\) is a matrix closely related to random walks that is derived from \(L\) as follows:</p> \[L_\text{rw} = D^{-1}L\] <h1 id="spectral-graph-theory">Spectral graph theory</h1> <p><strong>Spectral graph theory</strong> study how the eigenvalues and eigenvectors of a graph’s associated matrices relate to its properties. Specifically, the eigenvalues of the Laplacian are closely related to the connectivity of the associated graph.</p> <h2 id="number-of-connected-components">Number of connected components</h2> <p>A simple, but ultimately insightful property of \(L\) is that, for an undirected graph, the sum over the rows or the columns equals 0. In other words, multiplying \(L\) by an all-ones vector \(\mathbf{1}\) results in the zero vector. This tells us that \(L\) has an eigenvalue of 0, corresponding to the eigenvector \(\mathbf{1}\). Separately, linear algebra tells us that since \(L\) is real and symmetric, it has <em>real</em> eigenvalues and <em>orthogonal</em> eigenvectors. And since \(L\) is positive semi-definite, its eigenvalues are <em>non-negative</em>. As we have just seen, the <a href="../graphs-glossary#first-k-eigenvectors">first eigenvalue</a>, \(\lambda_1\), of \(L\) is 0, corresponding to the \(\mathbf{1}\) eigenvector. If a vector has multiple <a href="../graphs-glossary#component">components</a>, \(L\) is block diagonal. This makes it easy to see that the indicator vectors, representing the membership of each vertex to one of the components, are eigenvectors with an eigenvalue of 0. This highlights another important property of the Laplacian: given an undirected graph, the multiplicity of the eigenvalue 0 of \(L\) equals the number of <a href="../graphs-glossary#component">components</a>. Conversely, for a <a href="../graphs-glossary#connected-graph">connected</a> graph, \(\lambda_2 &gt; 0\). (The second smallest eigenvalue is sometimes called the Fiedler eigenvalue.)</p> <h2 id="spectral-clustering">Spectral clustering</h2> <p>The goal of <strong>spectral clustering</strong> is finding a partition of the graph into \(k\) groups such that the are densely/strongly connected with each other, and sparsely/weakly connected to the others. (If we consider <a href="#random-walks-and-markov-chains">random walks</a>, spectral clustering seeks a partition of the graph such that a random walker tends to stay within each partition, rarely shifting between disjoint sets.) An spectral clustering algorithm, in which seek to find <em>k</em> clusters, looks as follows:</p> <pre><code class="language-pseudocode">\begin{algorithm}
\caption{Spectral Clustering}
\begin{algorithmic}[1]
\PROCEDURE{GraphSpectralClustering}{$$A, k$$}
    \STATE $$n \gets \text{number of nodes (rows in A)}$$

    \STATE Compute degree matrix $$D$$ where $$D[i,i] = \sum_{j=1}^n A[i,j]$$
    \STATE $$D_{\text{sqrt-inv}} \gets \text{diag}(1/\sqrt{D[i,i]})$$
    \STATE $$L_{\text{sym}} \gets I - D_{\text{sqrt-inv}} A D_{\text{sqrt-inv}}$$ \COMMENT{Symmetric normalized Laplacian}

    \STATE Compute first $$k$$ eigenvectors $$u_1, \ldots, u_k$$ of $$L_{\text{sym}}$$
    \STATE Form matrix $$U \in \mathbb{R}^{n \times k}$$ with columns $$u_1, \ldots, u_k$$

    \FOR{$$i = 1$$ \TO $$n$$}
        \STATE $$U[i] \gets U[i] / \|U[i]\|$$ \COMMENT{Row normalization}
    \ENDFOR

    \STATE $$\text{labels} \gets \text{KMeans}(U, k)$$ \COMMENT{Cluster embedded nodes}
    \RETURN $$\text{labels}$$
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}
</code></pre> <blockquote> <p><strong>Note:</strong> spectral clustering is often applied as a clustering technique on datasets. The aim is to divide the observation into \(k\) groups based on their pairwise similarities. In that case, the first step consists on obtaining the graph. It will be a complete weighted graph in which the vertices are the different observations and the edges are weighted according to the similarity between each pair of vertices, as measured by an arbitrary function.</p> </blockquote> <h2 id="graph-partitioning">Graph partitioning</h2> <p>TODO</p> <h1 id="graph-fourier-transform">Graph Fourier Transform</h1> <p>TODO</p> <h1 id="further-reading">Further reading</h1> <ul> <li><a href="https://people.csail.mit.edu/dsontag/courses/ml14/notes/Luxburg07_tutorial_spectral_clustering.pdf" rel="external nofollow noopener" target="_blank">A Tutorial on Spectral Clustering</a></li> <li><a href="https://mathweb.ucsd.edu/~fan/talks/mlg.pdf" rel="external nofollow noopener" target="_blank">Four graph partitioning algorithms</a></li> </ul> </div> </article> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'hclimente/hclimente.github.io',
        'data-repo-id': '',
        'data-category': 'Comments',
        'data-category-id': '',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 Héctor Climente-González. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/mermaid@10.7.0/dist/mermaid.min.js" integrity="sha256-TtLOdUA8mstPoO6sGvHIGx2ceXrrX4KgIItO06XOn8A=" crossorigin="anonymous"></script> <script defer src="/assets/js/mermaid-setup.js?38ca0a0126f7328d2d9a46bad640931f" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/pseudocode-setup.js?72ed28a041e322f764b0d9c59cf428b5"></script> <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/pseudocode@2.4.1/build/pseudocode.min.js" integrity="sha256-aVkDxqyzrB+ExUsOY9PdyelkDhn/DfrjWu08aVpqNlo=" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>