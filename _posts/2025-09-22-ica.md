---
layout: distill
title: Independent Component Analysis
date: 2025-09-22 11:59:00 +0000
description: Cocktail parties make me anxious
tags:
  - linear_algebra
  - statistics
giscus_comments: true
related_posts: false
---

Deconvolution: simplify multidimensional datasets into a reduced number of factors (usually a linear combination of them). E.g. gene expression can be expressed as the combination of factors that regulate them. One approach to this problem are **matrix factorization**, which aim to decompose our original matrix $$X$$ into a product of matrices. Often the matrix is decomposed into two matrices: $$X = W S$$. $$W$$, the weighting matrix, represents the new basis vectors, which better capture the geometry of the data. $$S$$, the score matrix, represents the coordinates of each datapoint in that new basis.

{% include figure.liquid path="assets/img/posts/2025-09-22-ica/change_of_basis.webp" class="img-fluid" %}

<div class="caption">
    Illustration of a change of basis, such that each basis vector describes one of three subgroups of points. Note that the underlying data remains unchanged.
</div>

As you would have guessed, what "better capturing the geometry of the data" means exactly is up for debate. But, in general, it involves helping with interpretability, data compression, or parsimony. Unsurprisingly, many solutions have been proposed to this problem. A well-known one is the principal component analysis, or PCA. Geometrically speaking, PCA fits an ellipsoid to the data, and uses the axis of this ellipsoid as the basis for the new space. This is equivalent to PCA's traditional interpretation: capturing the main axes of variation on the data. However, PCA doesn't account for potential substructures of the data. When these are present, if will fail miserably:

{% include figure.liquid path="assets/img/posts/2025-09-22-ica/pca_overview.webp" class="img-fluid" %}

<div class="caption">
    Illustration of the principal component analysis on well-behaved data (A) and on data with substructures (B). Note that in the latter case, the new basis is not particularly well-suited to represent the data.
</div>

This is the case in with **independent component analysis (ICA)** shines.

{% include figure.liquid loading="eager" path="assets/python/2025-09-22-ica/img/ica_pca_sklearn_example.webp" class="img-fluid" %}

<div class="caption">
    ICA and PCA applied to a synthetic dataset. Adapted from the <a href="https://scikit-learn.org/stable/auto_examples/decomposition/plot_ica_vs_pca.html#sphx-glr-auto-examples-decomposition-plot-ica-vs-pca-py">scikit-learn documentation</a>.
</div>

# Background

By design, PCA seeks an uncorrelated basis, since the axes of the ellipsoid need to be orthogonal. ICA goes one step further: it seeks a **statistically independent** basis.

{% details The cocktail party problem %}

The cocktail party problem is a well-known problem in signal processing, and the one ICA is supposed to solve best. In a cocktail many things are happening, and some spies try to get everything that's happening through microphones. Each microphone will get a mixture of all the signals. But they want to separate them. They use ICA for that. Equivalently, gene expression is a mixture of many individual sources.

{% enddetails %}

In ICA, we identify different non-gaussian tails of the distribution.

# Implementation: FastICA

[FastICA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.FastICA.html) is one of the most popular algorithms to conduct ICA. Steps:

1. Define data dimensionality *k*.
2. Whitening of the data: remove all gaussian signals. The variance in all dimensions become unity. We are assuming that everything that is Gaussian is noise of some kind
3. ...

We rank the independent components according to their consistency (apparently there is a random step?).

X is an approximation of the data.

X = AS

A table of metagenes.
S table of metasamples.

Metagene interpretation: geneset enrichment analysis, hypergeometric test, correlations with properties of the genes...
Metasample interpretation: look at data of the patients e.g. match known cancer subtypes, study other tests on the same patient e.g. histopathological samples (e.g. rank them by the weight and checking if there is any trend).
