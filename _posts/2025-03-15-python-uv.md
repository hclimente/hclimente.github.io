---
layout: post
title: uv for data scientists
date: 2025-03-15 11:59:00-0000
description: Python environments, project management & more
tags: python coding
giscus_comments: true
related_posts: false
toc:
  sidebar: left
---

Python veterans will be familiar with `pip`, `poetry`, `pyenv`, `conda` and a few other tools for managing projects, packages and environments. [`uv`](https://github.com/astral-sh/uv)'s goal is to replace them all while being blazingly fast. Let's see how it works.

# First steps

We will use `uv` for a prototypical machine learning project: train a neural network to classify images of handwritten digits from the [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) using a [convolutional neural network](https://en.wikipedia.org/wiki/Convolutional_neural_network). The input of the model will be a 28x28 pixel image, and the output will be a vector of 10 probabilities, one for each digit. If you are interested in the details of the model, you can check out the [code](https://github.com/hclimente/hclimente.github.io/tree/main/assets/python/2025-03-15-python-uv/mnist-classifier).

{% include figure.liquid loading="eager" path="assets/python/2025-03-15-python-uv/mnist-classifier/img/mnist_examples.webp" class="img-fluid rounded z-depth-1" %}

When we start a new project, we simply need to run `uv init`.

```bash
uv init mnist-classifier
```

This creates a directory `mnist-classifier` in the current directory containing a few files; we'll see them in more detail later. Furthermore, it will start a git repository, with a sensible `.gitignore`.

By default, `init` creates an _application_ project. This is appropriate for scripts, like simple tools. This is why the command above created a `main.py` file, meant to be the entry point of our application. Alternatively, we could create a _library_ project with `uv init --package mnist-classifier-pkg`. This would create a new directory `mnist-classifier-pkg` and populate it with a standard structure and configuration suitable for a Python library.

## Project configuration

`uv init` creates a [`pyproject.toml`](https://packaging.python.org/en/latest/guides/writing-pyproject-toml/) to store the project's metadata. This is a standard file used by other tools like [`poetry`](https://python-poetry.org/) and [`pip`](https://pip.pypa.io). For instance `pip install .` would install all the packages listed under the `dependencies` field. The `pyproject.toml` file created by `uv` looks like this:

```toml
[project]
name = "mnist-classifier"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.10"
dependencies = []
```

`uv` commands will update this file when needed (e.g., when [adding a dependency](#uninstalling-packages)).

# Handling environments

Multiple Python projects can be run on the same machine, and they can depend on different versions of the same package. This is solved by creating _virtual environments_. These are self-contained directories containing a Python interpreter and an independent set of Python packages. There are multiple solutions to create and manage virtual environments, like [`venv`](https://docs.python.org/3/library/venv.html), [`conda`](https://anaconda.org/anaconda/conda) or [`poetry`](https://python-poetry.org/).

`uv` leverages Python's native support for different environments: `venv`. The virtual environment contains its own installation of Python, whose version is specified in `.python-version`. `uv init` created this file:

```
3.10
```

The virtual environment packages live in the `.venv` directory. When Python runs from within an environment, it uses the packages installed in that environment, and only those packages. Typically, we would activate this environment from `zsh` with `source .venv/bin/activate`, which would append `.venv/bin/` into our `PATH`, loading the `python` located there into our environment. However `uv` does not require explicitly activating the environment. Instead, it uses the `uv run` command to run any Python script or command using the environment's Python. For instance, `uv init` created a short, example script `main.py`:

```python
def main():
    print("Hello from mnist-classifier!")


if __name__ == "__main__":
    main()
```

As stated, we can run it using our default Python, as we are used to (`python main.py`), maybe after loading the relevant environment. But we can also run it using `uv run main.py`. This offers two conveniences. First, we do not need to load and unload environments, reducing effort and the probability of error. Second, if the project environment does not exist, it will create it. If it exists, `uv` will ensure it is up to date. Then, it runs `main.py` using its Python. Similarly, we can run an interactive Python session via `uv run python`.

# (Un)installing packages

Upon its first run, `uv run main.py` created a virtual environment. To do this, it examined the (empty) `dependencies` list in `pyproject.toml` and resolved an (empty) set of packages. `uv` records this exact state in the `uv.lock` file, detailing the specific package resolutions. Let's get a better understanding of how `uv` handles environments by installing the [`PyTorch`](https://pytorch.org/) package. Typically we would run `pip install torch`; but in `uv` we would use `uv add torch` instead. This installs the most recent version of the package that is compatible with our environment (2.7.0). In this process, `pyproject.toml` gets updated to:

```toml
dependencies = [
    "torch>=2.7.0",
]
```

This adds a general specification of environment that our project depends on. But `uv.lock` is also updated with considerably more thorough specification. Specifically, it expanded to 353 lines describing all the specific packages, their versions and the metadata that were installed in the environment. This is a small excerpt of the file:

```toml
[[package]]
name = "filelock"
version = "3.18.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/0a/10/c23352565a6544bdc5353e0b15fc1c563352101f30e24bf500207a54df9a/filelock-3.18.0.tar.gz", hash = "sha256:adbc88eabb99d2fec8c9c1b229b171f18afa655400173ddc653d5d01501fb9f2", size = 18075 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/4d/36/2a115987e2d8c300a974597416d9de88f2444426de9571f4b59b2cca3acc/filelock-3.18.0-py3-none-any.whl", hash = "sha256:c401f4f8377c4464e6db25fff06205fd89bdd83b65eb0488ed1b160f780e21de", size = 16215 },
]
```

`uv.lock` should be under git control, providing the exact recipe to replicate an environment, hence ensuring reproducibility. This file can be used to build a Docker image when moving the code to production. It can also be exported into a [`requirements.txt`](https://pip.pypa.io/en/stable/reference/requirements-file-format/) file for legacy tools, via `uv export --format=requirements-txt >requirements.txt`.

I also installed the [`torchvision`](https://pypi.org/project/torchvision/) package, which is a companion package to `torch` that provides datasets, model architectures and image transformations. This is done with `uv add torchvision`.

By default, `uv run` will make sure that environment, `uv.lock` and `pyproject.toml` are consistent with each other. This can also be forced manually with `uv sync`.

Other common operations to handle packages are `uv remove <package_name>`, to uninstall `<package_name>`; and `uv lock --upgragde package <package_name>` to upgrade `<package_name>`'s version if possible.

## Adding development dependencies

As a data scientist, Jupyter notebooks are my bread and butter. In order to run Jupyter notebooks on our `uv` environment, we need to install the [IPython kernel `ipykernel`](https://pypi.org/project/ipykernel/). However, `ipykernel` is qualitatively different from other packages: it is not a dependency of our code, but a tool needed for development. Once my code is ready, I will distribute it as a standalone Python script that has no dependencies on `ipykernel`. The same principle applies to tools like `pytest`, used to test your code, but which the end-user shouldn't require unless they intend to contribute to the project.

`uv` allows to add development dependencies with `uv add --dev ipykernel`, which will add the following to `pyproject.toml`:

```toml
[dependency-groups]
dev = [
    "ipykernel>=6.29.5",
]
```

This allows Visual Studio Code to find this virtual environment and run Jupyter notebooks on it. Alternatively you can launch a Jupyter lab with `uv run --with jupyter jupyter lab`.

## Train the model

Now comes the hard part. I wrote a simple script to train a convolutional neural network on the MNIST dataset. The script is located in [`train.py`](https://github.com/hclimente/hclimente.github.io/tree/main/assets/python/2025-03-15-python-uv/mnist-classifier/train.py), and can be run with `uv run train.py`. It gets 98% classification accuracy on the held out samples. Neat!

## Deploying the model

To conclude, let's exemplify how `uv` boosts reproducibility helping us deploy the model. There are [multiple pre-built images](https://docs.astral.sh/uv/guides/integration/docker/#available-images) that include `uv` and different versions of Python.

Deploying the model is as easy as copying the model weights and the prediction script [`predict.py`](https://github.com/hclimente/hclimente.github.io/tree/main/assets/python/2025-03-15-python-uv/mnist-classifier/predict.py) into the Dockerfile, copying some `uv` files, and building the environment:

```Dockerfile
FROM ghcr.io/astral-sh/uv:python3.10-bookworm-slim

RUN mkdir -p /mnist_classifier/data
WORKDIR /mnist_classifier

# copy the minimum required files:
## the uv files needed to recreate the environment
COPY pyproject.toml uv.lock ./
## the prediction script
COPY predict.py .
## the model weights
COPY data/mnist_cnn.pt data/

# recreate the environment
RUN uv sync --locked

CMD ["uv", "run", "predict.py"]
```

```bash
docker build -t hclimente/mnist_classifier .
docker run hclimente/mnist_classifier
```

```
SimpleCNN(
  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))
  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))
  (fc1): Linear(in_features=1600, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=10, bias=True)
)
Downloading MNIST test set...
Accuracy of SimpleCNN on the 10,000 test images: 98 %
```

# Further reading

- [A year of uv: pros, cons, and should you migrate](https://www.bitecode.dev/p/a-year-of-uv-pros-cons-and-should)
